{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelEvaluation.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/mplatt27/Language-Model-Linguistic-Doubling-Task/blob/main/LanguageModel.ipynb",
      "authorship_tag": "ABX9TyMEtVRkAGT7z1Ot5l/HIUvS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "901546461c2e445588fd043fe81fd85e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_16ba5559f71d437da19da81fcdc91bee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_73f25b4a150d46bf83afe25bd3a902f7",
              "IPY_MODEL_7f13ab0287d14bd39d832c9ef539ef79"
            ]
          }
        },
        "16ba5559f71d437da19da81fcdc91bee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73f25b4a150d46bf83afe25bd3a902f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d280cccc322149eb9184f605c2af4d72",
            "_dom_classes": [],
            "description": "training routine:  59%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 59,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c263817bcf094208b27457604280fd5c"
          }
        },
        "7f13ab0287d14bd39d832c9ef539ef79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_25c8eb7d8f7b4f86a7649ddf9b84ed44",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 59/100 [02:10&lt;01:29,  2.17s/it, sample1=s, sample2=deredittar]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60c7f9afce5b445a968f7a724f388205"
          }
        },
        "d280cccc322149eb9184f605c2af4d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c263817bcf094208b27457604280fd5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25c8eb7d8f7b4f86a7649ddf9b84ed44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60c7f9afce5b445a968f7a724f388205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d83cdad284c348e19bdd930f526f581e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2b260a72868a42dbab3999028e2abab6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4fbbd1e959c042878eea972b03bb5717",
              "IPY_MODEL_afc8ea76aff54ca2998ca59a51c60278"
            ]
          }
        },
        "2b260a72868a42dbab3999028e2abab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4fbbd1e959c042878eea972b03bb5717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2ec5d16daa554265a383863a78f78df4",
            "_dom_classes": [],
            "description": "split=train:  98%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 59,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 58,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae3c1ca057144db5a7259eb2b0437554"
          }
        },
        "afc8ea76aff54ca2998ca59a51c60278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_119456350522421ca6332f6999697d39",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 58/59 [02:11&lt;00:06,  6.03s/it, acc=21.4, epoch=59, loss=2.62]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_970653f9c5214951aac79607b509d6b7"
          }
        },
        "2ec5d16daa554265a383863a78f78df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae3c1ca057144db5a7259eb2b0437554": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "119456350522421ca6332f6999697d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "970653f9c5214951aac79607b509d6b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "109fe02e6e1f442a8a01af1bb588fb29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6d240300a3d74c23acda88674285fe1e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d8410ffd11ea4c85b2eb2a6339bceeb3",
              "IPY_MODEL_e17a5ad7bdc6472ba1a57aeaa1873d00"
            ]
          }
        },
        "6d240300a3d74c23acda88674285fe1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8410ffd11ea4c85b2eb2a6339bceeb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b9cd5367196648f9ad4bedd2b3522f66",
            "_dom_classes": [],
            "description": "split=val:  90%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88810b590e3043af8a789b06b9ca6f34"
          }
        },
        "e17a5ad7bdc6472ba1a57aeaa1873d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e706e9687a994075b2fac9c9a968e51a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9/10 [02:12&lt;00:06,  6.05s/it, acc=20.5, epoch=59, loss=2.64]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8e5279b8ecd4e0d9cfbcc784c349c9d"
          }
        },
        "b9cd5367196648f9ad4bedd2b3522f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88810b590e3043af8a789b06b9ca6f34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e706e9687a994075b2fac9c9a968e51a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8e5279b8ecd4e0d9cfbcc784c349c9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mplatt27/Language-Model-Linguistic-Doubling-Task/blob/main/LanguageModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bymBLatcwZz_"
      },
      "source": [
        "# Character-level English Language Model\r\n",
        "\r\n",
        "*Langauge and Mind Lab*\r\n",
        "\r\n",
        "\r\n",
        "All code is adapted from the book: Natural Language Processing with PyTorch: Build Intelligent Language Applications Using Deep Learning, by Delip Rao and Brian McMahan. The original code is available here: https://github.com/joosthub/PyTorchNLPBook. \r\n",
        "\r\n",
        "The model uses a Gated Recurrent Unit (GRU) neural network and is trained on a set of ### English words from \"\". We then evaluate the model with a test set of novel words that both have and do not have linguistic doubling, to determine if the model has learned preferences that are observed in English speakers. We can also generate novel words and look for features like linguistic doubling. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWHsiuY6nUsY"
      },
      "source": [
        "Notes on dataset:\r\n",
        "\r\n",
        "*   Retrieved from https://www.kaggle.com/rtatman/english-word-frequency and contains 333,333 unique words.\r\n",
        "*   I first shufflued the words in the spreadsheet, then took the first 10,000 words to use (the original code uses a smaller dataset around this size, so as a first attempt on this project, I used a shortened version of the word dataset). We can increase this to the full size later.\r\n",
        "*   I then labeled approximatley 70% as the training set, 15% as the validation set, and 15% as the test set. The test set will be used as a proof of concept to see how the model does with words that are true English words that the model has never seen before. \r\n",
        "*   Looking over the dataset in detail, I'm not sure this is what we want to use for the final version, as many words are strange and something I have never seen before. We can keep searching, but this at least shows us that the code works.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpfKJcY39nvZ"
      },
      "source": [
        "# Imports\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuIZa6uj9oAC"
      },
      "source": [
        "import os\r\n",
        "from argparse import Namespace\r\n",
        "from collections import Counter\r\n",
        "import json\r\n",
        "import re\r\n",
        "import string\r\n",
        "import math\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.nn import functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6n06uyV9vDy"
      },
      "source": [
        "# Data Vectorization classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woqkA8VU9tc0"
      },
      "source": [
        "class Vocabulary(object):\r\n",
        "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, token_to_idx=None):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            token_to_idx (dict): a pre-existing map of tokens to indices\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        if token_to_idx is None:\r\n",
        "            token_to_idx = {}\r\n",
        "        self._token_to_idx = token_to_idx\r\n",
        "\r\n",
        "        self._idx_to_token = {idx: token \r\n",
        "                              for token, idx in self._token_to_idx.items()}\r\n",
        "        \r\n",
        "    def to_serializable(self):\r\n",
        "        \"\"\" returns a dictionary that can be serialized \"\"\"\r\n",
        "        return {'token_to_idx': self._token_to_idx}\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def from_serializable(cls, contents):\r\n",
        "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\r\n",
        "        return cls(**contents)\r\n",
        "\r\n",
        "    def add_token(self, token):\r\n",
        "        \"\"\"Update mapping dicts based on the token.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            token (str): the item to add into the Vocabulary\r\n",
        "        Returns:\r\n",
        "            index (int): the integer corresponding to the token\r\n",
        "        \"\"\"\r\n",
        "        if token in self._token_to_idx:\r\n",
        "            index = self._token_to_idx[token]\r\n",
        "        else:\r\n",
        "            index = len(self._token_to_idx)\r\n",
        "            self._token_to_idx[token] = index\r\n",
        "            self._idx_to_token[index] = token\r\n",
        "        return index\r\n",
        "            \r\n",
        "    def add_many(self, tokens):\r\n",
        "        \"\"\"Add a list of tokens into the Vocabulary\r\n",
        "        \r\n",
        "        Args:\r\n",
        "            tokens (list): a list of string tokens\r\n",
        "        Returns:\r\n",
        "            indices (list): a list of indices corresponding to the tokens\r\n",
        "        \"\"\"\r\n",
        "        return [self.add_token(token) for token in tokens]\r\n",
        "\r\n",
        "    def lookup_token(self, token):\r\n",
        "        \"\"\"Retrieve the index associated with the token \r\n",
        "        \r\n",
        "        Args:\r\n",
        "            token (str): the token to look up \r\n",
        "        Returns:\r\n",
        "            index (int): the index corresponding to the token\r\n",
        "        \"\"\"\r\n",
        "        return self._token_to_idx[token]\r\n",
        "\r\n",
        "    def lookup_index(self, index):\r\n",
        "        \"\"\"Return the token associated with the index\r\n",
        "        \r\n",
        "        Args: \r\n",
        "            index (int): the index to look up\r\n",
        "        Returns:\r\n",
        "            token (str): the token corresponding to the index\r\n",
        "        Raises:\r\n",
        "            KeyError: if the index is not in the Vocabulary\r\n",
        "        \"\"\"\r\n",
        "        if index not in self._idx_to_token:\r\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\r\n",
        "        return self._idx_to_token[index]\r\n",
        "\r\n",
        "    def __str__(self):\r\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self._token_to_idx)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbYTG8LH9z5m"
      },
      "source": [
        "class SequenceVocabulary(Vocabulary):\r\n",
        "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\r\n",
        "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\r\n",
        "                 end_seq_token=\"<END>\"):\r\n",
        "\r\n",
        "        super(SequenceVocabulary, self).__init__(token_to_idx)\r\n",
        "\r\n",
        "        self._mask_token = mask_token\r\n",
        "        self._unk_token = unk_token\r\n",
        "        self._begin_seq_token = begin_seq_token\r\n",
        "        self._end_seq_token = end_seq_token\r\n",
        "\r\n",
        "        self.mask_index = self.add_token(self._mask_token)\r\n",
        "        self.unk_index = self.add_token(self._unk_token)\r\n",
        "        self.begin_seq_index = self.add_token(self._begin_seq_token)\r\n",
        "        self.end_seq_index = self.add_token(self._end_seq_token)\r\n",
        "\r\n",
        "    def to_serializable(self):\r\n",
        "        contents = super(SequenceVocabulary, self).to_serializable()\r\n",
        "        contents.update({'unk_token': self._unk_token,\r\n",
        "                         'mask_token': self._mask_token,\r\n",
        "                         'begin_seq_token': self._begin_seq_token,\r\n",
        "                         'end_seq_token': self._end_seq_token})\r\n",
        "        return contents\r\n",
        "\r\n",
        "    def lookup_token(self, token):\r\n",
        "        \"\"\"Retrieve the index associated with the token \r\n",
        "          or the UNK index if token isn't present.\r\n",
        "        \r\n",
        "        Args:\r\n",
        "            token (str): the token to look up \r\n",
        "        Returns:\r\n",
        "            index (int): the index corresponding to the token\r\n",
        "        Notes:\r\n",
        "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \r\n",
        "              for the UNK functionality \r\n",
        "        \"\"\"\r\n",
        "        if self.unk_index >= 0:\r\n",
        "            return self._token_to_idx.get(token, self.unk_index)\r\n",
        "        else:\r\n",
        "            return self._token_to_idx[token]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRDY-lT992oJ"
      },
      "source": [
        "# Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liiGfSkL94h9"
      },
      "source": [
        "class WordVectorizer(object):\r\n",
        "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"    \r\n",
        "    def __init__(self, char_vocab, classification_vocab):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            char_vocab (Vocabulary): maps words to integers\r\n",
        "            classification_vocab (Vocabulary): maps classes to integers\r\n",
        "        \"\"\"\r\n",
        "        self.char_vocab = char_vocab\r\n",
        "        self.classification_vocab = classification_vocab\r\n",
        "\r\n",
        "    def vectorize(self, word, vector_length=-1):\r\n",
        "        \"\"\"Vectorize a word into a vector of observations and targets\r\n",
        "        \r\n",
        "        The outputs are the vectorized word split into two vectors:\r\n",
        "            word[:-1] and word[1:]\r\n",
        "        At each timestep, the first vector is the observation and the second vector is the target. \r\n",
        "        \r\n",
        "        Args:\r\n",
        "            word (str): the word to be vectorized\r\n",
        "            vector_length (int): an argument for forcing the length of index vector\r\n",
        "        Returns:\r\n",
        "            a tuple: (from_vector, to_vector)\r\n",
        "            from_vector (numpy.ndarray): the observation vector \r\n",
        "            to_vector (numpy.ndarray): the target prediction vector\r\n",
        "        \"\"\"\r\n",
        "        indices = [self.char_vocab.begin_seq_index] \r\n",
        "        indices.extend(self.char_vocab.lookup_token(token) for token in word)\r\n",
        "        indices.append(self.char_vocab.end_seq_index)\r\n",
        "\r\n",
        "        if vector_length < 0:\r\n",
        "            vector_length = len(indices) - 1\r\n",
        "\r\n",
        "        from_vector = np.empty(vector_length, dtype=np.int64)         \r\n",
        "        from_indices = indices[:-1]\r\n",
        "        from_vector[:len(from_indices)] = from_indices\r\n",
        "        from_vector[len(from_indices):] = self.char_vocab.mask_index\r\n",
        "\r\n",
        "        to_vector = np.empty(vector_length, dtype=np.int64)\r\n",
        "        to_indices = indices[1:]\r\n",
        "        to_vector[:len(to_indices)] = to_indices\r\n",
        "        to_vector[len(to_indices):] = self.char_vocab.mask_index\r\n",
        "        \r\n",
        "        return from_vector, to_vector\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def from_dataframe(cls, word_df):\r\n",
        "        \"\"\"Instantiate the vectorizer from the dataset dataframe\r\n",
        "        \r\n",
        "        Args:\r\n",
        "            word_df (pandas.DataFrame): the word dataset\r\n",
        "        Returns:\r\n",
        "            an instance of the WordVectorizer\r\n",
        "        \"\"\"\r\n",
        "        char_vocab = SequenceVocabulary()\r\n",
        "        classification_vocab = Vocabulary()\r\n",
        "\r\n",
        "        for index, row in word_df.iterrows():\r\n",
        "            for char in row.word:\r\n",
        "                char_vocab.add_token(char)\r\n",
        "            classification_vocab.add_token(row.classification)\r\n",
        "\r\n",
        "        return cls(char_vocab, classification_vocab)\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def from_serializable(cls, contents):\r\n",
        "        \"\"\"Instantiate the vectorizer from saved contents\r\n",
        "        \r\n",
        "        Args:\r\n",
        "            contents (dict): a dict holding two vocabularies for this vectorizer\r\n",
        "                This dictionary is created using `vectorizer.to_serializable()`\r\n",
        "        Returns:\r\n",
        "            an instance of WordVectorizer\r\n",
        "        \"\"\"\r\n",
        "        char_vocab = SequenceVocabulary.from_serializable(contents['char_vocab'])\r\n",
        "        class_vocab =  Vocabulary.from_serializable(contents['classification_vocab'])\r\n",
        "\r\n",
        "        return cls(char_vocab=char_vocab, classification_vocab=nat_vocab)\r\n",
        "\r\n",
        "    def to_serializable(self):\r\n",
        "        \"\"\" Returns the serializable contents \"\"\"\r\n",
        "        return {'char_vocab': self.char_vocab.to_serializable(), \r\n",
        "                'classification_vocab': self.classification_vocab.to_serializable()}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlu4nKW696x8"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo824x6m98cd"
      },
      "source": [
        "class WordDataset(Dataset):\r\n",
        "    def __init__(self, word_df, vectorizer):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            word_df (pandas.DataFrame): the dataset\r\n",
        "            vectorizer (WordVectorizer): vectorizer instatiated from dataset\r\n",
        "        \"\"\"\r\n",
        "        self.word_df = word_df \r\n",
        "        self._vectorizer = vectorizer\r\n",
        "\r\n",
        "        self._max_seq_length = max(map(len, self.word_df.word)) + 2\r\n",
        "\r\n",
        "        self.train_df = self.word_df[self.word_df.split=='train']\r\n",
        "        self.train_size = len(self.train_df)\r\n",
        "\r\n",
        "        self.val_df = self.word_df[self.word_df.split=='val']\r\n",
        "        self.validation_size = len(self.val_df)\r\n",
        "\r\n",
        "        self.test_df = self.word_df[self.word_df.split=='test']\r\n",
        "        self.test_size = len(self.test_df)\r\n",
        "\r\n",
        "        # ADDED:\r\n",
        "        # -----------------------------------------------------------------\r\n",
        "        self.doubling_df = self.word_df[self.word_df.split=='doubling']\r\n",
        "        self.doubling_size = len(self.doubling_df)\r\n",
        "\r\n",
        "        self.nodoubling_df = self.word_df[self.word_df.split=='no_doubling']\r\n",
        "        self.nodoubling_size = len(self.nodoubling_df)\r\n",
        "\r\n",
        "\r\n",
        "        # -----------------------------------------------------------------\r\n",
        "\r\n",
        "        self._lookup_dict = {'train': (self.train_df, self.train_size), \r\n",
        "                             'val': (self.val_df, self.validation_size), \r\n",
        "                             'test': (self.test_df, self.test_size),\r\n",
        "                             'doubling': (self.doubling_df, self.doubling_size), # ADDED\r\n",
        "                             'no_doubling': (self.nodoubling_df, self.nodoubling_size)} # ADDED\r\n",
        "\r\n",
        "        self.set_split('train')\r\n",
        "        \r\n",
        "    @classmethod\r\n",
        "    def load_dataset_and_make_vectorizer(cls, word_csv):\r\n",
        "        \"\"\"Load dataset and make a new vectorizer from scratch\r\n",
        "        \r\n",
        "        Args:\r\n",
        "            word_csv (str): location of the dataset\r\n",
        "        Returns:\r\n",
        "            an instance of WordDataset\r\n",
        "        \"\"\"\r\n",
        "        \r\n",
        "        word_df = pd.read_csv(word_csv, encoding='latin-1')\r\n",
        "        return cls(word_df, WordVectorizer.from_dataframe(word_df))\r\n",
        "        \r\n",
        "    @classmethod\r\n",
        "    def load_dataset_and_load_vectorizer(cls, word_csv, vectorizer_filepath):\r\n",
        "        \"\"\"Load dataset and the corresponding vectorizer. \r\n",
        "        Used in the case in the vectorizer has been cached for re-use\r\n",
        "        \r\n",
        "        Args:\r\n",
        "            word_csv (str): location of the dataset\r\n",
        "            vectorizer_filepath (str): location of the saved vectorizer\r\n",
        "        Returns:\r\n",
        "            an instance of WordDataset\r\n",
        "        \"\"\"\r\n",
        "        word_df = pd.read_csv(word_csv, encoding='latin-1') # changed coding here\r\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\r\n",
        "        return cls(word_df, vectorizer)\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def load_vectorizer_only(vectorizer_filepath):\r\n",
        "        \"\"\"a static method for loading the vectorizer from file\r\n",
        "        \r\n",
        "        Args:\r\n",
        "            vectorizer_filepath (str): the location of the serialized vectorizer\r\n",
        "        Returns:\r\n",
        "            an instance of WordVectorizer\r\n",
        "        \"\"\"\r\n",
        "        with open(vectorizer_filepath) as fp:\r\n",
        "            return WordVectorizer.from_serializable(json.load(fp))\r\n",
        "\r\n",
        "    def save_vectorizer(self, vectorizer_filepath):\r\n",
        "        \"\"\"saves the vectorizer to disk using json\r\n",
        "        \r\n",
        "        Args:\r\n",
        "            vectorizer_filepath (str): the location to save the vectorizer\r\n",
        "        \"\"\"\r\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\r\n",
        "            json.dump(self._vectorizer.to_serializable(), fp)\r\n",
        "\r\n",
        "    def get_vectorizer(self):\r\n",
        "        \"\"\" returns the vectorizer \"\"\"\r\n",
        "        return self._vectorizer\r\n",
        "\r\n",
        "    def set_split(self, split=\"train\"):\r\n",
        "        self._target_split = split\r\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return self._target_size\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        \"\"\"the primary entry point method for PyTorch datasets\r\n",
        "        \r\n",
        "        Args:\r\n",
        "            index (int): the index to the data point \r\n",
        "        Returns:\r\n",
        "            a dictionary holding the data point: (x_data, y_target, class_index)\r\n",
        "        \"\"\"\r\n",
        "        row = self._target_df.iloc[index]\r\n",
        "        \r\n",
        "        from_vector, to_vector = \\\r\n",
        "            self._vectorizer.vectorize(row.word, self._max_seq_length)\r\n",
        "        \r\n",
        "        classification_index = \\\r\n",
        "            self._vectorizer.classification_vocab.lookup_token(row.classification)\r\n",
        "\r\n",
        "        return {'x_data': from_vector, \r\n",
        "                'y_target': to_vector, \r\n",
        "                'class_index': classification_index}\r\n",
        "\r\n",
        "    def get_num_batches(self, batch_size):\r\n",
        "        \"\"\"Given a batch size, return the number of batches in the dataset\r\n",
        "        \r\n",
        "        Args:\r\n",
        "            batch_size (int)\r\n",
        "        Returns:\r\n",
        "            number of batches in the dataset\r\n",
        "        \"\"\"\r\n",
        "        return len(self) // batch_size\r\n",
        "    \r\n",
        "def generate_batches(dataset, batch_size, shuffle=True,\r\n",
        "                     drop_last=True, device=\"cpu\"): \r\n",
        "    \"\"\"\r\n",
        "    A generator function which wraps the PyTorch DataLoader. It will \r\n",
        "      ensure each tensor is on the write device location.\r\n",
        "    \"\"\"\r\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\r\n",
        "                            shuffle=shuffle, drop_last=drop_last)\r\n",
        "\r\n",
        "    for data_dict in dataloader:\r\n",
        "        out_data_dict = {}\r\n",
        "        for name, tensor in data_dict.items():\r\n",
        "            out_data_dict[name] = data_dict[name].to(device)\r\n",
        "        yield out_data_dict"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcCvBM1j9_xY"
      },
      "source": [
        "# Word Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w33KikSE-BXG"
      },
      "source": [
        "class WordGenerationModel(nn.Module):\r\n",
        "    def __init__(self, char_embedding_size, char_vocab_size, rnn_hidden_size, \r\n",
        "                 batch_first=True, padding_idx=0, dropout_p=0.5):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            char_embedding_size (int): The size of the character embeddings\r\n",
        "            char_vocab_size (int): The number of characters to embed\r\n",
        "            rnn_hidden_size (int): The size of the RNN's hidden state\r\n",
        "            batch_first (bool): Informs whether the input tensors will \r\n",
        "                have batch or the sequence on the 0th dimension\r\n",
        "            padding_idx (int): The index for the tensor padding; \r\n",
        "                see torch.nn.Embedding\r\n",
        "            dropout_p (float): the probability of zeroing activations using\r\n",
        "                the dropout method.  higher means more likely to zero.\r\n",
        "        \"\"\"\r\n",
        "        super(WordGenerationModel, self).__init__()\r\n",
        "        \r\n",
        "        self.char_emb = nn.Embedding(num_embeddings=char_vocab_size,\r\n",
        "                                     embedding_dim=char_embedding_size,\r\n",
        "                                     padding_idx=padding_idx)\r\n",
        "\r\n",
        "        self.rnn = nn.GRU(input_size=char_embedding_size, \r\n",
        "                          hidden_size=rnn_hidden_size,\r\n",
        "                          batch_first=batch_first)\r\n",
        "        \r\n",
        "        self.fc = nn.Linear(in_features=rnn_hidden_size, \r\n",
        "                            out_features=char_vocab_size)\r\n",
        "        \r\n",
        "        self._dropout_p = dropout_p\r\n",
        "\r\n",
        "    def forward(self, x_in, apply_softmax=False):\r\n",
        "        \"\"\"The forward pass of the model\r\n",
        "        \r\n",
        "        Args:\r\n",
        "            x_in (torch.Tensor): an input data tensor. \r\n",
        "                x_in.shape should be (batch, input_dim)\r\n",
        "            apply_softmax (bool): a flag for the softmax activation\r\n",
        "                should be false if used with the Cross Entropy losses\r\n",
        "        Returns:\r\n",
        "            the resulting tensor. tensor.shape should be (batch, char_vocab_size)\r\n",
        "        \"\"\"\r\n",
        "        x_embedded = self.char_emb(x_in)\r\n",
        "\r\n",
        "        y_out, _ = self.rnn(x_embedded)\r\n",
        "\r\n",
        "        batch_size, seq_size, feat_size = y_out.shape\r\n",
        "        y_out = y_out.contiguous().view(batch_size * seq_size, feat_size)\r\n",
        "\r\n",
        "        y_out = self.fc(F.dropout(y_out, p=self._dropout_p))\r\n",
        "                         \r\n",
        "        if apply_softmax:\r\n",
        "            y_out = F.softmax(y_out, dim=1)\r\n",
        "            \r\n",
        "        new_feat_size = y_out.shape[-1]\r\n",
        "        y_out = y_out.view(batch_size, seq_size, new_feat_size)\r\n",
        "            \r\n",
        "        return y_out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGCoOA1M-JMg"
      },
      "source": [
        "def sample_from_model(model, vectorizer, num_samples=1, sample_size=20, \r\n",
        "                      temperature=1.0):\r\n",
        "    \"\"\"Sample a sequence of indices from the model\r\n",
        "    \r\n",
        "    Args:\r\n",
        "        model (WordGenerationModel): the trained model\r\n",
        "        vectorizer (WordVectorizer): the corresponding vectorizer\r\n",
        "        num_samples (int): the number of samples\r\n",
        "        sample_size (int): the max length of the samples\r\n",
        "        temperature (float): accentuates or flattens \r\n",
        "            the distribution. \r\n",
        "            0.0 < temperature < 1.0 will make it peakier. \r\n",
        "            temperature > 1.0 will make it more uniform\r\n",
        "    Returns:\r\n",
        "        indices (torch.Tensor): the matrix of indices; \r\n",
        "        shape = (num_samples, sample_size)\r\n",
        "    \"\"\"\r\n",
        "    begin_seq_index = [vectorizer.char_vocab.begin_seq_index \r\n",
        "                       for _ in range(num_samples)]\r\n",
        "    begin_seq_index = torch.tensor(begin_seq_index, \r\n",
        "                                   dtype=torch.int64).unsqueeze(dim=1)\r\n",
        "    indices = [begin_seq_index]\r\n",
        "    h_t = None\r\n",
        "    \r\n",
        "    for time_step in range(sample_size):\r\n",
        "        x_t = indices[time_step]\r\n",
        "        x_emb_t = model.char_emb(x_t)\r\n",
        "        rnn_out_t, h_t = model.rnn(x_emb_t, h_t)\r\n",
        "        prediction_vector = model.fc(rnn_out_t.squeeze(dim=1))\r\n",
        "        probability_vector = F.softmax(prediction_vector / temperature, dim=1)\r\n",
        "        indices.append(torch.multinomial(probability_vector, num_samples=1))\r\n",
        "    indices = torch.stack(indices).squeeze().permute(1, 0)\r\n",
        "    return indices\r\n",
        "\r\n",
        "def decode_samples(sampled_indices, vectorizer):\r\n",
        "    \"\"\"Transform indices into the string form of a word\r\n",
        "    \r\n",
        "    Args:\r\n",
        "        sampled_indices (torch.Tensor): the inidces from `sample_from_model`\r\n",
        "        vectorizer (WordVectorizer): the corresponding vectorizer\r\n",
        "    \"\"\"\r\n",
        "    decoded_words = []\r\n",
        "    vocab = vectorizer.char_vocab\r\n",
        "    \r\n",
        "    for sample_index in range(sampled_indices.shape[0]):\r\n",
        "        word = \"\"\r\n",
        "        for time_step in range(sampled_indices.shape[1]):\r\n",
        "            sample_item = sampled_indices[sample_index, time_step].item()\r\n",
        "            if sample_item == vocab.begin_seq_index:\r\n",
        "                continue\r\n",
        "            elif sample_item == vocab.end_seq_index:\r\n",
        "                break\r\n",
        "            else:\r\n",
        "                word += vocab.lookup_index(sample_item)\r\n",
        "        decoded_words.append(word)\r\n",
        "    return decoded_words"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQUIJdm7-M8y"
      },
      "source": [
        "# Training routine\r\n",
        "\r\n",
        "Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVhEaA5z-MBc"
      },
      "source": [
        "def make_train_state(args):\r\n",
        "    return {'stop_early': False,\r\n",
        "            'early_stopping_step': 0,\r\n",
        "            'early_stopping_best_val': 1e8,\r\n",
        "            'learning_rate': args.learning_rate,\r\n",
        "            'epoch_index': 0,\r\n",
        "            'train_loss': [],\r\n",
        "            'train_acc': [],\r\n",
        "            'val_loss': [],\r\n",
        "            'val_acc': [],\r\n",
        "            'test_loss': -1,\r\n",
        "            'test_acc': -1,\r\n",
        "            'model_filename': args.model_state_file}\r\n",
        "\r\n",
        "def update_train_state(args, model, train_state):\r\n",
        "    \"\"\"Handle the training state updates.\r\n",
        "    Components:\r\n",
        "     - Early Stopping: Prevent overfitting.\r\n",
        "     - Model Checkpoint: Model is saved if the model is better\r\n",
        "    \r\n",
        "    :param args: main arguments\r\n",
        "    :param model: model to train\r\n",
        "    :param train_state: a dictionary representing the training state values\r\n",
        "    :returns:\r\n",
        "        a new train_state\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # Save one model at least\r\n",
        "    if train_state['epoch_index'] == 0:\r\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\r\n",
        "        train_state['stop_early'] = False\r\n",
        "\r\n",
        "    # Save model if performance improved\r\n",
        "    elif train_state['epoch_index'] >= 1:\r\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\r\n",
        "         \r\n",
        "        # If loss worsened\r\n",
        "        if loss_t >= loss_tm1:\r\n",
        "            # Update step\r\n",
        "            train_state['early_stopping_step'] += 1\r\n",
        "        # Loss decreased\r\n",
        "        else:\r\n",
        "            # Save the best model\r\n",
        "            if loss_t < train_state['early_stopping_best_val']:\r\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\r\n",
        "                train_state['early_stopping_best_val'] = loss_t\r\n",
        "\r\n",
        "            # Reset early stopping step\r\n",
        "            train_state['early_stopping_step'] = 0\r\n",
        "\r\n",
        "        # Stop early ?\r\n",
        "        train_state['stop_early'] = \\\r\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\r\n",
        "\r\n",
        "    return train_state\r\n",
        "\r\n",
        "def normalize_sizes(y_pred, y_true):\r\n",
        "    \"\"\"Normalize tensor sizes\r\n",
        "    \r\n",
        "    Args:\r\n",
        "        y_pred (torch.Tensor): the output of the model\r\n",
        "            If a 3-dimensional tensor, reshapes to a matrix\r\n",
        "        y_true (torch.Tensor): the target predictions\r\n",
        "            If a matrix, reshapes to be a vector\r\n",
        "    \"\"\"\r\n",
        "    if len(y_pred.size()) == 3:\r\n",
        "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\r\n",
        "    if len(y_true.size()) == 2:\r\n",
        "        y_true = y_true.contiguous().view(-1)\r\n",
        "    return y_pred, y_true\r\n",
        "\r\n",
        "def compute_accuracy(y_pred, y_true, mask_index):\r\n",
        "    y_pred, y_true = normalize_sizes(y_pred, y_true)\r\n",
        "\r\n",
        "    _, y_pred_indices = y_pred.max(dim=1)\r\n",
        "    \r\n",
        "    correct_indices = torch.eq(y_pred_indices, y_true).float()\r\n",
        "    valid_indices = torch.ne(y_true, mask_index).float()\r\n",
        "    \r\n",
        "    n_correct = (correct_indices * valid_indices).sum().item()\r\n",
        "    n_valid = valid_indices.sum().item()\r\n",
        "\r\n",
        "    return n_correct / n_valid * 100\r\n",
        "\r\n",
        "def sequence_loss(y_pred, y_true, mask_index):\r\n",
        "    y_pred, y_true = normalize_sizes(y_pred, y_true)\r\n",
        "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ8oC67-XFq"
      },
      "source": [
        "Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPae1Ke1-UQj"
      },
      "source": [
        "def set_seed_everywhere(seed, cuda):\r\n",
        "    np.random.seed(seed)\r\n",
        "    torch.manual_seed(seed)\r\n",
        "    if cuda:\r\n",
        "        torch.cuda.manual_seed_all(seed)\r\n",
        "\r\n",
        "def handle_dirs(dirpath):\r\n",
        "    if not os.path.exists(dirpath):\r\n",
        "        os.makedirs(dirpath)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gux7fTG7-Yau"
      },
      "source": [
        "Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZSQZzGocS2i",
        "outputId": "00a3feb0-ced5-4830-e607-e35063a0a06a"
      },
      "source": [
        "# to access and save files on google drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RnmkCGW-a9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7acbb729-2e7e-420c-ac7d-ffcbea1aa606"
      },
      "source": [
        "args = Namespace(\r\n",
        "    # Data and Path information\r\n",
        "    word_csv=\"/content/drive/MyDrive/Lang-and-Mind-Lab/words_doubling.csv\", # CHANGE THIS TO YOUR PATH\r\n",
        "    vectorizer_file=\"vectorizer.json\",\r\n",
        "    model_state_file=\"model.pth\",\r\n",
        "    save_dir=\"/content/drive/MyDrive/Lang-and-Mind-Lab\", # CHANGE THIS TO YOUR PATH\r\n",
        "    # Model hyper parameters\r\n",
        "    char_embedding_size=32,\r\n",
        "    rnn_hidden_size=32,\r\n",
        "    # Training hyper parameters\r\n",
        "    seed=1337,\r\n",
        "    learning_rate=0.001,\r\n",
        "    batch_size=128,\r\n",
        "    num_epochs=100,\r\n",
        "    early_stopping_criteria=5,\r\n",
        "    # Runtime options\r\n",
        "    catch_keyboard_interrupt=True,\r\n",
        "    cuda=True,\r\n",
        "    expand_filepaths_to_save_dir=True,\r\n",
        "    reload_from_files=False, # change to true after first time running\r\n",
        ")\r\n",
        "\r\n",
        "if args.expand_filepaths_to_save_dir:\r\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\r\n",
        "                                        args.vectorizer_file)\r\n",
        "\r\n",
        "    args.model_state_file = os.path.join(args.save_dir,\r\n",
        "                                         args.model_state_file)\r\n",
        "    \r\n",
        "    print(\"Expanded filepaths: \")\r\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\r\n",
        "    print(\"\\t{}\".format(args.model_state_file))\r\n",
        "    \r\n",
        "    \r\n",
        "# Check CUDA\r\n",
        "if not torch.cuda.is_available():\r\n",
        "    args.cuda = False\r\n",
        "\r\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\r\n",
        "    \r\n",
        "print(\"Using CUDA: {}\".format(args.cuda))\r\n",
        "\r\n",
        "# Set seed for reproducibility\r\n",
        "set_seed_everywhere(args.seed, args.cuda)\r\n",
        "\r\n",
        "# handle dirs\r\n",
        "handle_dirs(args.save_dir)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expanded filepaths: \n",
            "\t/content/drive/MyDrive/Lang-and-Mind-Lab/vectorizer.json\n",
            "\t/content/drive/MyDrive/Lang-and-Mind-Lab/model.pth\n",
            "Using CUDA: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jntkz8JI-dh9"
      },
      "source": [
        "Initializations\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEdeHSwz-gaD"
      },
      "source": [
        "if args.reload_from_files:\r\n",
        "    # training from a checkpoint\r\n",
        "    dataset = WordDataset.load_dataset_and_load_vectorizer(args.word_csv, args.vectorizer_file)\r\n",
        "else:\r\n",
        "    # create dataset and vectorizer\r\n",
        "    dataset = WordDataset.load_dataset_and_make_vectorizer(args.word_csv)\r\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\r\n",
        "\r\n",
        "vectorizer = dataset.get_vectorizer()\r\n",
        "\r\n",
        "model = WordGenerationModel(char_embedding_size=args.char_embedding_size,\r\n",
        "                               char_vocab_size=len(vectorizer.char_vocab),\r\n",
        "                               rnn_hidden_size=args.rnn_hidden_size,\r\n",
        "                               padding_idx=vectorizer.char_vocab.mask_index)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHOKSXvE5A20"
      },
      "source": [
        "# this is useful later if we want to get the probability of a certain char\r\n",
        "vectorizer.char_vocab._idx_to_token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhy4G1pV-kfI"
      },
      "source": [
        "Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO2IKw0K-iK7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "901546461c2e445588fd043fe81fd85e",
            "16ba5559f71d437da19da81fcdc91bee",
            "73f25b4a150d46bf83afe25bd3a902f7",
            "7f13ab0287d14bd39d832c9ef539ef79",
            "d280cccc322149eb9184f605c2af4d72",
            "c263817bcf094208b27457604280fd5c",
            "25c8eb7d8f7b4f86a7649ddf9b84ed44",
            "60c7f9afce5b445a968f7a724f388205",
            "d83cdad284c348e19bdd930f526f581e",
            "2b260a72868a42dbab3999028e2abab6",
            "4fbbd1e959c042878eea972b03bb5717",
            "afc8ea76aff54ca2998ca59a51c60278",
            "2ec5d16daa554265a383863a78f78df4",
            "ae3c1ca057144db5a7259eb2b0437554",
            "119456350522421ca6332f6999697d39",
            "970653f9c5214951aac79607b509d6b7",
            "109fe02e6e1f442a8a01af1bb588fb29",
            "6d240300a3d74c23acda88674285fe1e",
            "d8410ffd11ea4c85b2eb2a6339bceeb3",
            "e17a5ad7bdc6472ba1a57aeaa1873d00",
            "b9cd5367196648f9ad4bedd2b3522f66",
            "88810b590e3043af8a789b06b9ca6f34",
            "e706e9687a994075b2fac9c9a968e51a",
            "e8e5279b8ecd4e0d9cfbcc784c349c9d"
          ]
        },
        "outputId": "cfe7d95b-739e-4d6b-a06a-8b8f044ebfb5"
      },
      "source": [
        "mask_index = vectorizer.char_vocab.mask_index\r\n",
        "\r\n",
        "model = model.to(args.device)\r\n",
        "\r\n",
        "\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\r\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\r\n",
        "                                           mode='min', factor=0.5,\r\n",
        "                                           patience=1)\r\n",
        "train_state = make_train_state(args)\r\n",
        "\r\n",
        "epoch_bar = tqdm_notebook(desc='training routine', \r\n",
        "                          total=args.num_epochs,\r\n",
        "                          position=0)\r\n",
        "\r\n",
        "dataset.set_split('train')\r\n",
        "train_bar = tqdm_notebook(desc='split=train',\r\n",
        "                          total=dataset.get_num_batches(args.batch_size), \r\n",
        "                          position=1, \r\n",
        "                          leave=True)\r\n",
        "dataset.set_split('val')\r\n",
        "val_bar = tqdm_notebook(desc='split=val',\r\n",
        "                        total=dataset.get_num_batches(args.batch_size), \r\n",
        "                        position=1, \r\n",
        "                        leave=True)\r\n",
        "\r\n",
        "try:\r\n",
        "    for epoch_index in range(args.num_epochs):\r\n",
        "        train_state['epoch_index'] = epoch_index\r\n",
        "\r\n",
        "        # Iterate over training dataset\r\n",
        "\r\n",
        "        # setup: batch generator, set loss and acc to 0, set train mode on\r\n",
        "        dataset.set_split('train')\r\n",
        "        batch_generator = generate_batches(dataset, \r\n",
        "                                           batch_size=args.batch_size, \r\n",
        "                                           device=args.device)\r\n",
        "        running_loss = 0.0\r\n",
        "        running_acc = 0.0\r\n",
        "        model.train()\r\n",
        "        \r\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\r\n",
        "            # the training routine is these 5 steps:\r\n",
        "\r\n",
        "            # --------------------------------------    \r\n",
        "            # step 1. zero the gradients\r\n",
        "            optimizer.zero_grad()\r\n",
        "\r\n",
        "            # step 2. compute the output\r\n",
        "            y_pred = model(x_in=batch_dict['x_data'])\r\n",
        "\r\n",
        "            # step 3. compute the loss\r\n",
        "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\r\n",
        "\r\n",
        "\r\n",
        "            # step 4. use loss to produce gradients\r\n",
        "            loss.backward()\r\n",
        "\r\n",
        "            # step 5. use optimizer to take gradient step\r\n",
        "            optimizer.step()\r\n",
        "            # -----------------------------------------\r\n",
        "            # compute the  running loss and running accuracy\r\n",
        "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\r\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\r\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\r\n",
        "\r\n",
        "            # update bar\r\n",
        "            train_bar.set_postfix(loss=running_loss,\r\n",
        "                                  acc=running_acc,\r\n",
        "                                  epoch=epoch_index)\r\n",
        "            train_bar.update()\r\n",
        "\r\n",
        "        train_state['train_loss'].append(running_loss)\r\n",
        "        train_state['train_acc'].append(running_acc)\r\n",
        "\r\n",
        "        # Iterate over val dataset\r\n",
        "\r\n",
        "        # setup: batch generator, set loss and acc to 0; set eval mode on\r\n",
        "        dataset.set_split('val')\r\n",
        "        batch_generator = generate_batches(dataset, \r\n",
        "                                           batch_size=args.batch_size, \r\n",
        "                                           device=args.device)\r\n",
        "        running_loss = 0.\r\n",
        "        running_acc = 0.\r\n",
        "        model.eval()\r\n",
        "\r\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\r\n",
        "            # compute the output\r\n",
        "            y_pred = model(x_in=batch_dict['x_data'])\r\n",
        "\r\n",
        "            # step 3. compute the loss\r\n",
        "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\r\n",
        "\r\n",
        "            # compute the  running loss and running accuracy\r\n",
        "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\r\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\r\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\r\n",
        "            \r\n",
        "            # Update bar\r\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \r\n",
        "                            epoch=epoch_index)\r\n",
        "            val_bar.update()\r\n",
        "\r\n",
        "        train_state['val_loss'].append(running_loss)\r\n",
        "        train_state['val_acc'].append(running_acc)\r\n",
        "\r\n",
        "        train_state = update_train_state(args=args, model=model, \r\n",
        "                                         train_state=train_state)\r\n",
        "\r\n",
        "        scheduler.step(train_state['val_loss'][-1])\r\n",
        "\r\n",
        "        if train_state['stop_early']:\r\n",
        "            break\r\n",
        "        \r\n",
        "        # move model to cpu for sampling\r\n",
        "        model = model.cpu()\r\n",
        "        sampled_words = decode_samples(\r\n",
        "            sample_from_model(model, vectorizer, num_samples=2), \r\n",
        "            vectorizer)\r\n",
        "        epoch_bar.set_postfix(sample1=sampled_words[0], \r\n",
        "                              sample2=sampled_words[1])\r\n",
        "        # move model back to whichever device it should be on\r\n",
        "        model = model.to(args.device)\r\n",
        "        \r\n",
        "        train_bar.n = 0\r\n",
        "        val_bar.n = 0\r\n",
        "        epoch_bar.update()\r\n",
        "        \r\n",
        "except KeyboardInterrupt:\r\n",
        "    print(\"Exiting loop\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "901546461c2e445588fd043fe81fd85e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d83cdad284c348e19bdd930f526f581e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='split=train', max=59.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "109fe02e6e1f442a8a01af1bb588fb29",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='split=val', max=10.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-VArXzT-qjk"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVQ3DBn--sey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dee74bb-4c74-4079-a599-8e72680ae69d"
      },
      "source": [
        "np.random.choice(np.arange(len(vectorizer.classification_vocab)), replace=True, size=2) # I think this just shows us how many classes are, if we have different classes"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogzoDm3N5hw7"
      },
      "source": [
        "\"\"\"\r\n",
        "For reference, the index of each character token in the distribution: CHANGE IF USING NEW DATASET\r\n",
        "\r\n",
        "{0: '<MASK>', 1: '<UNK>', 2: '<BEGIN>', 3: '<END>', 4: 'f', 5: 'i', 6: 'o', 7: 'n',\r\n",
        " 8: 'a', 9: 's', 10: 'h', 11: 't', 12: 'l', 13: 'w', 14: 'e', 15: 'b', 16: 'r', 17: 'u',\r\n",
        " 18: 'm', 19: 'c', 20: 'k', 21: 'p', 22: 'j', 23: 'd', 24: 'y', 25: 'v', 26: 'g', 27: 'q', \r\n",
        " 28: 'x', 29: 'z'}\r\n",
        "\r\n",
        "\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGzcIknG-I03"
      },
      "source": [
        "Evaluate using actual English words. This will give us an idea of how well the model does with predicting words that are actual in English. That is, for each \r\n",
        "test sequence, we will compare the probability of the sequence that actually exists in English, with the probability of the sequence that the model generated. We will evaluate using perplexity (2^-log prob of sequence). Lower perplexity means a better prediction was made."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acinRVe2-tMh"
      },
      "source": [
        "\"\"\"\r\n",
        "Compute the loss & accuracy on the English test set using the best available model.\r\n",
        "That is, here we are comparing the probability distribution of possible characters that could occur\r\n",
        "at each position, with what actually occured.\r\n",
        "\r\n",
        "y_pred: 128 words in batch, 34 character positions in each word, 30 characters in the distribution\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "model.load_state_dict(torch.load(train_state['model_filename']))\r\n",
        "\r\n",
        "model = model.to(args.device)\r\n",
        "\r\n",
        "dataset.set_split('test')\r\n",
        "batch_generator = generate_batches(dataset, \r\n",
        "                                   batch_size=args.batch_size, \r\n",
        "                                   device=args.device)\r\n",
        "running_acc = 0.\r\n",
        "model.eval()\r\n",
        "\r\n",
        "word_perplexities = {} # maps words --> perplexity values\r\n",
        "position_perplexities = {} # maps char positions --> perplexity values\r\n",
        "\r\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\r\n",
        "\r\n",
        "    # compute the output\r\n",
        "    y_pred = model(x_in=batch_dict['x_data'])\r\n",
        "\r\n",
        "    # initialize dictionary\r\n",
        "    word_perplexities[batch_index] = {}\r\n",
        "    position_perplexities[batch_index] = {}\r\n",
        "\r\n",
        "    # iterate over each word in the batch, and calculate the loss for that word\r\n",
        "    # save perplexity to dict\r\n",
        "    start = 0\r\n",
        "    end = 1\r\n",
        "    for i in range(128):\r\n",
        "        word_loss = sequence_loss(y_pred[start:end,:],batch_dict['y_target'][start:end,:], mask_index)\r\n",
        "\r\n",
        "        # reconstruct the word\r\n",
        "        word = \"\"\r\n",
        "        start_pos = 0\r\n",
        "        end_pos = 1\r\n",
        "        for j in range(34):\r\n",
        "            curr_char_index = batch_dict['y_target'][i][j].item()\r\n",
        "            if curr_char_index >= 4:\r\n",
        "                curr_char = vectorizer.char_vocab._idx_to_token[curr_char_index]\r\n",
        "                word += curr_char\r\n",
        "\r\n",
        "            position_loss = sequence_loss(y_pred[:, start_pos:end_pos],batch_dict['y_target'][:, start_pos:end_pos], mask_index)\r\n",
        "            position_pp = math.pow(2,position_loss)\r\n",
        "            position_perplexities[batch_index][j] = position_pp\r\n",
        "            start_pos += 1\r\n",
        "            end_pos += 1\r\n",
        "\r\n",
        "        pp = math.pow(2,word_loss)\r\n",
        "        word_perplexities[batch_index][word] = pp\r\n",
        "\r\n",
        "        start += 1\r\n",
        "        end += 1\r\n",
        "\r\n",
        "    # compute the loss\r\n",
        "    loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\r\n",
        "\r\n",
        "    # compute the accuracy\r\n",
        "    running_loss += (loss.item() - running_loss) / (batch_index + 1)\r\n",
        "\r\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\r\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\r\n",
        "\r\n",
        "train_state['test_loss'] = running_loss \r\n",
        "train_state['test_acc'] = running_acc"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NoiBWYC-wJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e1a452-16d1-45f9-ab0e-fc7886c2b500"
      },
      "source": [
        "# print the loss, perplexity, and accuracy for the test set overall\r\n",
        "print(\"Test loss: {};\".format(train_state['test_loss']))\r\n",
        "print(\"Test perplexity: {};\".format(math.pow(2,train_state['test_loss'])))\r\n",
        "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 2.6466638048489886;\n",
            "Test perplexity: 6.262174908349251;\n",
            "Test Accuracy: 20.67270505757142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I0XeU2wt-_G"
      },
      "source": [
        "# print the perplexity values for each word in the first batch (128 words)\r\n",
        "# low perplexity values are good\r\n",
        "\r\n",
        "flag = 0\r\n",
        "for b, w_dict in word_perplexities.items():\r\n",
        "    if flag > 0:\r\n",
        "            break\r\n",
        "    for w, p in w_dict.items():\r\n",
        "        print(\"word: \", w, \" perplexity: \", round(p,2))\r\n",
        "    flag += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIeXrJHzHQKs",
        "outputId": "a9a5b200-febc-4ba4-8b38-80d445e67325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "# get the perpelxity at each character position (averaged over each doubling word)\r\n",
        "avgs = {}\r\n",
        "for batch, char_dict in position_perplexities.items():\r\n",
        "    for ch, p in char_dict.items():\r\n",
        "        if avgs.get(ch):\r\n",
        "            avgs[ch] += p\r\n",
        "        else:\r\n",
        "            avgs[ch] = p\r\n",
        "avgs = {k: v / 19 for k, v in avgs.items()}\r\n",
        "\r\n",
        "# plot\r\n",
        "df = pd.DataFrame(list(avgs.items()), columns=['Character Positions', 'English']) \r\n",
        "plt.bar(df['Character Positions'], df['English'], color='purple', width=0.5)\r\n",
        "plt.title('English words')\r\n",
        "plt.xlabel('Character positions')\r\n",
        "plt.ylabel('Avg. perplexities')\r\n",
        "plt.xlim(0,29)\r\n",
        "plt.xticks(np.arange(0, 29, 1))\r\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 4)\r\n",
        "plt.show()\r\n",
        "print('\\n')\r\n",
        "\r\n",
        "# note that many of the character positions at the end are not real. Since\r\n",
        "# the model needs each word to be the same length, a \"mask\" character is created\r\n",
        "# for shorter words, and that probability is not counted overal when looking \r\n",
        "# at the probabilty of that word. So the end of the graph doesn't tell us a ton.\r\n",
        "\r\n",
        "# Each word should have high perplexity in the beginning, because the more \r\n",
        "# observations that a model sees, the less \"perlexed\" it will be, and it has\r\n",
        "# observed little in the beginning of the word. As we get farther into the word\r\n",
        "# perplexity should decrease. This isn't happening right now, but a lot of \r\n",
        "# the words aren't very representative of English. \r\n",
        "\r\n",
        "# However, I would guess that for doubling words, the model would get more \r\n",
        "# perplexed towards the end of the word as well, when the doubling occurs, \r\n",
        "# as doubling is not expected. I'm not sure how the non-words without doubling\r\n",
        "# will perform. They may have higher perpelxity than the actual English words,\r\n",
        "# but lower than the non-words with doubling. "
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hTJdNIV-vGv"
      },
      "source": [
        "Evaluate the model using non-words that have doubling. We would predict that the perplexity of these words would be higher than those that do not have doubling. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lK0eb2ztB0W"
      },
      "source": [
        "# test doubling words\r\n",
        "\r\n",
        "model.load_state_dict(torch.load(train_state['model_filename']))\r\n",
        "\r\n",
        "model = model.to(args.device)\r\n",
        "\r\n",
        "dataset.set_split('doubling')\r\n",
        "batch_generator = generate_batches(dataset, \r\n",
        "                                   batch_size=1, # we change the batch size to 1, since we don't have many words we are working with\r\n",
        "                                   device=args.device)\r\n",
        "\r\n",
        "\r\n",
        "running_acc = 0.\r\n",
        "model.eval()\r\n",
        "\r\n",
        "word_perplexities_doubling = {} # maps words --> perplexity values\r\n",
        "position_perplexities_doubling = {} # maps char positions --> perplexity values\r\n",
        "\r\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\r\n",
        "\r\n",
        "    # compute the output\r\n",
        "    y_pred = model(x_in=batch_dict['x_data'])\r\n",
        "\r\n",
        "    # initialize dictionary\r\n",
        "    word_perplexities_doubling[batch_index] = {}\r\n",
        "    position_perplexities_doubling[batch_index] = {}\r\n",
        "\r\n",
        "    # iterate over each word in the batch, and calculate the loss for that word\r\n",
        "    # save perplexity to dict\r\n",
        "    start = 0\r\n",
        "    end = 1\r\n",
        "    for i in range(1):\r\n",
        "        word_loss = sequence_loss(y_pred[start:end,:],batch_dict['y_target'][start:end,:], mask_index)\r\n",
        "\r\n",
        "        # reconstruct the word and get perplexity at each char position\r\n",
        "        word = \"\"\r\n",
        "        start_pos = 0\r\n",
        "        end_pos = 1\r\n",
        "        for j in range(34):\r\n",
        "            curr_char_index = batch_dict['y_target'][i][j].item()\r\n",
        "            if curr_char_index >= 4:\r\n",
        "                curr_char = vectorizer.char_vocab._idx_to_token[curr_char_index]\r\n",
        "                word += curr_char\r\n",
        "\r\n",
        "            position_loss = sequence_loss(y_pred[:, start_pos:end_pos],batch_dict['y_target'][:, start_pos:end_pos], mask_index)\r\n",
        "            position_pp = math.pow(2,position_loss)\r\n",
        "            position_perplexities_doubling[batch_index][j] = position_pp\r\n",
        "            start_pos += 1\r\n",
        "            end_pos += 1\r\n",
        "\r\n",
        "        pp = math.pow(2,word_loss)\r\n",
        "        word_perplexities_doubling[batch_index][word] = pp\r\n",
        "\r\n",
        "        start += 1\r\n",
        "        end += 1\r\n",
        "\r\n",
        "    # compute the loss\r\n",
        "    loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\r\n",
        "\r\n",
        "    # compute the accuracy\r\n",
        "    running_loss += (loss.item() - running_loss) / (batch_index + 1)\r\n",
        "\r\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\r\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\r\n",
        "\r\n",
        "train_state['test_loss'] = running_loss \r\n",
        "train_state['test_acc'] = running_acc"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnXu7uyH9a60",
        "outputId": "40ba67a2-e8d1-4627-e116-d7faf1d0033a"
      },
      "source": [
        "# print the loss, perplexity, and accuracy for the doubling set overall\r\n",
        "print(\"Test loss: {};\".format(train_state['test_loss']))\r\n",
        "print(\"Test perplexity: {};\".format(math.pow(2,train_state['test_loss'])))\r\n",
        "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 2.649598360061647;\n",
            "Test perplexity: 6.274925628357221;\n",
            "Test Accuracy: 21.071428571428577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS8YDxwL9ASu",
        "outputId": "8bcceebc-61ef-46fe-9889-ca18490aa955"
      },
      "source": [
        "# Print the perplexities for each word\r\n",
        "for b, w_dict in word_perplexities_doubling.items():\r\n",
        "    for w, p in w_dict.items():\r\n",
        "        print(\"word: \", w, \" perplexity: \", round(p,2))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word:  flamlam  perplexity:  5.65\n",
            "word:  premrem  perplexity:  5.45\n",
            "word:  drakrak  perplexity:  8.89\n",
            "word:  tramram  perplexity:  5.61\n",
            "word:  franran  perplexity:  5.4\n",
            "word:  grofrof  perplexity:  6.61\n",
            "word:  smatmat  perplexity:  5.47\n",
            "word:  grefref  perplexity:  6.75\n",
            "word:  dranran  perplexity:  5.07\n",
            "word:  trosros  perplexity:  5.52\n",
            "word:  snognog  perplexity:  6.5\n",
            "word:  frebreb  perplexity:  6.61\n",
            "word:  fliblib  perplexity:  6.52\n",
            "word:  granran  perplexity:  4.96\n",
            "word:  blaslas  perplexity:  4.9\n",
            "word:  blaflaf  perplexity:  6.55\n",
            "word:  prafraf  perplexity:  5.63\n",
            "word:  kragrag  perplexity:  7.98\n",
            "word:  flaklak  perplexity:  7.17\n",
            "word:  kravrav  perplexity:  7.84\n",
            "word:  smolmol  perplexity:  7.73\n",
            "word:  plonlon  perplexity:  5.45\n",
            "word:  trelrel  perplexity:  5.43\n",
            "word:  slodlod  perplexity:  6.07\n",
            "word:  snadnad  perplexity:  7.78\n",
            "word:  drofrof  perplexity:  7.6\n",
            "word:  frosros  perplexity:  5.2\n",
            "word:  stimtim  perplexity:  7.54\n",
            "word:  klenlen  perplexity:  5.97\n",
            "word:  kloplop  perplexity:  8.74\n",
            "word:  blatlat  perplexity:  5.26\n",
            "word:  trafraf  perplexity:  6.22\n",
            "word:  slanlan  perplexity:  5.98\n",
            "word:  flonlon  perplexity:  5.95\n",
            "word:  plaflaf  perplexity:  6.59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-57V3aYEd_o",
        "outputId": "b36f88d1-a5bc-44b0-dd29-5d9dd97dc540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "# get the perpelxity at each character position (averaged over each doubling word)\r\n",
        "avgs_doubling = {}\r\n",
        "for batch, char_dict in position_perplexities_doubling.items():\r\n",
        "    for ch, p in char_dict.items():\r\n",
        "        if avgs_doubling.get(ch):\r\n",
        "            avgs_doubling[ch] += p\r\n",
        "        else:\r\n",
        "            avgs_doubling[ch] = p\r\n",
        "avgs_doubling = {k: v / 19 for k, v in avgs_doubling.items()}\r\n",
        "\r\n",
        "# plot\r\n",
        "df_doubling = pd.DataFrame(list(avgs_doubling.items()), columns=['Character Positions', 'doubling']) \r\n",
        "plt.bar(df_doubling['Character Positions'], df_doubling['doubling'], color='purple', width=0.5)\r\n",
        "plt.title('Doubling words')\r\n",
        "plt.xlabel('Character positions')\r\n",
        "plt.ylabel('Avg. perplexities')\r\n",
        "plt.xlim(0,6)\r\n",
        "plt.xticks(np.arange(0, 6, 1))\r\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 4)\r\n",
        "plt.show()\r\n",
        "print('\\n')\r\n",
        "\r\n",
        "# Each word should have high perplexity in the begining, because the more \r\n",
        "# observations that a model sees, the less \"perlexed\" it will be, and it has\r\n",
        "# observed little in the beginning of the word. However, I would guess that\r\n",
        "# for doubling words, the model would get more perplexed towards the end\r\n",
        "# of the word as well, when the doubling occurs, as that is not expected.\r\n",
        "# On the other hand, I would expect perplexity to go down later in the word\r\n",
        "# for words without doubling. "
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOaS7UAY_DZT"
      },
      "source": [
        "Evaluate the model using non-words that do not have doubling. The perplexity of these words should be similar to that of actual English words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkEfde5M9ng1"
      },
      "source": [
        "# test control words (non-words, no doubling)\r\n",
        "\r\n",
        "model.load_state_dict(torch.load(train_state['model_filename']))\r\n",
        "\r\n",
        "model = model.to(args.device)\r\n",
        "\r\n",
        "dataset.set_split('no_doubling')\r\n",
        "batch_generator = generate_batches(dataset, \r\n",
        "                                   batch_size=1, # we change the batch size to 1, since we don't have many words we are working with\r\n",
        "                                   device=args.device)\r\n",
        "\r\n",
        "\r\n",
        "running_acc = 0.\r\n",
        "model.eval()\r\n",
        "\r\n",
        "word_perplexities_control = {} # maps words --> perplexity values\r\n",
        "position_perplexities_control = {}\r\n",
        "\r\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\r\n",
        "\r\n",
        "    # compute the output\r\n",
        "    y_pred = model(x_in=batch_dict['x_data'])\r\n",
        "\r\n",
        "    # initialize dictionary\r\n",
        "    word_perplexities_control[batch_index] = {}\r\n",
        "    position_perplexities_control[batch_index] = {}\r\n",
        "\r\n",
        "    # iterate over each word in the batch, and calculate the loss for that word\r\n",
        "    # save perplexity to dict\r\n",
        "    start = 0\r\n",
        "    end = 1\r\n",
        "    for i in range(1):\r\n",
        "        word_loss = sequence_loss(y_pred[start:end,:],batch_dict['y_target'][start:end,:], mask_index)\r\n",
        "\r\n",
        "        # reconstruct the word and pp at each char posiiton\r\n",
        "        word = \"\"\r\n",
        "        start_pos = 0\r\n",
        "        end_pos = 1\r\n",
        "        for j in range(34):\r\n",
        "            curr_char_index = batch_dict['y_target'][i][j].item()\r\n",
        "            if curr_char_index >= 4:\r\n",
        "                curr_char = vectorizer.char_vocab._idx_to_token[curr_char_index]\r\n",
        "                word += curr_char\r\n",
        "\r\n",
        "            position_loss = sequence_loss(y_pred[:, start_pos:end_pos],batch_dict['y_target'][:, start_pos:end_pos], mask_index)\r\n",
        "            position_pp = math.pow(2,position_loss)\r\n",
        "            position_perplexities_control[batch_index][j] = position_pp\r\n",
        "            start_pos += 1\r\n",
        "            end_pos += 1\r\n",
        "\r\n",
        "        pp = math.pow(2,word_loss)\r\n",
        "        word_perplexities_control[batch_index][word] = pp\r\n",
        "\r\n",
        "        start += 1\r\n",
        "        end += 1\r\n",
        "\r\n",
        "    # compute the loss\r\n",
        "    loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\r\n",
        "\r\n",
        "    # compute the accuracy\r\n",
        "    running_loss += (loss.item() - running_loss) / (batch_index + 1)\r\n",
        "\r\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\r\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\r\n",
        "\r\n",
        "train_state['test_loss'] = running_loss \r\n",
        "train_state['test_acc'] = running_acc"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n6ON6wp9uCd",
        "outputId": "ba3e56f5-3bf9-4d5d-e68e-6d06acdd2c9c"
      },
      "source": [
        "# print the loss, perplexity, and accuracy for the doubling set overall\r\n",
        "print(\"Test loss: {};\".format(train_state['test_loss']))\r\n",
        "print(\"Test perplexity: {};\".format(math.pow(2,train_state['test_loss'])))\r\n",
        "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 2.684738186427525;\n",
            "Test perplexity: 6.429640998780444;\n",
            "Test Accuracy: 18.134920634920633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McjjRGs09uO2",
        "outputId": "09e16a6a-9a6a-49b0-f65c-fb96a8affd0a"
      },
      "source": [
        "# print the perplexities for each word\r\n",
        "for b, w_dict in word_perplexities_control.items():\r\n",
        "    for w, p in w_dict.items():\r\n",
        "        print(\"word: \", w, \" perplexity: \", round(p,2))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word:  blatnog  perplexity:  6.85\n",
            "word:  klennmof  perplexity:  9.3\n",
            "word:  traflam  perplexity:  5.25\n",
            "word:  plonmuk  perplexity:  8.32\n",
            "word:  plafnut  perplexity:  7.12\n",
            "word:  snogmot  perplexity:  7.56\n",
            "word:  trosnot  perplexity:  5.79\n",
            "word:  smolrog  perplexity:  7.25\n",
            "word:  franmet  perplexity:  5.42\n",
            "word:  flakmal  perplexity:  6.38\n",
            "word:  slanmot  perplexity:  5.78\n",
            "word:  praflak  perplexity:  5.75\n",
            "word:  flamrad  perplexity:  5.79\n",
            "word:  klopnosh  perplexity:  6.85\n",
            "word:  blafron  perplexity:  5.71\n",
            "word:  flibnep  perplexity:  6.43\n",
            "word:  snadmak  perplexity:  7.64\n",
            "word:  smatnod  perplexity:  5.96\n",
            "word:  flonmog  perplexity:  7.59\n",
            "word:  kravmal  perplexity:  6.38\n",
            "word:  slodmog  perplexity:  6.67\n",
            "word:  freblek  perplexity:  5.18\n",
            "word:  granlat  perplexity:  5.01\n",
            "word:  stimkam  perplexity:  6.96\n",
            "word:  froslak  perplexity:  6.7\n",
            "word:  dranlat  perplexity:  5.81\n",
            "word:  draknad  perplexity:  6.59\n",
            "word:  droffmok  perplexity:  7.62\n",
            "word:  greflek  perplexity:  6.11\n",
            "word:  grofnom  perplexity:  6.74\n",
            "word:  trelnat  perplexity:  6.4\n",
            "word:  premlek  perplexity:  5.44\n",
            "word:  tramlut  perplexity:  5.25\n",
            "word:  blasnol  perplexity:  7.4\n",
            "word:  kragnel  perplexity:  6.34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUnMeF-gGFOG",
        "outputId": "9be7f2ba-70f8-4af6-d2c5-614af37f1d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "# get the perpelxity at each character position (averaged over each non-doubling word)\r\n",
        "avgs_control = {}\r\n",
        "for batch, char_dict in position_perplexities_control.items():\r\n",
        "    for ch, p in char_dict.items():\r\n",
        "        if avgs_control.get(ch):\r\n",
        "            avgs_control[ch] += p\r\n",
        "        else:\r\n",
        "            avgs_control[ch] = p\r\n",
        "avgs_control = {k: v / 19 for k, v in avgs_control.items()}\r\n",
        "\r\n",
        "# plot\r\n",
        "df_control = pd.DataFrame(list(avgs_control.items()), columns=['Character Positions', 'control']) \r\n",
        "plt.bar(df_control['Character Positions'], df_control['control'], color='purple', width=0.5)\r\n",
        "plt.title('Control non-words')\r\n",
        "plt.xlabel('Character positions')\r\n",
        "plt.ylabel('Avg. perplexities')\r\n",
        "plt.xlim(0,6)\r\n",
        "plt.xticks(np.arange(0, 6, 1))\r\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 4)\r\n",
        "plt.show()\r\n",
        "print('\\n')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLuqxq9iKGSg",
        "outputId": "06390d14-ca17-4b4c-f5ac-c00714fec053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# plot English test words, doubling non-words, and control non-words together\r\n",
        "# combined plot\r\n",
        "df_doubling_pp = df_doubling[\"doubling\"]\r\n",
        "df_control_pp = df_control[\"control\"]\r\n",
        "all_data = df.join(df_doubling_pp)\r\n",
        "all_data = all_data.join(df_control_pp)\r\n",
        "plt.plot(all_data[\"English\"], label='English', color=\"purple\")\r\n",
        "plt.plot(all_data[\"doubling\"], label='Doubling non-words', color=\"orange\")\r\n",
        "plt.plot(all_data[\"control\"], label='Control non-words', color=\"green\")\r\n",
        "plt.title('Perplexity by character position')\r\n",
        "plt.xlabel('Character positions')\r\n",
        "plt.ylabel('Avg. perplexities')\r\n",
        "plt.legend()\r\n",
        "plt.xticks(np.arange(0, 18, 1))\r\n",
        "plt.show()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE7UzCKe-0jT"
      },
      "source": [
        "# Generate new words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF2dX7qQ_LpN"
      },
      "source": [
        "We can have the model generate words, and count the words that have doubling in them (a model that has learned English well, would not have many words with doubling?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPgUqGDF-yZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "505e6738-f1c0-4fda-a043-75b1e5eb423d"
      },
      "source": [
        "# number of names to generate\r\n",
        "num_words = 20\r\n",
        "model = model.cpu()\r\n",
        "# Generate nationality hidden state\r\n",
        "sampled_words = decode_samples(\r\n",
        "    sample_from_model(model, vectorizer, num_samples=num_words), \r\n",
        "    vectorizer)\r\n",
        "# Show results\r\n",
        "print (\"-\"*15)\r\n",
        "for i in range(num_words):\r\n",
        "    print (sampled_words[i])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------\n",
            "sha\n",
            "de\n",
            "tenilga\n",
            "ghaseinn\n",
            "buidecky\n",
            "ffed\n",
            "faunaveton\n",
            "gcmovne\n",
            "foly\n",
            "reiten\n",
            "capogos\n",
            "tafl\n",
            "at\n",
            "oleauna\n",
            "mcnni\n",
            "dharnan\n",
            "riabou\n",
            "ulodevan\n",
            "poleoli\n",
            "iras\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}