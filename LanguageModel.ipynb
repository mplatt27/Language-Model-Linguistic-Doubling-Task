{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelEvaluation.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/mplatt27/Language-Model-Linguistic-Doubling-Task/blob/main/LanguageModel.ipynb",
      "authorship_tag": "ABX9TyOxnRmD2Urjh+/tiPnm9gYB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5137cda4993449c7be3282d133a2ce82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_67c7f300e9d840c8bcbe20e1849d8870",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b76120fa975545c284c88217e1184161",
              "IPY_MODEL_2e2863c957954eeba82384bbffa4f8ad"
            ]
          }
        },
        "67c7f300e9d840c8bcbe20e1849d8870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b76120fa975545c284c88217e1184161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dab3832c68bb4805bcedc789ae2236b0",
            "_dom_classes": [],
            "description": "training routine: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0bf9f6087b254dac9db10ef8a6cdf632"
          }
        },
        "2e2863c957954eeba82384bbffa4f8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_942804f348cd4876b2ec0cb95ac71906",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [05:36&lt;00:00,  3.36s/it, sample1=bacy, sample2=nexers]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d7e4f38fe134e09a155c69e30169842"
          }
        },
        "dab3832c68bb4805bcedc789ae2236b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0bf9f6087b254dac9db10ef8a6cdf632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "942804f348cd4876b2ec0cb95ac71906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d7e4f38fe134e09a155c69e30169842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef913c8d12454cea83b42f65ef818fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6a956f114e3c4114934e96da40e62394",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_585b58298c89498ab44daaabd0f108ab",
              "IPY_MODEL_0eec7d7a16384b1ca4bfee98c835cf24"
            ]
          }
        },
        "6a956f114e3c4114934e96da40e62394": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "585b58298c89498ab44daaabd0f108ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0ff260e4e2394082acfb9d747c8749ad",
            "_dom_classes": [],
            "description": "split=train:  98%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 59,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 58,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_79135d3dd5c1471cab00ba9be05ab19d"
          }
        },
        "0eec7d7a16384b1ca4bfee98c835cf24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4b0754603c854127b5c333953660a4ae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 58/59 [05:36&lt;00:06,  6.14s/it, acc=25.7, epoch=99, loss=2.45]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0555eab380b54acf8bba164f0a498596"
          }
        },
        "0ff260e4e2394082acfb9d747c8749ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "79135d3dd5c1471cab00ba9be05ab19d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b0754603c854127b5c333953660a4ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0555eab380b54acf8bba164f0a498596": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f92d4c7ff68241e8ad4b4b5b5ebeb708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_686d0ee29c354b92bc975bd8df93cba1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2cb07872eb49417eb1388767d2b5e5ba",
              "IPY_MODEL_952f6eef0cb44daaa213230336ad97f3"
            ]
          }
        },
        "686d0ee29c354b92bc975bd8df93cba1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2cb07872eb49417eb1388767d2b5e5ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4996efea89b54d8ba239bb44623ba2de",
            "_dom_classes": [],
            "description": "split=val:  89%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 9,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18cd81e9871b4893b943343ae50f820e"
          }
        },
        "952f6eef0cb44daaa213230336ad97f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e1d1c917efa41f1855c716ba7b44c04",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8/9 [05:36&lt;00:01,  1.10s/it, acc=26.4, epoch=99, loss=2.45]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_023282075364412486c473fb09d8d312"
          }
        },
        "4996efea89b54d8ba239bb44623ba2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18cd81e9871b4893b943343ae50f820e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e1d1c917efa41f1855c716ba7b44c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "023282075364412486c473fb09d8d312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mplatt27/Language-Model-Linguistic-Doubling-Task/blob/main/LanguageModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bymBLatcwZz_"
      },
      "source": [
        "# Character-level English Language Model\n",
        "\n",
        "*Langauge and Mind Lab*\n",
        "\n",
        "\n",
        "All code is adapted from the book: Natural Language Processing with PyTorch: Build Intelligent Language Applications Using Deep Learning, by Delip Rao and Brian McMahan. The original code is available here: https://github.com/joosthub/PyTorchNLPBook. \n",
        "\n",
        "The model uses a Gated Recurrent Unit (GRU) neural network and is trained on a set of ### English words from \"\". We then evaluate the model with a test set of novel words that both have and do not have linguistic doubling, to determine if the model has learned preferences that are observed in English speakers. We can also generate novel words and look for features like linguistic doubling. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWHsiuY6nUsY"
      },
      "source": [
        "Notes on dataset:\n",
        "\n",
        "*   Retrieved from https://www.kaggle.com/rtatman/english-word-frequency and contains 333,333 unique words.\n",
        "*   I first shuffled the words in the spreadsheet, then took the first ~10,000 words to use (the original code uses a smaller dataset around this size, so as a first attempt on this project, I used a shortened version of the word dataset). We can increase this size later if we want\n",
        "*   I then labeled approximatley 70% as the training set, 15% as the validation set, and 15% as the test set. The test set will be used as a proof of concept to see how the model does with words that are true English words that the model has never seen before. \n",
        "*   I then added to the data set, ~30 \"slaflaf\" words that I found (they may not be the more recent versions) both with doubling and the control matched pair without doubling (i.e., \"slafmat\").\n",
        "*   Looking over the English words in the dataset in detail, I'm not sure this is what we want to use for the final version, as many words are strange and something I have never seen before. We can keep searching, but this at least shows us that the code works and we can replace the dataset as long as it is in the same format.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpfKJcY39nvZ"
      },
      "source": [
        "# Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuIZa6uj9oAC"
      },
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6n06uyV9vDy"
      },
      "source": [
        "# Data Vectorization classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woqkA8VU9tc0"
      },
      "source": [
        "class Vocabulary(object):\n",
        "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
        "\n",
        "    def __init__(self, token_to_idx=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
        "        \"\"\"\n",
        "\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self._token_to_idx = token_to_idx\n",
        "\n",
        "        self._idx_to_token = {idx: token \n",
        "                              for token, idx in self._token_to_idx.items()}\n",
        "        \n",
        "    def to_serializable(self):\n",
        "        \"\"\" returns a dictionary that can be serialized \"\"\"\n",
        "        return {'token_to_idx': self._token_to_idx}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        \"\"\"Update mapping dicts based on the token.\n",
        "\n",
        "        Args:\n",
        "            token (str): the item to add into the Vocabulary\n",
        "        Returns:\n",
        "            index (int): the integer corresponding to the token\n",
        "        \"\"\"\n",
        "        if token in self._token_to_idx:\n",
        "            index = self._token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self._token_to_idx)\n",
        "            self._token_to_idx[token] = index\n",
        "            self._idx_to_token[index] = token\n",
        "        return index\n",
        "            \n",
        "    def add_many(self, tokens):\n",
        "        \"\"\"Add a list of tokens into the Vocabulary\n",
        "        \n",
        "        Args:\n",
        "            tokens (list): a list of string tokens\n",
        "        Returns:\n",
        "            indices (list): a list of indices corresponding to the tokens\n",
        "        \"\"\"\n",
        "        return [self.add_token(token) for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"Retrieve the index associated with the token \n",
        "        \n",
        "        Args:\n",
        "            token (str): the token to look up \n",
        "        Returns:\n",
        "            index (int): the index corresponding to the token\n",
        "        \"\"\"\n",
        "        return self._token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        \"\"\"Return the token associated with the index\n",
        "        \n",
        "        Args: \n",
        "            index (int): the index to look up\n",
        "        Returns:\n",
        "            token (str): the token corresponding to the index\n",
        "        Raises:\n",
        "            KeyError: if the index is not in the Vocabulary\n",
        "        \"\"\"\n",
        "        if index not in self._idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self._idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._token_to_idx)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbYTG8LH9z5m"
      },
      "source": [
        "class SequenceVocabulary(Vocabulary):\n",
        "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
        "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
        "                 end_seq_token=\"<END>\"):\n",
        "\n",
        "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
        "\n",
        "        self._mask_token = mask_token\n",
        "        self._unk_token = unk_token\n",
        "        self._begin_seq_token = begin_seq_token\n",
        "        self._end_seq_token = end_seq_token\n",
        "\n",
        "        self.mask_index = self.add_token(self._mask_token)\n",
        "        self.unk_index = self.add_token(self._unk_token)\n",
        "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
        "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        contents = super(SequenceVocabulary, self).to_serializable()\n",
        "        contents.update({'unk_token': self._unk_token,\n",
        "                         'mask_token': self._mask_token,\n",
        "                         'begin_seq_token': self._begin_seq_token,\n",
        "                         'end_seq_token': self._end_seq_token})\n",
        "        return contents\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"Retrieve the index associated with the token \n",
        "          or the UNK index if token isn't present.\n",
        "        \n",
        "        Args:\n",
        "            token (str): the token to look up \n",
        "        Returns:\n",
        "            index (int): the index corresponding to the token\n",
        "        Notes:\n",
        "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
        "              for the UNK functionality \n",
        "        \"\"\"\n",
        "        if self.unk_index >= 0:\n",
        "            return self._token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            return self._token_to_idx[token]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRDY-lT992oJ"
      },
      "source": [
        "# Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liiGfSkL94h9"
      },
      "source": [
        "class WordVectorizer(object):\n",
        "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"    \n",
        "    def __init__(self, char_vocab, classification_vocab):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            char_vocab (Vocabulary): maps words to integers\n",
        "            classification_vocab (Vocabulary): maps classes to integers\n",
        "        \"\"\"\n",
        "        self.char_vocab = char_vocab\n",
        "        self.classification_vocab = classification_vocab\n",
        "\n",
        "    def vectorize(self, word, vector_length=-1):\n",
        "        \"\"\"Vectorize a word into a vector of observations and targets\n",
        "        \n",
        "        The outputs are the vectorized word split into two vectors:\n",
        "            word[:-1] and word[1:]\n",
        "        At each timestep, the first vector is the observation and the second vector is the target. \n",
        "        \n",
        "        Args:\n",
        "            word (str): the word to be vectorized\n",
        "            vector_length (int): an argument for forcing the length of index vector\n",
        "        Returns:\n",
        "            a tuple: (from_vector, to_vector)\n",
        "            from_vector (numpy.ndarray): the observation vector \n",
        "            to_vector (numpy.ndarray): the target prediction vector\n",
        "        \"\"\"\n",
        "        indices = [self.char_vocab.begin_seq_index] \n",
        "        indices.extend(self.char_vocab.lookup_token(token) for token in word)\n",
        "        indices.append(self.char_vocab.end_seq_index)\n",
        "\n",
        "        if vector_length < 0:\n",
        "            vector_length = len(indices) - 1\n",
        "\n",
        "        from_vector = np.empty(vector_length, dtype=np.int64)         \n",
        "        from_indices = indices[:-1]\n",
        "        from_vector[:len(from_indices)] = from_indices\n",
        "        from_vector[len(from_indices):] = self.char_vocab.mask_index\n",
        "\n",
        "        to_vector = np.empty(vector_length, dtype=np.int64)\n",
        "        to_indices = indices[1:]\n",
        "        to_vector[:len(to_indices)] = to_indices\n",
        "        to_vector[len(to_indices):] = self.char_vocab.mask_index\n",
        "        \n",
        "        return from_vector, to_vector\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, word_df):\n",
        "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
        "        \n",
        "        Args:\n",
        "            word_df (pandas.DataFrame): the word dataset\n",
        "        Returns:\n",
        "            an instance of the WordVectorizer\n",
        "        \"\"\"\n",
        "        char_vocab = SequenceVocabulary()\n",
        "        classification_vocab = Vocabulary()\n",
        "\n",
        "        for index, row in word_df.iterrows():\n",
        "            for char in row.word:\n",
        "                char_vocab.add_token(char)\n",
        "            classification_vocab.add_token(row.classification)\n",
        "\n",
        "        return cls(char_vocab, classification_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\"Instantiate the vectorizer from saved contents\n",
        "        \n",
        "        Args:\n",
        "            contents (dict): a dict holding two vocabularies for this vectorizer\n",
        "                This dictionary is created using `vectorizer.to_serializable()`\n",
        "        Returns:\n",
        "            an instance of WordVectorizer\n",
        "        \"\"\"\n",
        "        char_vocab = SequenceVocabulary.from_serializable(contents['char_vocab'])\n",
        "        class_vocab =  Vocabulary.from_serializable(contents['classification_vocab'])\n",
        "\n",
        "        return cls(char_vocab=char_vocab, classification_vocab=nat_vocab)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        \"\"\" Returns the serializable contents \"\"\"\n",
        "        return {'char_vocab': self.char_vocab.to_serializable(), \n",
        "                'classification_vocab': self.classification_vocab.to_serializable()}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlu4nKW696x8"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo824x6m98cd"
      },
      "source": [
        "class WordDataset(Dataset):\n",
        "    def __init__(self, word_df, vectorizer):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            word_df (pandas.DataFrame): the dataset\n",
        "            vectorizer (WordVectorizer): vectorizer instatiated from dataset\n",
        "        \"\"\"\n",
        "        self.word_df = word_df \n",
        "        self._vectorizer = vectorizer\n",
        "\n",
        "        self._max_seq_length = max(map(len, self.word_df.word)) + 2\n",
        "\n",
        "        self.train_df = self.word_df[self.word_df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.word_df[self.word_df.split=='val']\n",
        "        self.validation_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.word_df[self.word_df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "\n",
        "        # ADDED:\n",
        "        # -----------------------------------------------------------------\n",
        "        self.doubling_df = self.word_df[self.word_df.split=='doubling']\n",
        "        self.doubling_size = len(self.doubling_df)\n",
        "\n",
        "        self.nodoubling_df = self.word_df[self.word_df.split=='no_doubling']\n",
        "        self.nodoubling_size = len(self.nodoubling_df)\n",
        "\n",
        "\n",
        "        # -----------------------------------------------------------------\n",
        "\n",
        "        self._lookup_dict = {'train': (self.train_df, self.train_size), \n",
        "                             'val': (self.val_df, self.validation_size), \n",
        "                             'test': (self.test_df, self.test_size),\n",
        "                             'doubling': (self.doubling_df, self.doubling_size), # ADDED\n",
        "                             'no_doubling': (self.nodoubling_df, self.nodoubling_size)} # ADDED\n",
        "\n",
        "        self.set_split('train')\n",
        "        \n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, word_csv):\n",
        "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
        "        \n",
        "        Args:\n",
        "            word_csv (str): location of the dataset\n",
        "        Returns:\n",
        "            an instance of WordDataset\n",
        "        \"\"\"\n",
        "        \n",
        "        word_df = pd.read_csv(word_csv, encoding='latin-1')\n",
        "        return cls(word_df, WordVectorizer.from_dataframe(word_df))\n",
        "        \n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, word_csv, vectorizer_filepath):\n",
        "        \"\"\"Load dataset and the corresponding vectorizer. \n",
        "        Used in the case in the vectorizer has been cached for re-use\n",
        "        \n",
        "        Args:\n",
        "            word_csv (str): location of the dataset\n",
        "            vectorizer_filepath (str): location of the saved vectorizer\n",
        "        Returns:\n",
        "            an instance of WordDataset\n",
        "        \"\"\"\n",
        "        word_df = pd.read_csv(word_csv, encoding='latin-1') # changed coding here\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(word_df, vectorizer)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        \"\"\"a static method for loading the vectorizer from file\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location of the serialized vectorizer\n",
        "        Returns:\n",
        "            an instance of WordVectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return WordVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        \"\"\"saves the vectorizer to disk using json\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location to save the vectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self._vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def get_vectorizer(self):\n",
        "        \"\"\" returns the vectorizer \"\"\"\n",
        "        return self._vectorizer\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        self._target_split = split\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"the primary entry point method for PyTorch datasets\n",
        "        \n",
        "        Args:\n",
        "            index (int): the index to the data point \n",
        "        Returns:\n",
        "            a dictionary holding the data point: (x_data, y_target, class_index)\n",
        "        \"\"\"\n",
        "        row = self._target_df.iloc[index]\n",
        "        \n",
        "        from_vector, to_vector = \\\n",
        "            self._vectorizer.vectorize(row.word, self._max_seq_length)\n",
        "        \n",
        "        classification_index = \\\n",
        "            self._vectorizer.classification_vocab.lookup_token(row.classification)\n",
        "\n",
        "        return {'x_data': from_vector, \n",
        "                'y_target': to_vector, \n",
        "                'class_index': classification_index}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
        "        \n",
        "        Args:\n",
        "            batch_size (int)\n",
        "        Returns:\n",
        "            number of batches in the dataset\n",
        "        \"\"\"\n",
        "        return len(self) // batch_size\n",
        "    \n",
        "def generate_batches(dataset, batch_size, shuffle=True,\n",
        "                     drop_last=True, device=\"cpu\"): \n",
        "    \"\"\"\n",
        "    A generator function which wraps the PyTorch DataLoader. It will \n",
        "      ensure each tensor is on the write device location.\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last)\n",
        "\n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        for name, tensor in data_dict.items():\n",
        "            out_data_dict[name] = data_dict[name].to(device)\n",
        "        yield out_data_dict"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcCvBM1j9_xY"
      },
      "source": [
        "# Word Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w33KikSE-BXG"
      },
      "source": [
        "class WordGenerationModel(nn.Module):\n",
        "    def __init__(self, char_embedding_size, char_vocab_size, rnn_hidden_size, \n",
        "                 batch_first=True, padding_idx=0, dropout_p=0.5):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            char_embedding_size (int): The size of the character embeddings\n",
        "            char_vocab_size (int): The number of characters to embed\n",
        "            rnn_hidden_size (int): The size of the RNN's hidden state\n",
        "            batch_first (bool): Informs whether the input tensors will \n",
        "                have batch or the sequence on the 0th dimension\n",
        "            padding_idx (int): The index for the tensor padding; \n",
        "                see torch.nn.Embedding\n",
        "            dropout_p (float): the probability of zeroing activations using\n",
        "                the dropout method.  higher means more likely to zero.\n",
        "        \"\"\"\n",
        "        super(WordGenerationModel, self).__init__()\n",
        "        \n",
        "        self.char_emb = nn.Embedding(num_embeddings=char_vocab_size,\n",
        "                                     embedding_dim=char_embedding_size,\n",
        "                                     padding_idx=padding_idx)\n",
        "\n",
        "        self.rnn = nn.GRU(input_size=char_embedding_size, \n",
        "                          hidden_size=rnn_hidden_size,\n",
        "                          batch_first=batch_first)\n",
        "        \n",
        "        self.fc = nn.Linear(in_features=rnn_hidden_size, \n",
        "                            out_features=char_vocab_size)\n",
        "        \n",
        "        self._dropout_p = dropout_p\n",
        "\n",
        "    def forward(self, x_in, apply_softmax=False):\n",
        "        \"\"\"The forward pass of the model\n",
        "        \n",
        "        Args:\n",
        "            x_in (torch.Tensor): an input data tensor. \n",
        "                x_in.shape should be (batch, input_dim)\n",
        "            apply_softmax (bool): a flag for the softmax activation\n",
        "                should be false if used with the Cross Entropy losses\n",
        "        Returns:\n",
        "            the resulting tensor. tensor.shape should be (batch, char_vocab_size)\n",
        "        \"\"\"\n",
        "        x_embedded = self.char_emb(x_in)\n",
        "\n",
        "        y_out, _ = self.rnn(x_embedded)\n",
        "\n",
        "        batch_size, seq_size, feat_size = y_out.shape\n",
        "        y_out = y_out.contiguous().view(batch_size * seq_size, feat_size)\n",
        "\n",
        "        y_out = self.fc(F.dropout(y_out, p=self._dropout_p))\n",
        "                         \n",
        "        if apply_softmax:\n",
        "            y_out = F.softmax(y_out, dim=1)\n",
        "            \n",
        "        new_feat_size = y_out.shape[-1]\n",
        "        y_out = y_out.view(batch_size, seq_size, new_feat_size)\n",
        "            \n",
        "        return y_out"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGCoOA1M-JMg"
      },
      "source": [
        "def sample_from_model(model, vectorizer, num_samples=1, sample_size=20, \n",
        "                      temperature=1.0):\n",
        "    \"\"\"Sample a sequence of indices from the model\n",
        "    \n",
        "    Args:\n",
        "        model (WordGenerationModel): the trained model\n",
        "        vectorizer (WordVectorizer): the corresponding vectorizer\n",
        "        num_samples (int): the number of samples\n",
        "        sample_size (int): the max length of the samples\n",
        "        temperature (float): accentuates or flattens \n",
        "            the distribution. \n",
        "            0.0 < temperature < 1.0 will make it peakier. \n",
        "            temperature > 1.0 will make it more uniform\n",
        "    Returns:\n",
        "        indices (torch.Tensor): the matrix of indices; \n",
        "        shape = (num_samples, sample_size)\n",
        "    \"\"\"\n",
        "    begin_seq_index = [vectorizer.char_vocab.begin_seq_index \n",
        "                       for _ in range(num_samples)]\n",
        "    begin_seq_index = torch.tensor(begin_seq_index, \n",
        "                                   dtype=torch.int64).unsqueeze(dim=1)\n",
        "    indices = [begin_seq_index]\n",
        "    h_t = None\n",
        "    \n",
        "    for time_step in range(sample_size):\n",
        "        x_t = indices[time_step]\n",
        "        x_emb_t = model.char_emb(x_t)\n",
        "        rnn_out_t, h_t = model.rnn(x_emb_t, h_t)\n",
        "        prediction_vector = model.fc(rnn_out_t.squeeze(dim=1))\n",
        "        probability_vector = F.softmax(prediction_vector / temperature, dim=1)\n",
        "        indices.append(torch.multinomial(probability_vector, num_samples=1))\n",
        "    indices = torch.stack(indices).squeeze().permute(1, 0)\n",
        "    return indices\n",
        "\n",
        "def decode_samples(sampled_indices, vectorizer):\n",
        "    \"\"\"Transform indices into the string form of a word\n",
        "    \n",
        "    Args:\n",
        "        sampled_indices (torch.Tensor): the inidces from `sample_from_model`\n",
        "        vectorizer (WordVectorizer): the corresponding vectorizer\n",
        "    \"\"\"\n",
        "    decoded_words = []\n",
        "    vocab = vectorizer.char_vocab\n",
        "    \n",
        "    for sample_index in range(sampled_indices.shape[0]):\n",
        "        word = \"\"\n",
        "        for time_step in range(sampled_indices.shape[1]):\n",
        "            sample_item = sampled_indices[sample_index, time_step].item()\n",
        "            if sample_item == vocab.begin_seq_index:\n",
        "                continue\n",
        "            elif sample_item == vocab.end_seq_index:\n",
        "                break\n",
        "            else:\n",
        "                word += vocab.lookup_index(sample_item)\n",
        "        decoded_words.append(word)\n",
        "    return decoded_words"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQUIJdm7-M8y"
      },
      "source": [
        "# Training routine\n",
        "\n",
        "Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVhEaA5z-MBc"
      },
      "source": [
        "def make_train_state(args):\n",
        "    return {'stop_early': False,\n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'learning_rate': args.learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': args.model_state_file}\n",
        "\n",
        "def update_train_state(args, model, train_state):\n",
        "    \"\"\"Handle the training state updates.\n",
        "    Components:\n",
        "     - Early Stopping: Prevent overfitting.\n",
        "     - Model Checkpoint: Model is saved if the model is better\n",
        "    \n",
        "    :param args: main arguments\n",
        "    :param model: model to train\n",
        "    :param train_state: a dictionary representing the training state values\n",
        "    :returns:\n",
        "        a new train_state\n",
        "    \"\"\"\n",
        "\n",
        "    # Save one model at least\n",
        "    if train_state['epoch_index'] == 0:\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\n",
        "        train_state['stop_early'] = False\n",
        "\n",
        "    # Save model if performance improved\n",
        "    elif train_state['epoch_index'] >= 1:\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
        "         \n",
        "        # If loss worsened\n",
        "        if loss_t >= loss_tm1:\n",
        "            # Update step\n",
        "            train_state['early_stopping_step'] += 1\n",
        "        # Loss decreased\n",
        "        else:\n",
        "            # Save the best model\n",
        "            if loss_t < train_state['early_stopping_best_val']:\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\n",
        "                train_state['early_stopping_best_val'] = loss_t\n",
        "\n",
        "            # Reset early stopping step\n",
        "            train_state['early_stopping_step'] = 0\n",
        "\n",
        "        # Stop early ?\n",
        "        train_state['stop_early'] = \\\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
        "\n",
        "    return train_state\n",
        "\n",
        "def normalize_sizes(y_pred, y_true):\n",
        "    \"\"\"Normalize tensor sizes\n",
        "    \n",
        "    Args:\n",
        "        y_pred (torch.Tensor): the output of the model\n",
        "            If a 3-dimensional tensor, reshapes to a matrix\n",
        "        y_true (torch.Tensor): the target predictions\n",
        "            If a matrix, reshapes to be a vector\n",
        "    \"\"\"\n",
        "    if len(y_pred.size()) == 3:\n",
        "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
        "    if len(y_true.size()) == 2:\n",
        "        y_true = y_true.contiguous().view(-1)\n",
        "    return y_pred, y_true\n",
        "\n",
        "def compute_accuracy(y_pred, y_true, mask_index):\n",
        "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
        "\n",
        "    _, y_pred_indices = y_pred.max(dim=1)\n",
        "    \n",
        "    correct_indices = torch.eq(y_pred_indices, y_true).float()\n",
        "    valid_indices = torch.ne(y_true, mask_index).float()\n",
        "    \n",
        "    n_correct = (correct_indices * valid_indices).sum().item()\n",
        "    n_valid = valid_indices.sum().item()\n",
        "\n",
        "    return n_correct / n_valid * 100\n",
        "\n",
        "def sequence_loss(y_pred, y_true, mask_index):\n",
        "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
        "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ8oC67-XFq"
      },
      "source": [
        "Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPae1Ke1-UQj"
      },
      "source": [
        "def set_seed_everywhere(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gux7fTG7-Yau"
      },
      "source": [
        "Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZSQZzGocS2i",
        "outputId": "c80b24ae-7ca1-484b-b75e-aa8a5d7d8d08"
      },
      "source": [
        "# to access and save files on google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RnmkCGW-a9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "117fb93b-2eee-4939-a589-f33d58bed641"
      },
      "source": [
        "args = Namespace(\n",
        "    # Data and Path information\n",
        "    word_csv=\"/content/drive/MyDrive/Lang-and-Mind-Lab/words_doubling_unshuffled.csv\", # CHANGE THIS TO YOUR PATH\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir=\"/content/drive/MyDrive/Lang-and-Mind-Lab\", # CHANGE THIS TO YOUR PATH\n",
        "    # Model hyper parameters\n",
        "    char_embedding_size=32,\n",
        "    rnn_hidden_size=32,\n",
        "    # Training hyper parameters\n",
        "    seed=1337,\n",
        "    learning_rate=0.001,\n",
        "    batch_size=128,\n",
        "    num_epochs=100,\n",
        "    early_stopping_criteria=5,\n",
        "    # Runtime options\n",
        "    catch_keyboard_interrupt=True,\n",
        "    cuda=True,\n",
        "    expand_filepaths_to_save_dir=True,\n",
        "    reload_from_files=False, # change to true after first time running\n",
        ")\n",
        "\n",
        "if args.expand_filepaths_to_save_dir:\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\n",
        "                                        args.vectorizer_file)\n",
        "\n",
        "    args.model_state_file = os.path.join(args.save_dir,\n",
        "                                         args.model_state_file)\n",
        "    \n",
        "    print(\"Expanded filepaths: \")\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\n",
        "    print(\"\\t{}\".format(args.model_state_file))\n",
        "    \n",
        "    \n",
        "# Check CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "    \n",
        "print(\"Using CUDA: {}\".format(args.cuda))\n",
        "\n",
        "# Set seed for reproducibility\n",
        "set_seed_everywhere(args.seed, args.cuda)\n",
        "\n",
        "# handle dirs\n",
        "handle_dirs(args.save_dir)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expanded filepaths: \n",
            "\t/content/drive/MyDrive/Lang-and-Mind-Lab/vectorizer.json\n",
            "\t/content/drive/MyDrive/Lang-and-Mind-Lab/model.pth\n",
            "Using CUDA: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jntkz8JI-dh9"
      },
      "source": [
        "Initializations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEdeHSwz-gaD"
      },
      "source": [
        "if args.reload_from_files:\n",
        "    # training from a checkpoint\n",
        "    dataset = WordDataset.load_dataset_and_load_vectorizer(args.word_csv, args.vectorizer_file)\n",
        "else:\n",
        "    # create dataset and vectorizer\n",
        "    dataset = WordDataset.load_dataset_and_make_vectorizer(args.word_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "\n",
        "vectorizer = dataset.get_vectorizer()\n",
        "\n",
        "model = WordGenerationModel(char_embedding_size=args.char_embedding_size,\n",
        "                               char_vocab_size=len(vectorizer.char_vocab),\n",
        "                               rnn_hidden_size=args.rnn_hidden_size,\n",
        "                               padding_idx=vectorizer.char_vocab.mask_index)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHOKSXvE5A20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd7f32a-5ede-41e4-ef8d-57d69ef9a762"
      },
      "source": [
        "# this is useful later if we want to get the probability of a certain char\n",
        "vectorizer.char_vocab._idx_to_token"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '<MASK>',\n",
              " 1: '<UNK>',\n",
              " 2: '<BEGIN>',\n",
              " 3: '<END>',\n",
              " 4: 's',\n",
              " 5: 't',\n",
              " 6: 'a',\n",
              " 7: 'u',\n",
              " 8: 'e',\n",
              " 9: 'o',\n",
              " 10: 'h',\n",
              " 11: 'i',\n",
              " 12: 'b',\n",
              " 13: 'j',\n",
              " 14: 'd',\n",
              " 15: 'r',\n",
              " 16: 'p',\n",
              " 17: 'y',\n",
              " 18: 'c',\n",
              " 19: 'q',\n",
              " 20: 'n',\n",
              " 21: 'l',\n",
              " 22: 'g',\n",
              " 23: 'f',\n",
              " 24: 'k',\n",
              " 25: 'm',\n",
              " 26: 'w',\n",
              " 27: 'x',\n",
              " 28: 'v',\n",
              " 29: 'z',\n",
              " 30: 'T',\n",
              " 31: 'R',\n",
              " 32: 'U',\n",
              " 33: 'E',\n",
              " 34: 'F',\n",
              " 35: 'A',\n",
              " 36: 'L',\n",
              " 37: 'S'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhy4G1pV-kfI"
      },
      "source": [
        "Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO2IKw0K-iK7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230,
          "referenced_widgets": [
            "5137cda4993449c7be3282d133a2ce82",
            "67c7f300e9d840c8bcbe20e1849d8870",
            "b76120fa975545c284c88217e1184161",
            "2e2863c957954eeba82384bbffa4f8ad",
            "dab3832c68bb4805bcedc789ae2236b0",
            "0bf9f6087b254dac9db10ef8a6cdf632",
            "942804f348cd4876b2ec0cb95ac71906",
            "5d7e4f38fe134e09a155c69e30169842",
            "ef913c8d12454cea83b42f65ef818fb0",
            "6a956f114e3c4114934e96da40e62394",
            "585b58298c89498ab44daaabd0f108ab",
            "0eec7d7a16384b1ca4bfee98c835cf24",
            "0ff260e4e2394082acfb9d747c8749ad",
            "79135d3dd5c1471cab00ba9be05ab19d",
            "4b0754603c854127b5c333953660a4ae",
            "0555eab380b54acf8bba164f0a498596",
            "f92d4c7ff68241e8ad4b4b5b5ebeb708",
            "686d0ee29c354b92bc975bd8df93cba1",
            "2cb07872eb49417eb1388767d2b5e5ba",
            "952f6eef0cb44daaa213230336ad97f3",
            "4996efea89b54d8ba239bb44623ba2de",
            "18cd81e9871b4893b943343ae50f820e",
            "1e1d1c917efa41f1855c716ba7b44c04",
            "023282075364412486c473fb09d8d312"
          ]
        },
        "outputId": "b65dd5ff-d41a-4274-84b1-a22bfeb1a3ae"
      },
      "source": [
        "mask_index = vectorizer.char_vocab.mask_index\n",
        "\n",
        "model = model.to(args.device)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                           mode='min', factor=0.5,\n",
        "                                           patience=1)\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm_notebook(desc='training routine', \n",
        "                          total=args.num_epochs,\n",
        "                          position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm_notebook(desc='split=train',\n",
        "                          total=dataset.get_num_batches(args.batch_size), \n",
        "                          position=1, \n",
        "                          leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm_notebook(desc='split=val',\n",
        "                        total=dataset.get_num_batches(args.batch_size), \n",
        "                        position=1, \n",
        "                        leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # Iterate over training dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        model.train()\n",
        "        \n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # the training routine is these 5 steps:\n",
        "\n",
        "            # --------------------------------------    \n",
        "            # step 1. zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # step 2. compute the output\n",
        "            y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "\n",
        "            # step 4. use loss to produce gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # step 5. use optimizer to take gradient step\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            # compute the  running loss and running accuracy\n",
        "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # update bar\n",
        "            train_bar.set_postfix(loss=running_loss,\n",
        "                                  acc=running_acc,\n",
        "                                  epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # Iterate over val dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        model.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # compute the output\n",
        "            y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "            # compute the  running loss and running accuracy\n",
        "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            \n",
        "            # Update bar\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "\n",
        "        train_state = update_train_state(args=args, model=model, \n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "        \n",
        "        # move model to cpu for sampling\n",
        "        model = model.cpu()\n",
        "        sampled_words = decode_samples(\n",
        "            sample_from_model(model, vectorizer, num_samples=2), \n",
        "            vectorizer)\n",
        "        epoch_bar.set_postfix(sample1=sampled_words[0], \n",
        "                              sample2=sampled_words[1])\n",
        "        # move model back to whichever device it should be on\n",
        "        model = model.to(args.device)\n",
        "        \n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "        \n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5137cda4993449c7be3282d133a2ce82",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef913c8d12454cea83b42f65ef818fb0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='split=train', max=59.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f92d4c7ff68241e8ad4b4b5b5ebeb708",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='split=val', max=9.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-VArXzT-qjk"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVQ3DBn--sey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f2d0d16-f60b-4f85-a0dc-5155b821e476"
      },
      "source": [
        "np.random.choice(np.arange(len(vectorizer.classification_vocab)), replace=True, size=2) # I think this just shows us how many classes are, if we have different classes"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogzoDm3N5hw7"
      },
      "source": [
        "\"\"\"\n",
        "For reference, the index of each character token in the distribution: CHANGE IF USING NEW DATASET\n",
        "\n",
        "{0: '<MASK>', 1: '<UNK>', 2: '<BEGIN>', 3: '<END>', 4: 'f', 5: 'i', 6: 'o', 7: 'n',\n",
        " 8: 'a', 9: 's', 10: 'h', 11: 't', 12: 'l', 13: 'w', 14: 'e', 15: 'b', 16: 'r', 17: 'u',\n",
        " 18: 'm', 19: 'c', 20: 'k', 21: 'p', 22: 'j', 23: 'd', 24: 'y', 25: 'v', 26: 'g', 27: 'q', \n",
        " 28: 'x', 29: 'z'}\n",
        "\n",
        "\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQc1CVzSyJZi"
      },
      "source": [
        "from collections import OrderedDict"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGzcIknG-I03"
      },
      "source": [
        "Evaluate using actual English words. This will give us an idea of how well the model does with predicting words that are actual in English. That is, for each \n",
        "test sequence, we will compare the probability of the sequence that actually exists in English, with the probability of the sequence that the model generated. We will evaluate using perplexity (2^-log prob of sequence). Lower perplexity means a better prediction was made."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acinRVe2-tMh"
      },
      "source": [
        "\"\"\"\n",
        "Compute the loss & accuracy on the English test set using the best available model.\n",
        "That is, here we are comparing the probability distribution of possible characters that could occur\n",
        "at each position, with what actually occured.\n",
        "\n",
        "y_pred: 128 words in batch, 20 character positions in each word, 38 characters in the distribution <-- NOTE THIS CHANGES WITH DIFFERENT DATASETS, BECAUSE OF HOW MANY CHARS THERE ARE\n",
        "\"\"\"\n",
        "\n",
        "model.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "model = model.to(args.device)\n",
        "\n",
        "dataset.set_split('test')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=args.batch_size, \n",
        "                                   device=args.device)\n",
        "running_acc = 0.\n",
        "model.eval()\n",
        "\n",
        "word_perplexities = OrderedDict() # maps words --> perplexity values\n",
        "position_perplexities = OrderedDict() # maps char positions --> perplexity values\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "    # compute the output\n",
        "    y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "    # initialize dictionary\n",
        "    word_perplexities[batch_index] = OrderedDict()\n",
        "    position_perplexities[batch_index] = OrderedDict()\n",
        "\n",
        "    # iterate over each word in the batch, and calculate the loss for that word\n",
        "    # save perplexity to dict\n",
        "    start = 0\n",
        "    end = 1\n",
        "    for i in range(128):\n",
        "        position_perplexities[batch_index][i] = OrderedDict()\n",
        "        word_loss = sequence_loss(y_pred[start:end,:],batch_dict['y_target'][start:end,:], mask_index)\n",
        "\n",
        "        # reconstruct the word\n",
        "        word = \"\"\n",
        "        start_pos = 0\n",
        "        end_pos = 1\n",
        "        for j in range(20):\n",
        "            curr_char_index = batch_dict['y_target'][i][j].item()\n",
        "            curr_char = vectorizer.char_vocab._idx_to_token[curr_char_index]\n",
        "            if curr_char_index >= 4:\n",
        "                word += curr_char\n",
        "\n",
        "            position_loss = sequence_loss(y_pred[:, start_pos:end_pos],batch_dict['y_target'][:, start_pos:end_pos], mask_index)\n",
        "            position_pp = math.pow(2,position_loss)\n",
        "            position_perplexities[batch_index][i][(j,curr_char)] = position_pp\n",
        "            start_pos += 1\n",
        "            end_pos += 1\n",
        "\n",
        "        pp = math.pow(2,word_loss)\n",
        "        word_perplexities[batch_index][word] = pp\n",
        "\n",
        "        start += 1\n",
        "        end += 1\n",
        "\n",
        "    # compute the loss\n",
        "    loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "    # compute the accuracy\n",
        "    running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss \n",
        "train_state['test_acc'] = running_acc"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCAugUqRLR-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e2ac4ad-d441-474f-9eec-11e5de2088b6"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 20, 38])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NoiBWYC-wJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af450a2e-3a46-4976-c97b-4a4ef4cf0a72"
      },
      "source": [
        "# print the loss, perplexity, and accuracy for the test set overall\n",
        "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
        "print(\"Test perplexity: {};\".format(math.pow(2,train_state['test_loss'])))\n",
        "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 2.4652416308720904;\n",
            "Test perplexity: 5.522194225022069;\n",
            "Test Accuracy: 25.41412383993305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZspmYUguc_M"
      },
      "source": [
        "# save word pp to file\n",
        "\n",
        "s_words = []\n",
        "for b, w_dict in word_perplexities.items():\n",
        "    for w, p in w_dict.items():\n",
        "        temp = [w,p]\n",
        "        s_words.append(temp)\n",
        "s_words_df = pd.DataFrame(s_words, columns = ['word', 'perplexity'])\n",
        "s_words_df.to_csv(\"/content/drive/MyDrive/Lang-and-Mind-Lab/english_word_pp.csv\", sep=\",\", header=True)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asUgo3eIwT2H"
      },
      "source": [
        "# save pp for each char of each word to file\n",
        "s_chars = []\n",
        "for b, w_dict in position_perplexities.items():\n",
        "    for w, char_dict in w_dict.items():\n",
        "        temp = [w]\n",
        "        for ch, p in char_dict.items():\n",
        "            temp.append((ch,p))\n",
        "        s_chars.append(temp)\n",
        "\n",
        "s_chars_df = pd.DataFrame(s_chars)\n",
        "s_chars_df.to_csv(\"/content/drive/MyDrive/Lang-and-Mind-Lab/english_char_pp.csv\", sep=\",\", header=True)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I0XeU2wt-_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed3ccc40-d8cc-4e16-8054-5a99f78d73f7"
      },
      "source": [
        "# print the perplexity values for each word in the first batch (128 words)\n",
        "# low perplexity values are good\n",
        "\n",
        "flag = 0\n",
        "for b, w_dict in word_perplexities.items():\n",
        "    if flag > 0:\n",
        "            break\n",
        "    for w, p in w_dict.items():\n",
        "        print(\"word: \", w, \" perplexity: \", round(p,2))\n",
        "    flag += 1"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word:  revenues  perplexity:  5.71\n",
            "word:  pursue  perplexity:  6.18\n",
            "word:  tracking  perplexity:  3.0\n",
            "word:  concentration  perplexity:  3.3\n",
            "word:  stephen  perplexity:  6.4\n",
            "word:  streams  perplexity:  4.99\n",
            "word:  info  perplexity:  8.58\n",
            "word:  petite  perplexity:  4.25\n",
            "word:  reunion  perplexity:  4.42\n",
            "word:  acknowledged  perplexity:  7.62\n",
            "word:  norway  perplexity:  8.04\n",
            "word:  initiated  perplexity:  4.36\n",
            "word:  roberts  perplexity:  5.14\n",
            "word:  azerbaijan  perplexity:  11.64\n",
            "word:  wisdom  perplexity:  7.19\n",
            "word:  aluminium  perplexity:  6.65\n",
            "word:  assume  perplexity:  5.59\n",
            "word:  cuban  perplexity:  6.27\n",
            "word:  examines  perplexity:  4.1\n",
            "word:  shades  perplexity:  4.21\n",
            "word:  identity  perplexity:  4.17\n",
            "word:  jokes  perplexity:  5.52\n",
            "word:  related  perplexity:  4.1\n",
            "word:  presenting  perplexity:  3.45\n",
            "word:  existence  perplexity:  5.15\n",
            "word:  latest  perplexity:  4.48\n",
            "word:  breakdown  perplexity:  11.91\n",
            "word:  orientation  perplexity:  4.18\n",
            "word:  upgrades  perplexity:  5.85\n",
            "word:  hardware  perplexity:  7.04\n",
            "word:  geek  perplexity:  9.44\n",
            "word:  daddy  perplexity:  5.87\n",
            "word:  rebate  perplexity:  4.15\n",
            "word:  child  perplexity:  5.04\n",
            "word:  drive  perplexity:  4.65\n",
            "word:  url  perplexity:  10.14\n",
            "word:  move  perplexity:  5.2\n",
            "word:  concepts  perplexity:  4.35\n",
            "word:  estate  perplexity:  4.33\n",
            "word:  viii  perplexity:  12.82\n",
            "word:  guaranteed  perplexity:  5.13\n",
            "word:  classics  perplexity:  5.5\n",
            "word:  mason  perplexity:  5.88\n",
            "word:  induced  perplexity:  4.93\n",
            "word:  weekly  perplexity:  8.29\n",
            "word:  g  perplexity:  12.81\n",
            "word:  glasgow  perplexity:  7.39\n",
            "word:  automatically  perplexity:  5.87\n",
            "word:  exciting  perplexity:  3.61\n",
            "word:  restaurants  perplexity:  4.69\n",
            "word:  pie  perplexity:  9.48\n",
            "word:  bi  perplexity:  10.23\n",
            "word:  grown  perplexity:  7.23\n",
            "word:  minute  perplexity:  4.45\n",
            "word:  former  perplexity:  3.87\n",
            "word:  burner  perplexity:  4.15\n",
            "word:  georgia  perplexity:  7.71\n",
            "word:  spanking  perplexity:  3.65\n",
            "word:  in  perplexity:  6.07\n",
            "word:  illustration  perplexity:  4.5\n",
            "word:  reason  perplexity:  5.14\n",
            "word:  lesser  perplexity:  3.94\n",
            "word:  no  perplexity:  7.38\n",
            "word:  consistently  perplexity:  4.23\n",
            "word:  feeling  perplexity:  4.36\n",
            "word:  celtic  perplexity:  5.6\n",
            "word:  campus  perplexity:  6.29\n",
            "word:  joke  perplexity:  6.43\n",
            "word:  steering  perplexity:  4.03\n",
            "word:  evaluate  perplexity:  5.31\n",
            "word:  criticism  perplexity:  6.8\n",
            "word:  wheels  perplexity:  6.03\n",
            "word:  situations  perplexity:  3.77\n",
            "word:  negative  perplexity:  5.44\n",
            "word:  narrow  perplexity:  7.43\n",
            "word:  stephanie  perplexity:  5.85\n",
            "word:  edgar  perplexity:  7.22\n",
            "word:  gamespot  perplexity:  5.98\n",
            "word:  doom  perplexity:  6.88\n",
            "word:  marathon  perplexity:  4.55\n",
            "word:  miss  perplexity:  4.59\n",
            "word:  hometown  perplexity:  7.33\n",
            "word:  commodities  perplexity:  3.93\n",
            "word:  filter  perplexity:  4.49\n",
            "word:  radar  perplexity:  6.72\n",
            "word:  soccer  perplexity:  6.04\n",
            "word:  state  perplexity:  3.99\n",
            "word:  customs  perplexity:  4.64\n",
            "word:  fp  perplexity:  10.25\n",
            "word:  specs  perplexity:  6.59\n",
            "word:  mental  perplexity:  4.42\n",
            "word:  quiz  perplexity:  15.49\n",
            "word:  consumer  perplexity:  3.45\n",
            "word:  fox  perplexity:  7.38\n",
            "word:  xanax  perplexity:  17.63\n",
            "word:  involving  perplexity:  6.09\n",
            "word:  might  perplexity:  6.28\n",
            "word:  bought  perplexity:  5.43\n",
            "word:  founded  perplexity:  4.01\n",
            "word:  b  perplexity:  11.35\n",
            "word:  most  perplexity:  7.06\n",
            "word:  papua  perplexity:  10.89\n",
            "word:  substantially  perplexity:  5.73\n",
            "word:  pierce  perplexity:  5.36\n",
            "word:  away  perplexity:  9.15\n",
            "word:  min  perplexity:  4.73\n",
            "word:  civic  perplexity:  6.79\n",
            "word:  rem  perplexity:  5.76\n",
            "word:  ist  perplexity:  6.9\n",
            "word:  technicians  perplexity:  6.22\n",
            "word:  responding  perplexity:  3.53\n",
            "word:  underlying  perplexity:  4.65\n",
            "word:  warming  perplexity:  3.34\n",
            "word:  bestsellers  perplexity:  6.34\n",
            "word:  ali  perplexity:  7.88\n",
            "word:  orleans  perplexity:  4.35\n",
            "word:  speed  perplexity:  5.6\n",
            "word:  administration  perplexity:  4.9\n",
            "word:  guam  perplexity:  6.0\n",
            "word:  costumes  perplexity:  3.99\n",
            "word:  effectiveness  perplexity:  5.73\n",
            "word:  boats  perplexity:  6.04\n",
            "word:  inner  perplexity:  5.68\n",
            "word:  letters  perplexity:  4.64\n",
            "word:  ups  perplexity:  6.69\n",
            "word:  surgeon  perplexity:  4.36\n",
            "word:  trader  perplexity:  4.29\n",
            "word:  qld  perplexity:  9.18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIeXrJHzHQKs"
      },
      "source": [
        "# get the perpelxity at each character position (averaged over each English word)\n",
        "\n",
        "# avgs = {}\n",
        "# for batch, char_dict in position_perplexities.items():\n",
        "#     for ch, p in char_dict.items():\n",
        "#         if avgs.get(ch):\n",
        "#             avgs[ch] += p\n",
        "#         else:\n",
        "#             avgs[ch] = p\n",
        "# avgs = {k: v / 20 for k, v in avgs.items()} # change this for num of chars\n",
        "\n",
        "# # plot\n",
        "# df = pd.DataFrame(list(avgs.items()), columns=['Character Positions', 'English']) \n",
        "# plt.bar(df['Character Positions'], df['English'], color='purple', width=0.5)\n",
        "# plt.title('English words')\n",
        "# plt.xlabel('Character positions')\n",
        "# plt.ylabel('Avg. perplexities')\n",
        "# plt.xlim(0,29)\n",
        "# plt.xticks(np.arange(0, 20, 1))\n",
        "# plt.rcParams[\"figure.figsize\"] = (20, 4)\n",
        "# plt.show()\n",
        "# print('\\n')\n",
        "\n",
        "# note that many of the character positions at the end are not real. Since\n",
        "# the model needs each word to be the same length, a \"mask\" character is created\n",
        "# for shorter words, and that probability is not counted overall when looking \n",
        "# at the probabilty of that word. So the end of the graph doesn't tell us a ton.\n",
        "\n",
        "# Each word should have high perplexity in the beginning, because the more \n",
        "# observations that a model sees, the less \"perlexed\" it will be, and it has\n",
        "# observed little in the beginning of the word. As we get farther into the word\n",
        "# perplexity should decrease. This isn't happening right now, but a lot of \n",
        "# the words aren't very representative of English. \n",
        "\n",
        "# However, I would guess that for doubling words, the model would get more \n",
        "# perplexed towards the end of the word as well, when the doubling occurs, \n",
        "# as doubling is not expected. I'm not sure how the non-words without doubling\n",
        "# will perform. They may have higher perpelxity than the actual English words,\n",
        "# but lower than the non-words with doubling. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hTJdNIV-vGv"
      },
      "source": [
        "Evaluate the model using non-words that have doubling. We would predict that the perplexity of these words would be higher than those that do not have doubling. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lK0eb2ztB0W"
      },
      "source": [
        "# test doubling words\n",
        "\n",
        "model.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "model = model.to(args.device)\n",
        "\n",
        "dataset.set_split('doubling')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=1, # we change the batch size to 1, since we don't have many words we are working with\n",
        "                                   device=args.device)\n",
        "\n",
        "\n",
        "running_acc = 0.\n",
        "model.eval()\n",
        "\n",
        "word_perplexities_doubling = OrderedDict() # maps words --> perplexity values\n",
        "position_perplexities_doubling = OrderedDict() # maps char positions --> perplexity values\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "    # compute the output\n",
        "    y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "    # initialize dictionary\n",
        "    word_perplexities_doubling[batch_index] = OrderedDict()\n",
        "    position_perplexities_doubling[batch_index] = OrderedDict()\n",
        "\n",
        "    # iterate over each word in the batch, and calculate the loss for that word\n",
        "    # save perplexity to dict\n",
        "    start = 0\n",
        "    end = 1\n",
        "    for i in range(1):\n",
        "        position_perplexities_doubling[batch_index][i] = OrderedDict()\n",
        "        word_loss = sequence_loss(y_pred[start:end,:],batch_dict['y_target'][start:end,:], mask_index)\n",
        "        \n",
        "        # reconstruct the word and get perplexity at each char position\n",
        "        word = \"\"\n",
        "        start_pos = 0\n",
        "        end_pos = 1\n",
        "        for j in range(20):\n",
        "            curr_char_index = batch_dict['y_target'][i][j].item()\n",
        "            curr_char = vectorizer.char_vocab._idx_to_token[curr_char_index]\n",
        "            word += curr_char\n",
        "\n",
        "            position_loss = sequence_loss(y_pred[:, start_pos:end_pos],batch_dict['y_target'][:, start_pos:end_pos], mask_index)\n",
        "            position_pp = math.pow(2,position_loss)\n",
        "            position_perplexities_doubling[batch_index][i][(j,curr_char)] = position_pp\n",
        "            start_pos += 1\n",
        "            end_pos += 1\n",
        "\n",
        "        pp = math.pow(2,word_loss)\n",
        "        word_perplexities_doubling[batch_index][word] = pp\n",
        "\n",
        "        start += 1\n",
        "        end += 1\n",
        "\n",
        "    # compute the loss\n",
        "    loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "    # compute the accuracy\n",
        "    running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss \n",
        "train_state['test_acc'] = running_acc"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czkYOh0RMJqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "878cc71e-ff4b-4c14-a49a-30e7a2f159f2"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20, 38])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnXu7uyH9a60",
        "outputId": "c5e44753-233a-4573-8241-89f84334e2de"
      },
      "source": [
        "# print the loss, perplexity, and accuracy for the doubling set overall\n",
        "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
        "print(\"Test perplexity: {};\".format(math.pow(2,train_state['test_loss'])))\n",
        "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 2.837270838873726;\n",
            "Test perplexity: 7.1466683455316575;\n",
            "Test Accuracy: 10.000000000000004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS8YDxwL9ASu",
        "outputId": "ebc07dea-a0dd-41d3-e750-1b2b1f1317f7"
      },
      "source": [
        "# Print the perplexities for each word\n",
        "for b, w_dict in word_perplexities_doubling.items():\n",
        "    for w, p in w_dict.items():\n",
        "        print(\"word: \", w, \" perplexity: \", round(p,2))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word:  stimtim<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  5.81\n",
            "word:  premrem<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  6.07\n",
            "word:  trosros<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  5.81\n",
            "word:  trelrel<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  6.54\n",
            "word:  flonlon<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  7.18\n",
            "word:  tramram<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  6.55\n",
            "word:  granran<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  5.64\n",
            "word:  blatlat<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  6.94\n",
            "word:  trafraf<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  8.23\n",
            "word:  plaflaf<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  6.87\n",
            "word:  kloplop<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  8.45\n",
            "word:  flaklak<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  8.73\n",
            "word:  frosros<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  5.3\n",
            "word:  drakrak<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  9.89\n",
            "word:  snognog<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  8.42\n",
            "word:  fliblib<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  7.67\n",
            "word:  grofrof<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  7.37\n",
            "word:  kravrav<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  10.09\n",
            "word:  prafraf<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  7.36\n",
            "word:  franran<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  6.74\n",
            "word:  blaslas<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  5.18\n",
            "word:  dranran<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  5.91\n",
            "word:  smatmat<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  5.97\n",
            "word:  blaflaf<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  9.05\n",
            "word:  drofrof<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  8.89\n",
            "word:  slanlan<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  6.8\n",
            "word:  kragrag<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  8.03\n",
            "word:  smolmol<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  8.18\n",
            "word:  grefref<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  7.86\n",
            "word:  flamlam<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  8.35\n",
            "word:  plonlon<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  7.19\n",
            "word:  slodlod<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  6.15\n",
            "word:  klenlen<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  6.58\n",
            "word:  snadnad<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  6.84\n",
            "word:  frebreb<END><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK><MASK>  perplexity:  7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyI-cCTf2U73"
      },
      "source": [
        "s_words_doubling = []\n",
        "for b, w_dict in word_perplexities_doubling.items():\n",
        "    for w, p in w_dict.items():\n",
        "        temp = [w,p]\n",
        "        s_words_doubling.append(temp)\n",
        "s_words_double_df = pd.DataFrame(s_words_doubling, columns = ['word', 'perplexity'])\n",
        "s_words_double_df.to_csv(\"/content/drive/MyDrive/Lang-and-Mind-Lab/doubling_word_pp.csv\", sep=\",\", header=True)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p71W83Zf2crU"
      },
      "source": [
        "# save pp for each char of each word to file\n",
        "s_chars_doubling = []\n",
        "for b, w_dict in position_perplexities_doubling.items():\n",
        "    for w, char_dict in w_dict.items():\n",
        "        temp = [w]\n",
        "        for ch, p in char_dict.items():\n",
        "            temp.append((ch,p))\n",
        "        s_chars_doubling.append(temp)\n",
        "\n",
        "s_chars_double_df = pd.DataFrame(s_chars_doubling)\n",
        "s_chars_double_df.to_csv(\"/content/drive/MyDrive/Lang-and-Mind-Lab/doubling_char_pp.csv\", sep=\",\", header=True)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-57V3aYEd_o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "171b07e6-b68c-45c0-bf1f-be15575a2270"
      },
      "source": [
        "# get the perpelxity at each character position (averaged over each doubling word)\n",
        "# avgs_doubling = {}\n",
        "# for batch, char_dict in position_perplexities_doubling.items():\n",
        "#     for ch, p in char_dict.items():\n",
        "#         if avgs_doubling.get(ch):\n",
        "#             avgs_doubling[ch] += p\n",
        "#         else:\n",
        "#             avgs_doubling[ch] = p\n",
        "# avgs_doubling = {k: v / 20 for k, v in avgs_doubling.items()}\n",
        "\n",
        "# # plot\n",
        "# df_doubling = pd.DataFrame(list(avgs_doubling.items()), columns=['Character Positions', 'doubling']) \n",
        "# plt.bar(df_doubling['Character Positions'], df_doubling['doubling'], color='orange', width=0.5)\n",
        "# plt.title('Doubling words')\n",
        "# plt.xlabel('Character positions')\n",
        "# plt.ylabel('Avg. perplexities')\n",
        "# plt.xlim(0,6)\n",
        "# plt.xticks(np.arange(0, 6, 1))\n",
        "# plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
        "# plt.show()\n",
        "# print('\\n')\n",
        "\n",
        "# Each word should have high perplexity in the begining, because the more \n",
        "# observations that a model sees, the less \"perlexed\" it will be, and it has\n",
        "# observed little in the beginning of the word. However, I would guess that\n",
        "# for doubling words, the model would get more perplexed towards the end\n",
        "# of the word as well, when the doubling occurs, as that is not expected.\n",
        "# On the other hand, I would expect perplexity to go down later in the word\n",
        "# for words without doubling. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOaS7UAY_DZT"
      },
      "source": [
        "Evaluate the model using non-words that do not have doubling. The perplexity of these words should be similar to that of actual English words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkEfde5M9ng1"
      },
      "source": [
        "# test control words (non-words, no doubling)\n",
        "\n",
        "model.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "model = model.to(args.device)\n",
        "\n",
        "dataset.set_split('no_doubling')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=1, # we change the batch size to 1, since we don't have many words we are working with\n",
        "                                   device=args.device)\n",
        "\n",
        "\n",
        "running_acc = 0.\n",
        "model.eval()\n",
        "\n",
        "word_perplexities_control = OrderedDict() # maps words --> perplexity values\n",
        "position_perplexities_control = OrderedDict()\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "    # compute the output\n",
        "    y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "    # initialize dictionary\n",
        "    word_perplexities_control[batch_index] = OrderedDict()\n",
        "    position_perplexities_control[batch_index] = OrderedDict()\n",
        "\n",
        "    # iterate over each word in the batch, and calculate the loss for that word\n",
        "    # save perplexity to dict\n",
        "    start = 0\n",
        "    end = 1\n",
        "    for i in range(1):\n",
        "        position_perplexities_control[batch_index][i] = OrderedDict()\n",
        "        word_loss = sequence_loss(y_pred[start:end,:],batch_dict['y_target'][start:end,:], mask_index)\n",
        "\n",
        "        # reconstruct the word and pp at each char posiiton\n",
        "        word = \"\"\n",
        "        start_pos = 0\n",
        "        end_pos = 1\n",
        "        for j in range(20):\n",
        "            curr_char_index = batch_dict['y_target'][i][j].item()\n",
        "            curr_char = vectorizer.char_vocab._idx_to_token[curr_char_index]\n",
        "            if curr_char_index >= 4:\n",
        "                word += curr_char\n",
        "\n",
        "            position_loss = sequence_loss(y_pred[:, start_pos:end_pos],batch_dict['y_target'][:, start_pos:end_pos], mask_index)\n",
        "            position_pp = math.pow(2,position_loss)\n",
        "            position_perplexities_control[batch_index][i][(j,curr_char)] = position_pp\n",
        "            start_pos += 1\n",
        "            end_pos += 1\n",
        "\n",
        "        pp = math.pow(2,word_loss)\n",
        "        word_perplexities_control[batch_index][word] = pp\n",
        "\n",
        "        start += 1\n",
        "        end += 1\n",
        "\n",
        "    # compute the loss\n",
        "    loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "    # compute the accuracy\n",
        "    running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss \n",
        "train_state['test_acc'] = running_acc"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n6ON6wp9uCd",
        "outputId": "ab2d2fbf-b773-4776-c66d-ab4564e8a098"
      },
      "source": [
        "# print the loss, perplexity, and accuracy for the doubling set overall\n",
        "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
        "print(\"Test perplexity: {};\".format(math.pow(2,train_state['test_loss'])))\n",
        "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 2.8568397453853067;\n",
            "Test perplexity: 7.2442671260070695;\n",
            "Test Accuracy: 14.642857142857142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McjjRGs09uO2",
        "outputId": "620576e2-edcd-4d55-8a5c-6d5203c886da"
      },
      "source": [
        "# print the perplexities for each word\n",
        "for b, w_dict in word_perplexities_control.items():\n",
        "    for w, p in w_dict.items():\n",
        "        print(\"word: \", w, \" perplexity: \", round(p,2))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word:  plonmuk  perplexity:  10.22\n",
            "word:  smatnod  perplexity:  7.99\n",
            "word:  slodmog  perplexity:  8.75\n",
            "word:  klenmof  perplexity:  11.79\n",
            "word:  draknad  perplexity:  7.11\n",
            "word:  freblek  perplexity:  7.33\n",
            "word:  praflak  perplexity:  6.07\n",
            "word:  trosnot  perplexity:  5.95\n",
            "word:  kravmal  perplexity:  7.95\n",
            "word:  snadmak  perplexity:  11.84\n",
            "word:  slanmot  perplexity:  5.78\n",
            "word:  flakmal  perplexity:  8.11\n",
            "word:  flamrad  perplexity:  6.25\n",
            "word:  plafnut  perplexity:  6.87\n",
            "word:  franmet  perplexity:  4.98\n",
            "word:  smolrog  perplexity:  8.11\n",
            "word:  klopnog  perplexity:  7.59\n",
            "word:  blafron  perplexity:  7.08\n",
            "word:  tramlut  perplexity:  7.08\n",
            "word:  froslak  perplexity:  6.84\n",
            "word:  snogmot  perplexity:  8.14\n",
            "word:  granlat  perplexity:  5.85\n",
            "word:  kragnel  perplexity:  7.29\n",
            "word:  greflek  perplexity:  6.04\n",
            "word:  flonmog  perplexity:  7.99\n",
            "word:  trelnat  perplexity:  4.96\n",
            "word:  flibnep  perplexity:  7.37\n",
            "word:  dranlat  perplexity:  4.63\n",
            "word:  traflam  perplexity:  6.63\n",
            "word:  grofnom  perplexity:  8.84\n",
            "word:  drofmok  perplexity:  9.87\n",
            "word:  blatnog  perplexity:  6.19\n",
            "word:  premlek  perplexity:  6.56\n",
            "word:  blasnol  perplexity:  6.64\n",
            "word:  stimkam  perplexity:  9.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCuXG3Df6ga8"
      },
      "source": [
        "s_words_control = []\n",
        "for b, w_dict in word_perplexities_control.items():\n",
        "    for w, p in w_dict.items():\n",
        "        temp = [w,p]\n",
        "        s_words_control.append(temp)\n",
        "s_words_control_df = pd.DataFrame(s_words_control, columns = ['word', 'perplexity'])\n",
        "s_words_control_df.to_csv(\"/content/drive/MyDrive/Lang-and-Mind-Lab/control_word_pp.csv\", sep=\",\", header=True)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqQt9ZhX6gme"
      },
      "source": [
        "# save pp for each char of each word to file\n",
        "s_chars_control = []\n",
        "for b, w_dict in position_perplexities_control.items():\n",
        "    for w, char_dict in w_dict.items():\n",
        "        temp = [w]\n",
        "        for ch, p in char_dict.items():\n",
        "            temp.append((ch,p))\n",
        "        s_chars_control.append(temp)\n",
        "\n",
        "s_chars_control_df = pd.DataFrame(s_chars_control)\n",
        "s_chars_control_df.to_csv(\"/content/drive/MyDrive/Lang-and-Mind-Lab/control_char_pp.csv\", sep=\",\", header=True)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUnMeF-gGFOG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "f2afe77d-7d17-42ba-b734-198236768f35"
      },
      "source": [
        "# # get the perpelxity at each character position (averaged over each non-doubling word)\n",
        "# avgs_control = {}\n",
        "# for batch, char_dict in position_perplexities_control.items():\n",
        "#     for ch, p in char_dict.items():\n",
        "#         if avgs_control.get(ch):\n",
        "#             avgs_control[ch] += p\n",
        "#         else:\n",
        "#             avgs_control[ch] = p\n",
        "# avgs_control = {k: v / 20 for k, v in avgs_control.items()}\n",
        "\n",
        "# # plot\n",
        "# df_control = pd.DataFrame(list(avgs_control.items()), columns=['Character Positions', 'control']) \n",
        "# plt.bar(df_control['Character Positions'], df_control['control'], color='green', width=0.5)\n",
        "# plt.title('Control non-words')\n",
        "# plt.xlabel('Character positions')\n",
        "# plt.ylabel('Avg. perplexities')\n",
        "# plt.xlim(0,6)\n",
        "# plt.xticks(np.arange(0, 6, 1))\n",
        "# plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
        "# plt.show()\n",
        "# print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLuqxq9iKGSg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "25f60f2e-f6f2-403a-bb82-66cab451d0a7"
      },
      "source": [
        "# plot English test words, doubling non-words, and control non-words together\n",
        "# # combined plot\n",
        "# df_doubling_pp = df_doubling[\"doubling\"]\n",
        "# df_control_pp = df_control[\"control\"]\n",
        "# all_data = df.join(df_doubling_pp)\n",
        "# all_data = all_data.join(df_control_pp)\n",
        "# plt.plot(all_data[\"English\"], label='English', color=\"purple\")\n",
        "# plt.plot(all_data[\"doubling\"], label='Doubling non-words', color=\"orange\")\n",
        "# plt.plot(all_data[\"control\"], label='Control non-words', color=\"green\")\n",
        "# plt.title('Perplexity by character position')\n",
        "# plt.xlabel('Character positions')\n",
        "# plt.ylabel('Avg. perplexities')\n",
        "# plt.legend()\n",
        "# plt.xlim(0,6)\n",
        "# plt.xticks(np.arange(0, 6, 1))\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE7UzCKe-0jT"
      },
      "source": [
        "# Generate new words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF2dX7qQ_LpN"
      },
      "source": [
        "We can have the model generate words, and count the words that have doubling in them (a model that has learned English well, would not have many words with doubling?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPgUqGDF-yZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1b74f8-b93b-401c-d37a-e231986b8003"
      },
      "source": [
        "# number of names to generate\n",
        "num_words = 20\n",
        "model = model.cpu()\n",
        "# Generate nationality hidden state\n",
        "sampled_words = decode_samples(\n",
        "    sample_from_model(model, vectorizer, num_samples=num_words), \n",
        "    vectorizer)\n",
        "# Show results\n",
        "print (\"-\"*15)\n",
        "for i in range(num_words):\n",
        "    print (sampled_words[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------\n",
            "lecaderLrmecs\n",
            "accoccuytal\n",
            "dilire\n",
            "rofamict\n",
            "obmcnecrieds\n",
            "bummere\n",
            "des\n",
            "mipt\n",
            "abhl\n",
            "palfes\n",
            "pxlure\n",
            "icolic\n",
            "pbor\n",
            "wanyac\n",
            "atibakiud\n",
            "hnakul\n",
            "benlexs\n",
            "detons\n",
            "arfhion\n",
            "cenpimalemer\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}