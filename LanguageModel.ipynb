{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelEvaluation.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/mplatt27/Language-Model-Linguistic-Doubling-Task/blob/main/LanguageModel.ipynb",
      "authorship_tag": "ABX9TyNtE1jb0zIorHaNxTI3Kj8B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "267a34a2f4cd438bb030e7d25c7b06a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6c78f5b18ecc4b4cac70b77c34a0bb13",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_65901777d0a94f72b0ceb2de73e8c36c",
              "IPY_MODEL_8ed6a5ff757b40188ed3bec81ff5f443"
            ]
          }
        },
        "6c78f5b18ecc4b4cac70b77c34a0bb13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65901777d0a94f72b0ceb2de73e8c36c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a2196613e4554d24adbafcc476648b91",
            "_dom_classes": [],
            "description": "training routine: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5062f2a268574de48274ae8a6a2fe274"
          }
        },
        "8ed6a5ff757b40188ed3bec81ff5f443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ece2fe70782042a9921e206e5d7597de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [05:36&lt;00:00,  3.36s/it, sample1=bacy, sample2=nexers]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ea58bfaeec3487796e7a3bd5ad2b74d"
          }
        },
        "a2196613e4554d24adbafcc476648b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5062f2a268574de48274ae8a6a2fe274": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ece2fe70782042a9921e206e5d7597de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ea58bfaeec3487796e7a3bd5ad2b74d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c86994870b343628a1b7fcbe0f7c62e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_934da7852c294db09e4849537c14be80",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b96721b856d945b3b503e7c258f1f8a7",
              "IPY_MODEL_734beee7c47b4b8ebf576aaac30e6295"
            ]
          }
        },
        "934da7852c294db09e4849537c14be80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b96721b856d945b3b503e7c258f1f8a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_403ec490fd0b4bd6b338d74efdd80500",
            "_dom_classes": [],
            "description": "split=train:  98%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 59,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 58,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86fcb59f8c314b6990d94877701b74c2"
          }
        },
        "734beee7c47b4b8ebf576aaac30e6295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f237901722694d12829bce4360bf9357",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 58/59 [05:36&lt;00:00,  1.78it/s, acc=25.7, epoch=99, loss=2.45]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34821193d4e746efa95acc6a9cd266f7"
          }
        },
        "403ec490fd0b4bd6b338d74efdd80500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86fcb59f8c314b6990d94877701b74c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f237901722694d12829bce4360bf9357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34821193d4e746efa95acc6a9cd266f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eccbba6313fe42b9af2ccf20c67f9421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_685c3aad640d4303b9d72e85c89bfac2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d418ee366a1e439ca4a030600cccdb35",
              "IPY_MODEL_2cdd4d983b7b43cab4d1ef51d0ce98bf"
            ]
          }
        },
        "685c3aad640d4303b9d72e85c89bfac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d418ee366a1e439ca4a030600cccdb35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_59a4b285dba548bb9fcf7397750900ab",
            "_dom_classes": [],
            "description": "split=val:  89%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 9,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc627cc089e046c4ac63128d45d1c07c"
          }
        },
        "2cdd4d983b7b43cab4d1ef51d0ce98bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_851a2fbf3c1d462eae1fa3d21d4874fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8/9 [05:36&lt;00:01,  1.63s/it, acc=26.4, epoch=99, loss=2.45]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f15666a70b23453d98e2272aab7e730f"
          }
        },
        "59a4b285dba548bb9fcf7397750900ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc627cc089e046c4ac63128d45d1c07c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "851a2fbf3c1d462eae1fa3d21d4874fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f15666a70b23453d98e2272aab7e730f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mplatt27/Language-Model-Linguistic-Doubling-Task/blob/main/LanguageModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bymBLatcwZz_"
      },
      "source": [
        "# Character-level English Language Model\n",
        "\n",
        "*Langauge and Mind Lab*\n",
        "\n",
        "\n",
        "All code is adapted from the book: Natural Language Processing with PyTorch: Build Intelligent Language Applications Using Deep Learning, by Delip Rao and Brian McMahan. The original code is available here: https://github.com/joosthub/PyTorchNLPBook. \n",
        "\n",
        "The model uses a Gated Recurrent Unit (GRU) neural network and is trained on a set of ### English words from \"\". We then evaluate the model with a test set of novel words that both have and do not have linguistic doubling, to determine if the model has learned preferences that are observed in English speakers. We can also generate novel words and look for features like linguistic doubling. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWHsiuY6nUsY"
      },
      "source": [
        "Notes on dataset:\n",
        "\n",
        "*   Retrieved from https://www.kaggle.com/rtatman/english-word-frequency and contains 333,333 unique words.\n",
        "*   I first shuffled the words in the spreadsheet, then took the first ~10,000 words to use (the original code uses a smaller dataset around this size, so as a first attempt on this project, I used a shortened version of the word dataset). We can increase this size later if we want\n",
        "*   I then labeled approximatley 70% as the training set, 15% as the validation set, and 15% as the test set. The test set will be used as a proof of concept to see how the model does with words that are true English words that the model has never seen before. \n",
        "*   I then added to the data set, ~30 \"slaflaf\" words that I found (they may not be the more recent versions) both with doubling and the control matched pair without doubling (i.e., \"slafmat\").\n",
        "*   Looking over the English words in the dataset in detail, I'm not sure this is what we want to use for the final version, as many words are strange and something I have never seen before. We can keep searching, but this at least shows us that the code works and we can replace the dataset as long as it is in the same format.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpfKJcY39nvZ"
      },
      "source": [
        "# Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuIZa6uj9oAC"
      },
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6n06uyV9vDy"
      },
      "source": [
        "# Data Vectorization classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woqkA8VU9tc0"
      },
      "source": [
        "class Vocabulary(object):\n",
        "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
        "\n",
        "    def __init__(self, token_to_idx=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
        "        \"\"\"\n",
        "\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self._token_to_idx = token_to_idx\n",
        "\n",
        "        self._idx_to_token = {idx: token \n",
        "                              for token, idx in self._token_to_idx.items()}\n",
        "        \n",
        "    def to_serializable(self):\n",
        "        \"\"\" returns a dictionary that can be serialized \"\"\"\n",
        "        return {'token_to_idx': self._token_to_idx}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        \"\"\"Update mapping dicts based on the token.\n",
        "\n",
        "        Args:\n",
        "            token (str): the item to add into the Vocabulary\n",
        "        Returns:\n",
        "            index (int): the integer corresponding to the token\n",
        "        \"\"\"\n",
        "        if token in self._token_to_idx:\n",
        "            index = self._token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self._token_to_idx)\n",
        "            self._token_to_idx[token] = index\n",
        "            self._idx_to_token[index] = token\n",
        "        return index\n",
        "            \n",
        "    def add_many(self, tokens):\n",
        "        \"\"\"Add a list of tokens into the Vocabulary\n",
        "        \n",
        "        Args:\n",
        "            tokens (list): a list of string tokens\n",
        "        Returns:\n",
        "            indices (list): a list of indices corresponding to the tokens\n",
        "        \"\"\"\n",
        "        return [self.add_token(token) for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"Retrieve the index associated with the token \n",
        "        \n",
        "        Args:\n",
        "            token (str): the token to look up \n",
        "        Returns:\n",
        "            index (int): the index corresponding to the token\n",
        "        \"\"\"\n",
        "        return self._token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        \"\"\"Return the token associated with the index\n",
        "        \n",
        "        Args: \n",
        "            index (int): the index to look up\n",
        "        Returns:\n",
        "            token (str): the token corresponding to the index\n",
        "        Raises:\n",
        "            KeyError: if the index is not in the Vocabulary\n",
        "        \"\"\"\n",
        "        if index not in self._idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self._idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._token_to_idx)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbYTG8LH9z5m"
      },
      "source": [
        "class SequenceVocabulary(Vocabulary):\n",
        "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
        "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
        "                 end_seq_token=\"<END>\"):\n",
        "\n",
        "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
        "\n",
        "        self._mask_token = mask_token\n",
        "        self._unk_token = unk_token\n",
        "        self._begin_seq_token = begin_seq_token\n",
        "        self._end_seq_token = end_seq_token\n",
        "\n",
        "        self.mask_index = self.add_token(self._mask_token)\n",
        "        self.unk_index = self.add_token(self._unk_token)\n",
        "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
        "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        contents = super(SequenceVocabulary, self).to_serializable()\n",
        "        contents.update({'unk_token': self._unk_token,\n",
        "                         'mask_token': self._mask_token,\n",
        "                         'begin_seq_token': self._begin_seq_token,\n",
        "                         'end_seq_token': self._end_seq_token})\n",
        "        return contents\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"Retrieve the index associated with the token \n",
        "          or the UNK index if token isn't present.\n",
        "        \n",
        "        Args:\n",
        "            token (str): the token to look up \n",
        "        Returns:\n",
        "            index (int): the index corresponding to the token\n",
        "        Notes:\n",
        "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
        "              for the UNK functionality \n",
        "        \"\"\"\n",
        "        if self.unk_index >= 0:\n",
        "            return self._token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            return self._token_to_idx[token]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRDY-lT992oJ"
      },
      "source": [
        "# Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liiGfSkL94h9"
      },
      "source": [
        "class WordVectorizer(object):\n",
        "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"    \n",
        "    def __init__(self, char_vocab, classification_vocab):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            char_vocab (Vocabulary): maps words to integers\n",
        "            classification_vocab (Vocabulary): maps classes to integers\n",
        "        \"\"\"\n",
        "        self.char_vocab = char_vocab\n",
        "        self.classification_vocab = classification_vocab\n",
        "\n",
        "    def vectorize(self, word, vector_length=-1):\n",
        "        \"\"\"Vectorize a word into a vector of observations and targets\n",
        "        \n",
        "        The outputs are the vectorized word split into two vectors:\n",
        "            word[:-1] and word[1:]\n",
        "        At each timestep, the first vector is the observation and the second vector is the target. \n",
        "        \n",
        "        Args:\n",
        "            word (str): the word to be vectorized\n",
        "            vector_length (int): an argument for forcing the length of index vector\n",
        "        Returns:\n",
        "            a tuple: (from_vector, to_vector)\n",
        "            from_vector (numpy.ndarray): the observation vector \n",
        "            to_vector (numpy.ndarray): the target prediction vector\n",
        "        \"\"\"\n",
        "        indices = [self.char_vocab.begin_seq_index] \n",
        "        indices.extend(self.char_vocab.lookup_token(token) for token in word)\n",
        "        indices.append(self.char_vocab.end_seq_index)\n",
        "\n",
        "        if vector_length < 0:\n",
        "            vector_length = len(indices) - 1\n",
        "\n",
        "        from_vector = np.empty(vector_length, dtype=np.int64)         \n",
        "        from_indices = indices[:-1]\n",
        "        from_vector[:len(from_indices)] = from_indices\n",
        "        from_vector[len(from_indices):] = self.char_vocab.mask_index\n",
        "\n",
        "        to_vector = np.empty(vector_length, dtype=np.int64)\n",
        "        to_indices = indices[1:]\n",
        "        to_vector[:len(to_indices)] = to_indices\n",
        "        to_vector[len(to_indices):] = self.char_vocab.mask_index\n",
        "        \n",
        "        return from_vector, to_vector\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, word_df):\n",
        "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
        "        \n",
        "        Args:\n",
        "            word_df (pandas.DataFrame): the word dataset\n",
        "        Returns:\n",
        "            an instance of the WordVectorizer\n",
        "        \"\"\"\n",
        "        char_vocab = SequenceVocabulary()\n",
        "        classification_vocab = Vocabulary()\n",
        "\n",
        "        for index, row in word_df.iterrows():\n",
        "            for char in row.word:\n",
        "                char_vocab.add_token(char)\n",
        "            classification_vocab.add_token(row.classification)\n",
        "\n",
        "        return cls(char_vocab, classification_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\"Instantiate the vectorizer from saved contents\n",
        "        \n",
        "        Args:\n",
        "            contents (dict): a dict holding two vocabularies for this vectorizer\n",
        "                This dictionary is created using `vectorizer.to_serializable()`\n",
        "        Returns:\n",
        "            an instance of WordVectorizer\n",
        "        \"\"\"\n",
        "        char_vocab = SequenceVocabulary.from_serializable(contents['char_vocab'])\n",
        "        class_vocab =  Vocabulary.from_serializable(contents['classification_vocab'])\n",
        "\n",
        "        return cls(char_vocab=char_vocab, classification_vocab=nat_vocab)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        \"\"\" Returns the serializable contents \"\"\"\n",
        "        return {'char_vocab': self.char_vocab.to_serializable(), \n",
        "                'classification_vocab': self.classification_vocab.to_serializable()}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlu4nKW696x8"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo824x6m98cd"
      },
      "source": [
        "class WordDataset(Dataset):\n",
        "    def __init__(self, word_df, vectorizer):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            word_df (pandas.DataFrame): the dataset\n",
        "            vectorizer (WordVectorizer): vectorizer instatiated from dataset\n",
        "        \"\"\"\n",
        "        self.word_df = word_df \n",
        "        self._vectorizer = vectorizer\n",
        "\n",
        "        self._max_seq_length = max(map(len, self.word_df.word)) + 2\n",
        "\n",
        "        self.train_df = self.word_df[self.word_df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.word_df[self.word_df.split=='val']\n",
        "        self.validation_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.word_df[self.word_df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "\n",
        "        # ADDED:\n",
        "        # -----------------------------------------------------------------\n",
        "        self.doubling_df = self.word_df[self.word_df.split=='doubling']\n",
        "        self.doubling_size = len(self.doubling_df)\n",
        "\n",
        "        self.nodoubling_df = self.word_df[self.word_df.split=='no_doubling']\n",
        "        self.nodoubling_size = len(self.nodoubling_df)\n",
        "\n",
        "\n",
        "        # -----------------------------------------------------------------\n",
        "\n",
        "        self._lookup_dict = {'train': (self.train_df, self.train_size), \n",
        "                             'val': (self.val_df, self.validation_size), \n",
        "                             'test': (self.test_df, self.test_size),\n",
        "                             'doubling': (self.doubling_df, self.doubling_size), # ADDED\n",
        "                             'no_doubling': (self.nodoubling_df, self.nodoubling_size)} # ADDED\n",
        "\n",
        "        self.set_split('train')\n",
        "        \n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, word_csv):\n",
        "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
        "        \n",
        "        Args:\n",
        "            word_csv (str): location of the dataset\n",
        "        Returns:\n",
        "            an instance of WordDataset\n",
        "        \"\"\"\n",
        "        \n",
        "        word_df = pd.read_csv(word_csv, encoding='latin-1')\n",
        "        return cls(word_df, WordVectorizer.from_dataframe(word_df))\n",
        "        \n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, word_csv, vectorizer_filepath):\n",
        "        \"\"\"Load dataset and the corresponding vectorizer. \n",
        "        Used in the case in the vectorizer has been cached for re-use\n",
        "        \n",
        "        Args:\n",
        "            word_csv (str): location of the dataset\n",
        "            vectorizer_filepath (str): location of the saved vectorizer\n",
        "        Returns:\n",
        "            an instance of WordDataset\n",
        "        \"\"\"\n",
        "        word_df = pd.read_csv(word_csv, encoding='latin-1') # changed coding here\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(word_df, vectorizer)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        \"\"\"a static method for loading the vectorizer from file\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location of the serialized vectorizer\n",
        "        Returns:\n",
        "            an instance of WordVectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return WordVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        \"\"\"saves the vectorizer to disk using json\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location to save the vectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self._vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def get_vectorizer(self):\n",
        "        \"\"\" returns the vectorizer \"\"\"\n",
        "        return self._vectorizer\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        self._target_split = split\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"the primary entry point method for PyTorch datasets\n",
        "        \n",
        "        Args:\n",
        "            index (int): the index to the data point \n",
        "        Returns:\n",
        "            a dictionary holding the data point: (x_data, y_target, class_index)\n",
        "        \"\"\"\n",
        "        row = self._target_df.iloc[index]\n",
        "        \n",
        "        from_vector, to_vector = \\\n",
        "            self._vectorizer.vectorize(row.word, self._max_seq_length)\n",
        "        \n",
        "        classification_index = \\\n",
        "            self._vectorizer.classification_vocab.lookup_token(row.classification)\n",
        "\n",
        "        return {'x_data': from_vector, \n",
        "                'y_target': to_vector, \n",
        "                'class_index': classification_index}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
        "        \n",
        "        Args:\n",
        "            batch_size (int)\n",
        "        Returns:\n",
        "            number of batches in the dataset\n",
        "        \"\"\"\n",
        "        return len(self) // batch_size\n",
        "    \n",
        "def generate_batches(dataset, batch_size, shuffle=True,\n",
        "                     drop_last=True, device=\"cpu\"): \n",
        "    \"\"\"\n",
        "    A generator function which wraps the PyTorch DataLoader. It will \n",
        "      ensure each tensor is on the write device location.\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last)\n",
        "\n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        for name, tensor in data_dict.items():\n",
        "            out_data_dict[name] = data_dict[name].to(device)\n",
        "        yield out_data_dict"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcCvBM1j9_xY"
      },
      "source": [
        "# Word Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w33KikSE-BXG"
      },
      "source": [
        "class WordGenerationModel(nn.Module):\n",
        "    def __init__(self, char_embedding_size, char_vocab_size, rnn_hidden_size, \n",
        "                 batch_first=True, padding_idx=0, dropout_p=0.5):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            char_embedding_size (int): The size of the character embeddings\n",
        "            char_vocab_size (int): The number of characters to embed\n",
        "            rnn_hidden_size (int): The size of the RNN's hidden state\n",
        "            batch_first (bool): Informs whether the input tensors will \n",
        "                have batch or the sequence on the 0th dimension\n",
        "            padding_idx (int): The index for the tensor padding; \n",
        "                see torch.nn.Embedding\n",
        "            dropout_p (float): the probability of zeroing activations using\n",
        "                the dropout method.  higher means more likely to zero.\n",
        "        \"\"\"\n",
        "        super(WordGenerationModel, self).__init__()\n",
        "        \n",
        "        self.char_emb = nn.Embedding(num_embeddings=char_vocab_size,\n",
        "                                     embedding_dim=char_embedding_size,\n",
        "                                     padding_idx=padding_idx)\n",
        "\n",
        "        self.rnn = nn.GRU(input_size=char_embedding_size, \n",
        "                          hidden_size=rnn_hidden_size,\n",
        "                          batch_first=batch_first)\n",
        "        \n",
        "        self.fc = nn.Linear(in_features=rnn_hidden_size, \n",
        "                            out_features=char_vocab_size)\n",
        "        \n",
        "        self._dropout_p = dropout_p\n",
        "\n",
        "    def forward(self, x_in, apply_softmax=False):\n",
        "        \"\"\"The forward pass of the model\n",
        "        \n",
        "        Args:\n",
        "            x_in (torch.Tensor): an input data tensor. \n",
        "                x_in.shape should be (batch, input_dim)\n",
        "            apply_softmax (bool): a flag for the softmax activation\n",
        "                should be false if used with the Cross Entropy losses\n",
        "        Returns:\n",
        "            the resulting tensor. tensor.shape should be (batch, char_vocab_size)\n",
        "        \"\"\"\n",
        "        x_embedded = self.char_emb(x_in)\n",
        "\n",
        "        y_out, _ = self.rnn(x_embedded)\n",
        "\n",
        "        batch_size, seq_size, feat_size = y_out.shape\n",
        "        y_out = y_out.contiguous().view(batch_size * seq_size, feat_size)\n",
        "\n",
        "        y_out = self.fc(F.dropout(y_out, p=self._dropout_p))\n",
        "                         \n",
        "        if apply_softmax:\n",
        "            y_out = F.softmax(y_out, dim=1)\n",
        "            \n",
        "        new_feat_size = y_out.shape[-1]\n",
        "        y_out = y_out.view(batch_size, seq_size, new_feat_size)\n",
        "            \n",
        "        return y_out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGCoOA1M-JMg"
      },
      "source": [
        "def sample_from_model(model, vectorizer, num_samples=1, sample_size=20, \n",
        "                      temperature=1.0):\n",
        "    \"\"\"Sample a sequence of indices from the model\n",
        "    \n",
        "    Args:\n",
        "        model (WordGenerationModel): the trained model\n",
        "        vectorizer (WordVectorizer): the corresponding vectorizer\n",
        "        num_samples (int): the number of samples\n",
        "        sample_size (int): the max length of the samples\n",
        "        temperature (float): accentuates or flattens \n",
        "            the distribution. \n",
        "            0.0 < temperature < 1.0 will make it peakier. \n",
        "            temperature > 1.0 will make it more uniform\n",
        "    Returns:\n",
        "        indices (torch.Tensor): the matrix of indices; \n",
        "        shape = (num_samples, sample_size)\n",
        "    \"\"\"\n",
        "    begin_seq_index = [vectorizer.char_vocab.begin_seq_index \n",
        "                       for _ in range(num_samples)]\n",
        "    begin_seq_index = torch.tensor(begin_seq_index, \n",
        "                                   dtype=torch.int64).unsqueeze(dim=1)\n",
        "    indices = [begin_seq_index]\n",
        "    h_t = None\n",
        "    \n",
        "    for time_step in range(sample_size):\n",
        "        x_t = indices[time_step]\n",
        "        x_emb_t = model.char_emb(x_t)\n",
        "        rnn_out_t, h_t = model.rnn(x_emb_t, h_t)\n",
        "        prediction_vector = model.fc(rnn_out_t.squeeze(dim=1))\n",
        "        probability_vector = F.softmax(prediction_vector / temperature, dim=1)\n",
        "        indices.append(torch.multinomial(probability_vector, num_samples=1))\n",
        "    indices = torch.stack(indices).squeeze().permute(1, 0)\n",
        "    return indices\n",
        "\n",
        "def decode_samples(sampled_indices, vectorizer):\n",
        "    \"\"\"Transform indices into the string form of a word\n",
        "    \n",
        "    Args:\n",
        "        sampled_indices (torch.Tensor): the inidces from `sample_from_model`\n",
        "        vectorizer (WordVectorizer): the corresponding vectorizer\n",
        "    \"\"\"\n",
        "    decoded_words = []\n",
        "    vocab = vectorizer.char_vocab\n",
        "    \n",
        "    for sample_index in range(sampled_indices.shape[0]):\n",
        "        word = \"\"\n",
        "        for time_step in range(sampled_indices.shape[1]):\n",
        "            sample_item = sampled_indices[sample_index, time_step].item()\n",
        "            if sample_item == vocab.begin_seq_index:\n",
        "                continue\n",
        "            elif sample_item == vocab.end_seq_index:\n",
        "                break\n",
        "            else:\n",
        "                word += vocab.lookup_index(sample_item)\n",
        "        decoded_words.append(word)\n",
        "    return decoded_words"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQUIJdm7-M8y"
      },
      "source": [
        "# Training routine\n",
        "\n",
        "Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVhEaA5z-MBc"
      },
      "source": [
        "def make_train_state(args):\n",
        "    return {'stop_early': False,\n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'learning_rate': args.learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': args.model_state_file}\n",
        "\n",
        "def update_train_state(args, model, train_state):\n",
        "    \"\"\"Handle the training state updates.\n",
        "    Components:\n",
        "     - Early Stopping: Prevent overfitting.\n",
        "     - Model Checkpoint: Model is saved if the model is better\n",
        "    \n",
        "    :param args: main arguments\n",
        "    :param model: model to train\n",
        "    :param train_state: a dictionary representing the training state values\n",
        "    :returns:\n",
        "        a new train_state\n",
        "    \"\"\"\n",
        "\n",
        "    # Save one model at least\n",
        "    if train_state['epoch_index'] == 0:\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\n",
        "        train_state['stop_early'] = False\n",
        "\n",
        "    # Save model if performance improved\n",
        "    elif train_state['epoch_index'] >= 1:\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
        "         \n",
        "        # If loss worsened\n",
        "        if loss_t >= loss_tm1:\n",
        "            # Update step\n",
        "            train_state['early_stopping_step'] += 1\n",
        "        # Loss decreased\n",
        "        else:\n",
        "            # Save the best model\n",
        "            if loss_t < train_state['early_stopping_best_val']:\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\n",
        "                train_state['early_stopping_best_val'] = loss_t\n",
        "\n",
        "            # Reset early stopping step\n",
        "            train_state['early_stopping_step'] = 0\n",
        "\n",
        "        # Stop early ?\n",
        "        train_state['stop_early'] = \\\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
        "\n",
        "    return train_state\n",
        "\n",
        "def normalize_sizes(y_pred, y_true):\n",
        "    \"\"\"Normalize tensor sizes\n",
        "    \n",
        "    Args:\n",
        "        y_pred (torch.Tensor): the output of the model\n",
        "            If a 3-dimensional tensor, reshapes to a matrix\n",
        "        y_true (torch.Tensor): the target predictions\n",
        "            If a matrix, reshapes to be a vector\n",
        "    \"\"\"\n",
        "    if len(y_pred.size()) == 3:\n",
        "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
        "    if len(y_true.size()) == 2:\n",
        "        y_true = y_true.contiguous().view(-1)\n",
        "    return y_pred, y_true\n",
        "\n",
        "def compute_accuracy(y_pred, y_true, mask_index):\n",
        "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
        "\n",
        "    _, y_pred_indices = y_pred.max(dim=1)\n",
        "    \n",
        "    correct_indices = torch.eq(y_pred_indices, y_true).float()\n",
        "    valid_indices = torch.ne(y_true, mask_index).float()\n",
        "    \n",
        "    n_correct = (correct_indices * valid_indices).sum().item()\n",
        "    n_valid = valid_indices.sum().item()\n",
        "\n",
        "    return n_correct / n_valid * 100\n",
        "\n",
        "def sequence_loss(y_pred, y_true, mask_index):\n",
        "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
        "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ8oC67-XFq"
      },
      "source": [
        "Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPae1Ke1-UQj"
      },
      "source": [
        "def set_seed_everywhere(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gux7fTG7-Yau"
      },
      "source": [
        "Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZSQZzGocS2i",
        "outputId": "c80b24ae-7ca1-484b-b75e-aa8a5d7d8d08"
      },
      "source": [
        "# to access and save files on google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RnmkCGW-a9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61ff588-479f-4eb4-a31c-1d89c47392ca"
      },
      "source": [
        "args = Namespace(\n",
        "    # Data and Path information\n",
        "    word_csv=\"/content/drive/MyDrive/Lang-and-Mind-Lab/words_doubling.csv\", # CHANGE THIS TO YOUR PATH\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir=\"/content/drive/MyDrive/Lang-and-Mind-Lab\", # CHANGE THIS TO YOUR PATH\n",
        "    # Model hyper parameters\n",
        "    char_embedding_size=32,\n",
        "    rnn_hidden_size=32,\n",
        "    # Training hyper parameters\n",
        "    seed=1337,\n",
        "    learning_rate=0.001,\n",
        "    batch_size=128,\n",
        "    num_epochs=100,\n",
        "    early_stopping_criteria=5,\n",
        "    # Runtime options\n",
        "    catch_keyboard_interrupt=True,\n",
        "    cuda=True,\n",
        "    expand_filepaths_to_save_dir=True,\n",
        "    reload_from_files=False, # change to true after first time running\n",
        ")\n",
        "\n",
        "if args.expand_filepaths_to_save_dir:\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\n",
        "                                        args.vectorizer_file)\n",
        "\n",
        "    args.model_state_file = os.path.join(args.save_dir,\n",
        "                                         args.model_state_file)\n",
        "    \n",
        "    print(\"Expanded filepaths: \")\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\n",
        "    print(\"\\t{}\".format(args.model_state_file))\n",
        "    \n",
        "    \n",
        "# Check CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "    \n",
        "print(\"Using CUDA: {}\".format(args.cuda))\n",
        "\n",
        "# Set seed for reproducibility\n",
        "set_seed_everywhere(args.seed, args.cuda)\n",
        "\n",
        "# handle dirs\n",
        "handle_dirs(args.save_dir)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expanded filepaths: \n",
            "\t/content/drive/MyDrive/Lang-and-Mind-Lab/vectorizer.json\n",
            "\t/content/drive/MyDrive/Lang-and-Mind-Lab/model.pth\n",
            "Using CUDA: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jntkz8JI-dh9"
      },
      "source": [
        "Initializations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEdeHSwz-gaD"
      },
      "source": [
        "if args.reload_from_files:\n",
        "    # training from a checkpoint\n",
        "    dataset = WordDataset.load_dataset_and_load_vectorizer(args.word_csv, args.vectorizer_file)\n",
        "else:\n",
        "    # create dataset and vectorizer\n",
        "    dataset = WordDataset.load_dataset_and_make_vectorizer(args.word_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "\n",
        "vectorizer = dataset.get_vectorizer()\n",
        "\n",
        "model = WordGenerationModel(char_embedding_size=args.char_embedding_size,\n",
        "                               char_vocab_size=len(vectorizer.char_vocab),\n",
        "                               rnn_hidden_size=args.rnn_hidden_size,\n",
        "                               padding_idx=vectorizer.char_vocab.mask_index)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHOKSXvE5A20",
        "outputId": "45cb35fb-e189-41e1-83e7-736733bff2e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# this is useful later if we want to get the probability of a certain char\n",
        "vectorizer.char_vocab._idx_to_token"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '<MASK>',\n",
              " 1: '<UNK>',\n",
              " 2: '<BEGIN>',\n",
              " 3: '<END>',\n",
              " 4: 's',\n",
              " 5: 't',\n",
              " 6: 'a',\n",
              " 7: 'u',\n",
              " 8: 'e',\n",
              " 9: 'o',\n",
              " 10: 'h',\n",
              " 11: 'i',\n",
              " 12: 'b',\n",
              " 13: 'j',\n",
              " 14: 'd',\n",
              " 15: 'r',\n",
              " 16: 'p',\n",
              " 17: 'y',\n",
              " 18: 'c',\n",
              " 19: 'q',\n",
              " 20: 'n',\n",
              " 21: 'l',\n",
              " 22: 'g',\n",
              " 23: 'f',\n",
              " 24: 'k',\n",
              " 25: 'm',\n",
              " 26: 'w',\n",
              " 27: 'x',\n",
              " 28: 'v',\n",
              " 29: 'z',\n",
              " 30: 'T',\n",
              " 31: 'R',\n",
              " 32: 'U',\n",
              " 33: 'E',\n",
              " 34: 'F',\n",
              " 35: 'A',\n",
              " 36: 'L',\n",
              " 37: 'S'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhy4G1pV-kfI"
      },
      "source": [
        "Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO2IKw0K-iK7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230,
          "referenced_widgets": [
            "267a34a2f4cd438bb030e7d25c7b06a7",
            "6c78f5b18ecc4b4cac70b77c34a0bb13",
            "65901777d0a94f72b0ceb2de73e8c36c",
            "8ed6a5ff757b40188ed3bec81ff5f443",
            "a2196613e4554d24adbafcc476648b91",
            "5062f2a268574de48274ae8a6a2fe274",
            "ece2fe70782042a9921e206e5d7597de",
            "7ea58bfaeec3487796e7a3bd5ad2b74d",
            "1c86994870b343628a1b7fcbe0f7c62e",
            "934da7852c294db09e4849537c14be80",
            "b96721b856d945b3b503e7c258f1f8a7",
            "734beee7c47b4b8ebf576aaac30e6295",
            "403ec490fd0b4bd6b338d74efdd80500",
            "86fcb59f8c314b6990d94877701b74c2",
            "f237901722694d12829bce4360bf9357",
            "34821193d4e746efa95acc6a9cd266f7",
            "eccbba6313fe42b9af2ccf20c67f9421",
            "685c3aad640d4303b9d72e85c89bfac2",
            "d418ee366a1e439ca4a030600cccdb35",
            "2cdd4d983b7b43cab4d1ef51d0ce98bf",
            "59a4b285dba548bb9fcf7397750900ab",
            "cc627cc089e046c4ac63128d45d1c07c",
            "851a2fbf3c1d462eae1fa3d21d4874fa",
            "f15666a70b23453d98e2272aab7e730f"
          ]
        },
        "outputId": "7c7a45e6-eb82-41c0-b00e-d43b559a7191"
      },
      "source": [
        "mask_index = vectorizer.char_vocab.mask_index\n",
        "\n",
        "model = model.to(args.device)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                           mode='min', factor=0.5,\n",
        "                                           patience=1)\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm_notebook(desc='training routine', \n",
        "                          total=args.num_epochs,\n",
        "                          position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm_notebook(desc='split=train',\n",
        "                          total=dataset.get_num_batches(args.batch_size), \n",
        "                          position=1, \n",
        "                          leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm_notebook(desc='split=val',\n",
        "                        total=dataset.get_num_batches(args.batch_size), \n",
        "                        position=1, \n",
        "                        leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # Iterate over training dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        model.train()\n",
        "        \n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # the training routine is these 5 steps:\n",
        "\n",
        "            # --------------------------------------    \n",
        "            # step 1. zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # step 2. compute the output\n",
        "            y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "\n",
        "            # step 4. use loss to produce gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # step 5. use optimizer to take gradient step\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            # compute the  running loss and running accuracy\n",
        "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # update bar\n",
        "            train_bar.set_postfix(loss=running_loss,\n",
        "                                  acc=running_acc,\n",
        "                                  epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # Iterate over val dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        model.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # compute the output\n",
        "            y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "            # compute the  running loss and running accuracy\n",
        "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            \n",
        "            # Update bar\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "\n",
        "        train_state = update_train_state(args=args, model=model, \n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "        \n",
        "        # move model to cpu for sampling\n",
        "        model = model.cpu()\n",
        "        sampled_words = decode_samples(\n",
        "            sample_from_model(model, vectorizer, num_samples=2), \n",
        "            vectorizer)\n",
        "        epoch_bar.set_postfix(sample1=sampled_words[0], \n",
        "                              sample2=sampled_words[1])\n",
        "        # move model back to whichever device it should be on\n",
        "        model = model.to(args.device)\n",
        "        \n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "        \n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "267a34a2f4cd438bb030e7d25c7b06a7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c86994870b343628a1b7fcbe0f7c62e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='split=train', max=59.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eccbba6313fe42b9af2ccf20c67f9421",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='split=val', max=9.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-VArXzT-qjk"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVQ3DBn--sey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4dc7ffc-2174-463c-d9d7-8dbb3513355e"
      },
      "source": [
        "np.random.choice(np.arange(len(vectorizer.classification_vocab)), replace=True, size=2) # I think this just shows us how many classes are, if we have different classes"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogzoDm3N5hw7"
      },
      "source": [
        "\"\"\"\n",
        "For reference, the index of each character token in the distribution: CHANGE IF USING NEW DATASET\n",
        "\n",
        "{0: '<MASK>', 1: '<UNK>', 2: '<BEGIN>', 3: '<END>', 4: 'f', 5: 'i', 6: 'o', 7: 'n',\n",
        " 8: 'a', 9: 's', 10: 'h', 11: 't', 12: 'l', 13: 'w', 14: 'e', 15: 'b', 16: 'r', 17: 'u',\n",
        " 18: 'm', 19: 'c', 20: 'k', 21: 'p', 22: 'j', 23: 'd', 24: 'y', 25: 'v', 26: 'g', 27: 'q', \n",
        " 28: 'x', 29: 'z'}\n",
        "\n",
        "\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGzcIknG-I03"
      },
      "source": [
        "Evaluate using actual English words. This will give us an idea of how well the model does with predicting words that are actual in English. That is, for each \n",
        "test sequence, we will compare the probability of the sequence that actually exists in English, with the probability of the sequence that the model generated. We will evaluate using perplexity (2^-log prob of sequence). Lower perplexity means a better prediction was made."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acinRVe2-tMh"
      },
      "source": [
        "\"\"\"\n",
        "Compute the loss & accuracy on the English test set using the best available model.\n",
        "That is, here we are comparing the probability distribution of possible characters that could occur\n",
        "at each position, with what actually occured.\n",
        "\n",
        "y_pred: 128 words in batch, 20 character positions in each word, 38 characters in the distribution <-- NOTE THIS CHANGES WITH DIFFERENT DATASETS, BECAUSE OF HOW MANY CHARS THERE ARE\n",
        "\"\"\"\n",
        "\n",
        "model.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "model = model.to(args.device)\n",
        "\n",
        "dataset.set_split('test')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=args.batch_size, \n",
        "                                   device=args.device)\n",
        "running_acc = 0.\n",
        "model.eval()\n",
        "\n",
        "word_perplexities = {} # maps words --> perplexity values\n",
        "position_perplexities = {} # maps char positions --> perplexity values\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "    # compute the output\n",
        "    y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "    # initialize dictionary\n",
        "    word_perplexities[batch_index] = {}\n",
        "    position_perplexities[batch_index] = {}\n",
        "\n",
        "    # iterate over each word in the batch, and calculate the loss for that word\n",
        "    # save perplexity to dict\n",
        "    start = 0\n",
        "    end = 1\n",
        "    for i in range(128):\n",
        "        \n",
        "        word_loss = sequence_loss(y_pred[start:end,:],batch_dict['y_target'][start:end,:], mask_index)\n",
        "\n",
        "        # reconstruct the word\n",
        "        word = \"\"\n",
        "        start_pos = 0\n",
        "        end_pos = 1\n",
        "        for j in range(20):\n",
        "            curr_char_index = batch_dict['y_target'][i][j].item()\n",
        "            if curr_char_index >= 4:\n",
        "                curr_char = vectorizer.char_vocab._idx_to_token[curr_char_index]\n",
        "                word += curr_char\n",
        "\n",
        "            position_loss = sequence_loss(y_pred[:, start_pos:end_pos],batch_dict['y_target'][:, start_pos:end_pos], mask_index)\n",
        "            position_pp = math.pow(2,position_loss)\n",
        "            position_perplexities[batch_index][j] = position_pp\n",
        "            start_pos += 1\n",
        "            end_pos += 1\n",
        "\n",
        "        pp = math.pow(2,word_loss)\n",
        "        word_perplexities[batch_index][word] = pp\n",
        "\n",
        "        start += 1\n",
        "        end += 1\n",
        "\n",
        "    # compute the loss\n",
        "    loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "    # compute the accuracy\n",
        "    running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss \n",
        "train_state['test_acc'] = running_acc"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCAugUqRLR-q",
        "outputId": "919fec15-9bb4-4ba5-faa5-b6ef0e4df083",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 20, 38])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NoiBWYC-wJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34811f5e-adb3-4352-c092-bcb19a0c6e1c"
      },
      "source": [
        "# print the loss, perplexity, and accuracy for the test set overall\n",
        "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
        "print(\"Test perplexity: {};\".format(math.pow(2,train_state['test_loss'])))\n",
        "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 2.464428285757701;\n",
            "Test perplexity: 5.519081866736541;\n",
            "Test Accuracy: 25.353855215097024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I0XeU2wt-_G",
        "outputId": "2e9f8357-e152-49f9-9157-736983e72934",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# print the perplexity values for each word in the first batch (128 words)\n",
        "# low perplexity values are good\n",
        "\n",
        "flag = 0\n",
        "for b, w_dict in word_perplexities.items():\n",
        "    if flag > 0:\n",
        "            break\n",
        "    for w, p in w_dict.items():\n",
        "        print(\"word: \", w, \" perplexity: \", round(p,2))\n",
        "    flag += 1"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word:  stephanie  perplexity:  7.18\n",
            "word:  states  perplexity:  3.7\n",
            "word:  fbi  perplexity:  10.51\n",
            "word:  performer  perplexity:  3.77\n",
            "word:  opponents  perplexity:  6.93\n",
            "word:  surf  perplexity:  10.09\n",
            "word:  permits  perplexity:  5.7\n",
            "word:  oval  perplexity:  7.05\n",
            "word:  centered  perplexity:  3.79\n",
            "word:  inter  perplexity:  4.17\n",
            "word:  encouraged  perplexity:  5.76\n",
            "word:  similar  perplexity:  5.21\n",
            "word:  affair  perplexity:  8.41\n",
            "word:  reduce  perplexity:  5.49\n",
            "word:  diagnostic  perplexity:  6.69\n",
            "word:  shades  perplexity:  4.7\n",
            "word:  arabia  perplexity:  8.56\n",
            "word:  boston  perplexity:  3.87\n",
            "word:  solid  perplexity:  5.49\n",
            "word:  wisdom  perplexity:  7.62\n",
            "word:  welsh  perplexity:  6.56\n",
            "word:  mediawiki  perplexity:  8.66\n",
            "word:  shopzilla  perplexity:  8.34\n",
            "word:  bare  perplexity:  4.26\n",
            "word:  former  perplexity:  4.97\n",
            "word:  suffered  perplexity:  4.86\n",
            "word:  contracting  perplexity:  3.3\n",
            "word:  college  perplexity:  4.18\n",
            "word:  adviser  perplexity:  6.33\n",
            "word:  fuzzy  perplexity:  9.42\n",
            "word:  temple  perplexity:  4.94\n",
            "word:  pens  perplexity:  6.0\n",
            "word:  ppp  perplexity:  14.71\n",
            "word:  sales  perplexity:  4.26\n",
            "word:  fur  perplexity:  5.61\n",
            "word:  permitted  perplexity:  4.96\n",
            "word:  families  perplexity:  4.75\n",
            "word:  regional  perplexity:  5.43\n",
            "word:  ic  perplexity:  11.07\n",
            "word:  build  perplexity:  5.54\n",
            "word:  radar  perplexity:  5.67\n",
            "word:  goes  perplexity:  6.19\n",
            "word:  departure  perplexity:  4.81\n",
            "word:  hill  perplexity:  5.7\n",
            "word:  dialog  perplexity:  6.7\n",
            "word:  prediction  perplexity:  3.43\n",
            "word:  hats  perplexity:  5.51\n",
            "word:  packard  perplexity:  4.96\n",
            "word:  avg  perplexity:  12.12\n",
            "word:  quit  perplexity:  7.17\n",
            "word:  principles  perplexity:  5.56\n",
            "word:  negative  perplexity:  4.72\n",
            "word:  meals  perplexity:  4.34\n",
            "word:  segment  perplexity:  4.53\n",
            "word:  poison  perplexity:  7.28\n",
            "word:  notice  perplexity:  5.52\n",
            "word:  mirror  perplexity:  5.74\n",
            "word:  joyce  perplexity:  9.76\n",
            "word:  preferred  perplexity:  4.17\n",
            "word:  position  perplexity:  3.96\n",
            "word:  phpbb  perplexity:  19.91\n",
            "word:  deborah  perplexity:  6.46\n",
            "word:  treatment  perplexity:  4.94\n",
            "word:  subsequently  perplexity:  6.27\n",
            "word:  vampire  perplexity:  5.87\n",
            "word:  cache  perplexity:  5.85\n",
            "word:  hungarian  perplexity:  3.98\n",
            "word:  mountain  perplexity:  5.14\n",
            "word:  hardware  perplexity:  6.05\n",
            "word:  terrain  perplexity:  4.73\n",
            "word:  wheels  perplexity:  5.66\n",
            "word:  cabinet  perplexity:  4.8\n",
            "word:  names  perplexity:  4.14\n",
            "word:  scary  perplexity:  4.34\n",
            "word:  usgs  perplexity:  7.88\n",
            "word:  beverage  perplexity:  5.39\n",
            "word:  ceiling  perplexity:  4.49\n",
            "word:  beside  perplexity:  5.25\n",
            "word:  lie  perplexity:  7.34\n",
            "word:  cingular  perplexity:  5.01\n",
            "word:  republic  perplexity:  6.13\n",
            "word:  addressed  perplexity:  5.51\n",
            "word:  killer  perplexity:  6.3\n",
            "word:  magnificent  perplexity:  6.27\n",
            "word:  towards  perplexity:  6.58\n",
            "word:  trembl  perplexity:  5.78\n",
            "word:  nearby  perplexity:  7.4\n",
            "word:  cooperation  perplexity:  3.76\n",
            "word:  stream  perplexity:  5.43\n",
            "word:  diseases  perplexity:  4.8\n",
            "word:  lawyers  perplexity:  6.67\n",
            "word:  wilson  perplexity:  5.3\n",
            "word:  xx  perplexity:  55.11\n",
            "word:  aviation  perplexity:  4.59\n",
            "word:  midlands  perplexity:  5.29\n",
            "word:  forestry  perplexity:  5.64\n",
            "word:  ascii  perplexity:  11.89\n",
            "word:  aged  perplexity:  7.04\n",
            "word:  mpeg  perplexity:  8.37\n",
            "word:  knights  perplexity:  9.11\n",
            "word:  dry  perplexity:  7.65\n",
            "word:  ill  perplexity:  8.85\n",
            "word:  wrong  perplexity:  5.52\n",
            "word:  atmospheric  perplexity:  6.9\n",
            "word:  alex  perplexity:  8.0\n",
            "word:  anyone  perplexity:  6.36\n",
            "word:  ranks  perplexity:  5.71\n",
            "word:  polyphonic  perplexity:  5.61\n",
            "word:  designation  perplexity:  3.79\n",
            "word:  break  perplexity:  5.41\n",
            "word:  kept  perplexity:  6.83\n",
            "word:  running  perplexity:  4.37\n",
            "word:  pushed  perplexity:  4.77\n",
            "word:  municipal  perplexity:  6.5\n",
            "word:  flexibility  perplexity:  6.29\n",
            "word:  crucial  perplexity:  5.36\n",
            "word:  communicate  perplexity:  4.75\n",
            "word:  sounds  perplexity:  5.38\n",
            "word:  meeting  perplexity:  3.8\n",
            "word:  futures  perplexity:  4.75\n",
            "word:  re  perplexity:  6.61\n",
            "word:  twelve  perplexity:  6.64\n",
            "word:  fame  perplexity:  5.42\n",
            "word:  miracle  perplexity:  4.81\n",
            "word:  settle  perplexity:  5.36\n",
            "word:  conditional  perplexity:  4.2\n",
            "word:  essential  perplexity:  4.55\n",
            "word:  groups  perplexity:  6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIeXrJHzHQKs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "dbd92616-5ac3-49b6-eb5e-03a8c52707a5"
      },
      "source": [
        "# get the perpelxity at each character position (averaged over each doubling word)\n",
        "avgs = {}\n",
        "for batch, char_dict in position_perplexities.items():\n",
        "    for ch, p in char_dict.items():\n",
        "        if avgs.get(ch):\n",
        "            avgs[ch] += p\n",
        "        else:\n",
        "            avgs[ch] = p\n",
        "avgs = {k: v / 20 for k, v in avgs.items()} # change this for num of chars\n",
        "\n",
        "# plot\n",
        "df = pd.DataFrame(list(avgs.items()), columns=['Character Positions', 'English']) \n",
        "plt.bar(df['Character Positions'], df['English'], color='purple', width=0.5)\n",
        "plt.title('English words')\n",
        "plt.xlabel('Character positions')\n",
        "plt.ylabel('Avg. perplexities')\n",
        "plt.xlim(0,29)\n",
        "plt.xticks(np.arange(0, 20, 1))\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 4)\n",
        "plt.show()\n",
        "print('\\n')\n",
        "\n",
        "# note that many of the character positions at the end are not real. Since\n",
        "# the model needs each word to be the same length, a \"mask\" character is created\n",
        "# for shorter words, and that probability is not counted overall when looking \n",
        "# at the probabilty of that word. So the end of the graph doesn't tell us a ton.\n",
        "\n",
        "# Each word should have high perplexity in the beginning, because the more \n",
        "# observations that a model sees, the less \"perlexed\" it will be, and it has\n",
        "# observed little in the beginning of the word. As we get farther into the word\n",
        "# perplexity should decrease. This isn't happening right now, but a lot of \n",
        "# the words aren't very representative of English. \n",
        "\n",
        "# However, I would guess that for doubling words, the model would get more \n",
        "# perplexed towards the end of the word as well, when the doubling occurs, \n",
        "# as doubling is not expected. I'm not sure how the non-words without doubling\n",
        "# will perform. They may have higher perpelxity than the actual English words,\n",
        "# but lower than the non-words with doubling. "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hTJdNIV-vGv"
      },
      "source": [
        "Evaluate the model using non-words that have doubling. We would predict that the perplexity of these words would be higher than those that do not have doubling. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lK0eb2ztB0W"
      },
      "source": [
        "# test doubling words\n",
        "\n",
        "model.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "model = model.to(args.device)\n",
        "\n",
        "dataset.set_split('doubling')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=1, # we change the batch size to 1, since we don't have many words we are working with\n",
        "                                   device=args.device)\n",
        "\n",
        "\n",
        "running_acc = 0.\n",
        "model.eval()\n",
        "\n",
        "word_perplexities_doubling = {} # maps words --> perplexity values\n",
        "position_perplexities_doubling = {} # maps char positions --> perplexity values\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "    # compute the output\n",
        "    y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "    # initialize dictionary\n",
        "    word_perplexities_doubling[batch_index] = {}\n",
        "    position_perplexities_doubling[batch_index] = {}\n",
        "\n",
        "    # iterate over each word in the batch, and calculate the loss for that word\n",
        "    # save perplexity to dict\n",
        "    start = 0\n",
        "    end = 1\n",
        "    for i in range(1):\n",
        "        word_loss = sequence_loss(y_pred[start:end,:],batch_dict['y_target'][start:end,:], mask_index)\n",
        "\n",
        "        # reconstruct the word and get perplexity at each char position\n",
        "        word = \"\"\n",
        "        start_pos = 0\n",
        "        end_pos = 1\n",
        "        for j in range(20):\n",
        "            curr_char_index = batch_dict['y_target'][i][j].item()\n",
        "            if curr_char_index >= 4:\n",
        "                curr_char = vectorizer.char_vocab._idx_to_token[curr_char_index]\n",
        "                word += curr_char\n",
        "\n",
        "            position_loss = sequence_loss(y_pred[:, start_pos:end_pos],batch_dict['y_target'][:, start_pos:end_pos], mask_index)\n",
        "            position_pp = math.pow(2,position_loss)\n",
        "            position_perplexities_doubling[batch_index][j] = position_pp\n",
        "            start_pos += 1\n",
        "            end_pos += 1\n",
        "\n",
        "        pp = math.pow(2,word_loss)\n",
        "        word_perplexities_doubling[batch_index][word] = pp\n",
        "\n",
        "        start += 1\n",
        "        end += 1\n",
        "\n",
        "    # compute the loss\n",
        "    loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "    # compute the accuracy\n",
        "    running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss \n",
        "train_state['test_acc'] = running_acc"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czkYOh0RMJqO",
        "outputId": "949f5225-464e-4f1d-a03b-449b1a3e6235",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20, 38])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnXu7uyH9a60",
        "outputId": "0734c17c-f561-4fb9-f9cb-adc393205891"
      },
      "source": [
        "# print the loss, perplexity, and accuracy for the doubling set overall\n",
        "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
        "print(\"Test perplexity: {};\".format(math.pow(2,train_state['test_loss'])))\n",
        "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 2.8126780850546704;\n",
            "Test perplexity: 7.025875856136567;\n",
            "Test Accuracy: 15.357142857142858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS8YDxwL9ASu",
        "outputId": "cfa187c6-1ce5-423d-caef-b28b86405a00"
      },
      "source": [
        "# Print the perplexities for each word\n",
        "for b, w_dict in word_perplexities_doubling.items():\n",
        "    for w, p in w_dict.items():\n",
        "        print(\"word: \", w, \" perplexity: \", round(p,2))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word:  trafraf  perplexity:  7.88\n",
            "word:  blaslas  perplexity:  6.71\n",
            "word:  granran  perplexity:  6.86\n",
            "word:  blaflaf  perplexity:  7.67\n",
            "word:  plonlon  perplexity:  5.62\n",
            "word:  trosros  perplexity:  5.84\n",
            "word:  blatlat  perplexity:  6.27\n",
            "word:  flonlon  perplexity:  5.66\n",
            "word:  trelrel  perplexity:  4.98\n",
            "word:  frosros  perplexity:  7.07\n",
            "word:  kragrag  perplexity:  6.36\n",
            "word:  snadnad  perplexity:  8.92\n",
            "word:  frebreb  perplexity:  6.37\n",
            "word:  drofrof  perplexity:  8.93\n",
            "word:  prafraf  perplexity:  6.67\n",
            "word:  klenlen  perplexity:  6.34\n",
            "word:  grefref  perplexity:  6.22\n",
            "word:  snognog  perplexity:  8.72\n",
            "word:  flaklak  perplexity:  9.09\n",
            "word:  kravrav  perplexity:  10.89\n",
            "word:  tramram  perplexity:  6.18\n",
            "word:  franran  perplexity:  5.34\n",
            "word:  grofrof  perplexity:  6.54\n",
            "word:  flamlam  perplexity:  7.8\n",
            "word:  plaflaf  perplexity:  7.95\n",
            "word:  slodlod  perplexity:  6.83\n",
            "word:  premrem  perplexity:  4.79\n",
            "word:  drakrak  perplexity:  8.84\n",
            "word:  kloplop  perplexity:  11.17\n",
            "word:  smolmol  perplexity:  7.12\n",
            "word:  stimtim  perplexity:  6.81\n",
            "word:  slanlan  perplexity:  5.81\n",
            "word:  smatmat  perplexity:  7.86\n",
            "word:  dranran  perplexity:  6.64\n",
            "word:  fliblib  perplexity:  8.09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-57V3aYEd_o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "a5cc1e48-612d-4d07-b8eb-a4a25f23f6bb"
      },
      "source": [
        "# get the perpelxity at each character position (averaged over each doubling word)\n",
        "avgs_doubling = {}\n",
        "for batch, char_dict in position_perplexities_doubling.items():\n",
        "    for ch, p in char_dict.items():\n",
        "        if avgs_doubling.get(ch):\n",
        "            avgs_doubling[ch] += p\n",
        "        else:\n",
        "            avgs_doubling[ch] = p\n",
        "avgs_doubling = {k: v / 20 for k, v in avgs_doubling.items()}\n",
        "\n",
        "# plot\n",
        "df_doubling = pd.DataFrame(list(avgs_doubling.items()), columns=['Character Positions', 'doubling']) \n",
        "plt.bar(df_doubling['Character Positions'], df_doubling['doubling'], color='orange', width=0.5)\n",
        "plt.title('Doubling words')\n",
        "plt.xlabel('Character positions')\n",
        "plt.ylabel('Avg. perplexities')\n",
        "plt.xlim(0,6)\n",
        "plt.xticks(np.arange(0, 6, 1))\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
        "plt.show()\n",
        "print('\\n')\n",
        "\n",
        "# Each word should have high perplexity in the begining, because the more \n",
        "# observations that a model sees, the less \"perlexed\" it will be, and it has\n",
        "# observed little in the beginning of the word. However, I would guess that\n",
        "# for doubling words, the model would get more perplexed towards the end\n",
        "# of the word as well, when the doubling occurs, as that is not expected.\n",
        "# On the other hand, I would expect perplexity to go down later in the word\n",
        "# for words without doubling. "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOaS7UAY_DZT"
      },
      "source": [
        "Evaluate the model using non-words that do not have doubling. The perplexity of these words should be similar to that of actual English words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkEfde5M9ng1"
      },
      "source": [
        "# test control words (non-words, no doubling)\n",
        "\n",
        "model.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "model = model.to(args.device)\n",
        "\n",
        "dataset.set_split('no_doubling')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=1, # we change the batch size to 1, since we don't have many words we are working with\n",
        "                                   device=args.device)\n",
        "\n",
        "\n",
        "running_acc = 0.\n",
        "model.eval()\n",
        "\n",
        "word_perplexities_control = {} # maps words --> perplexity values\n",
        "position_perplexities_control = {}\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "    # compute the output\n",
        "    y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "    # initialize dictionary\n",
        "    word_perplexities_control[batch_index] = {}\n",
        "    position_perplexities_control[batch_index] = {}\n",
        "\n",
        "    # iterate over each word in the batch, and calculate the loss for that word\n",
        "    # save perplexity to dict\n",
        "    start = 0\n",
        "    end = 1\n",
        "    for i in range(1):\n",
        "        word_loss = sequence_loss(y_pred[start:end,:],batch_dict['y_target'][start:end,:], mask_index)\n",
        "\n",
        "        # reconstruct the word and pp at each char posiiton\n",
        "        word = \"\"\n",
        "        start_pos = 0\n",
        "        end_pos = 1\n",
        "        for j in range(20):\n",
        "            curr_char_index = batch_dict['y_target'][i][j].item()\n",
        "            if curr_char_index >= 4:\n",
        "                curr_char = vectorizer.char_vocab._idx_to_token[curr_char_index]\n",
        "                word += curr_char\n",
        "\n",
        "            position_loss = sequence_loss(y_pred[:, start_pos:end_pos],batch_dict['y_target'][:, start_pos:end_pos], mask_index)\n",
        "            position_pp = math.pow(2,position_loss)\n",
        "            position_perplexities_control[batch_index][j] = position_pp\n",
        "            start_pos += 1\n",
        "            end_pos += 1\n",
        "\n",
        "        pp = math.pow(2,word_loss)\n",
        "        word_perplexities_control[batch_index][word] = pp\n",
        "\n",
        "        start += 1\n",
        "        end += 1\n",
        "\n",
        "    # compute the loss\n",
        "    loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "    # compute the accuracy\n",
        "    running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss \n",
        "train_state['test_acc'] = running_acc"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n6ON6wp9uCd",
        "outputId": "649a9305-d13e-4f8f-b316-de3c28fb8c59"
      },
      "source": [
        "# print the loss, perplexity, and accuracy for the doubling set overall\n",
        "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
        "print(\"Test perplexity: {};\".format(math.pow(2,train_state['test_loss'])))\n",
        "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 2.8101833207266673;\n",
            "Test perplexity: 7.013736937149879;\n",
            "Test Accuracy: 17.777777777777782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McjjRGs09uO2",
        "outputId": "ece853b5-4753-450d-87c1-93f97beb4ed6"
      },
      "source": [
        "# print the perplexities for each word\n",
        "for b, w_dict in word_perplexities_control.items():\n",
        "    for w, p in w_dict.items():\n",
        "        print(\"word: \", w, \" perplexity: \", round(p,2))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word:  premlek  perplexity:  5.92\n",
            "word:  greflek  perplexity:  6.26\n",
            "word:  flonmog  perplexity:  8.26\n",
            "word:  kragnel  perplexity:  8.38\n",
            "word:  trosnot  perplexity:  5.33\n",
            "word:  flibnep  perplexity:  6.86\n",
            "word:  freblek  perplexity:  5.7\n",
            "word:  praflak  perplexity:  5.87\n",
            "word:  slanmot  perplexity:  7.76\n",
            "word:  smatnod  perplexity:  7.58\n",
            "word:  snadmak  perplexity:  7.9\n",
            "word:  flakmal  perplexity:  6.05\n",
            "word:  slodmog  perplexity:  8.02\n",
            "word:  grofnom  perplexity:  5.24\n",
            "word:  klennmof  perplexity:  11.6\n",
            "word:  plafnut  perplexity:  7.47\n",
            "word:  blatnog  perplexity:  9.02\n",
            "word:  granlat  perplexity:  5.02\n",
            "word:  dranlat  perplexity:  5.42\n",
            "word:  flamrad  perplexity:  7.44\n",
            "word:  stimkam  perplexity:  7.68\n",
            "word:  klopnosh  perplexity:  10.53\n",
            "word:  tramlut  perplexity:  5.49\n",
            "word:  blafron  perplexity:  6.77\n",
            "word:  droffmok  perplexity:  10.25\n",
            "word:  draknad  perplexity:  7.42\n",
            "word:  traflam  perplexity:  6.64\n",
            "word:  snogmot  perplexity:  10.61\n",
            "word:  kravmal  perplexity:  6.92\n",
            "word:  smolrog  perplexity:  8.64\n",
            "word:  trelnat  perplexity:  4.88\n",
            "word:  blasnol  perplexity:  6.5\n",
            "word:  plonmuk  perplexity:  9.46\n",
            "word:  froslak  perplexity:  5.72\n",
            "word:  franmet  perplexity:  4.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUnMeF-gGFOG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "365ce6d7-2710-4c71-969d-98350728066b"
      },
      "source": [
        "# get the perpelxity at each character position (averaged over each non-doubling word)\n",
        "avgs_control = {}\n",
        "for batch, char_dict in position_perplexities_control.items():\n",
        "    for ch, p in char_dict.items():\n",
        "        if avgs_control.get(ch):\n",
        "            avgs_control[ch] += p\n",
        "        else:\n",
        "            avgs_control[ch] = p\n",
        "avgs_control = {k: v / 20 for k, v in avgs_control.items()}\n",
        "\n",
        "# plot\n",
        "df_control = pd.DataFrame(list(avgs_control.items()), columns=['Character Positions', 'control']) \n",
        "plt.bar(df_control['Character Positions'], df_control['control'], color='green', width=0.5)\n",
        "plt.title('Control non-words')\n",
        "plt.xlabel('Character positions')\n",
        "plt.ylabel('Avg. perplexities')\n",
        "plt.xlim(0,6)\n",
        "plt.xticks(np.arange(0, 6, 1))\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
        "plt.show()\n",
        "print('\\n')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLuqxq9iKGSg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "bf449bbb-86e5-4d01-ddf7-86dc6c033db3"
      },
      "source": [
        "# plot English test words, doubling non-words, and control non-words together\n",
        "# combined plot\n",
        "df_doubling_pp = df_doubling[\"doubling\"]\n",
        "df_control_pp = df_control[\"control\"]\n",
        "all_data = df.join(df_doubling_pp)\n",
        "all_data = all_data.join(df_control_pp)\n",
        "plt.plot(all_data[\"English\"], label='English', color=\"purple\")\n",
        "plt.plot(all_data[\"doubling\"], label='Doubling non-words', color=\"orange\")\n",
        "plt.plot(all_data[\"control\"], label='Control non-words', color=\"green\")\n",
        "plt.title('Perplexity by character position')\n",
        "plt.xlabel('Character positions')\n",
        "plt.ylabel('Avg. perplexities')\n",
        "plt.legend()\n",
        "plt.xlim(0,10)\n",
        "plt.xticks(np.arange(0, 10, 1))\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE7UzCKe-0jT"
      },
      "source": [
        "# Generate new words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF2dX7qQ_LpN"
      },
      "source": [
        "We can have the model generate words, and count the words that have doubling in them (a model that has learned English well, would not have many words with doubling?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPgUqGDF-yZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1b74f8-b93b-401c-d37a-e231986b8003"
      },
      "source": [
        "# number of names to generate\n",
        "num_words = 20\n",
        "model = model.cpu()\n",
        "# Generate nationality hidden state\n",
        "sampled_words = decode_samples(\n",
        "    sample_from_model(model, vectorizer, num_samples=num_words), \n",
        "    vectorizer)\n",
        "# Show results\n",
        "print (\"-\"*15)\n",
        "for i in range(num_words):\n",
        "    print (sampled_words[i])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------\n",
            "lecaderLrmecs\n",
            "accoccuytal\n",
            "dilire\n",
            "rofamict\n",
            "obmcnecrieds\n",
            "bummere\n",
            "des\n",
            "mipt\n",
            "abhl\n",
            "palfes\n",
            "pxlure\n",
            "icolic\n",
            "pbor\n",
            "wanyac\n",
            "atibakiud\n",
            "hnakul\n",
            "benlexs\n",
            "detons\n",
            "arfhion\n",
            "cenpimalemer\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}