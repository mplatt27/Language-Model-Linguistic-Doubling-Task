{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelEvaluation.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/mplatt27/Language-Model-Linguistic-Doubling-Task/blob/main/LanguageModel.ipynb",
      "authorship_tag": "ABX9TyP0zrHtIpasfLAAslqefc2X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0fcc4a2f6b754de396bdb9eee340f93a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0cc4c5098fc743198a8d8ebad10f138e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_39aabd6237814d709ebbfea93a926389",
              "IPY_MODEL_f71d8360b27c43afa18c6604770d9a6b"
            ]
          }
        },
        "0cc4c5098fc743198a8d8ebad10f138e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39aabd6237814d709ebbfea93a926389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_13eeab08f272488aa6be4a327eb00268",
            "_dom_classes": [],
            "description": "training routine: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94c7ddecf68b4dd3a68c005e8df1595c"
          }
        },
        "f71d8360b27c43afa18c6604770d9a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bddc34014d27442284cf1f60e8d11ec6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [05:43&lt;00:00,  3.44s/it, sample1=bacy, sample2=nexers]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c00e7f3eb1414eaba4e7942c336800f7"
          }
        },
        "13eeab08f272488aa6be4a327eb00268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94c7ddecf68b4dd3a68c005e8df1595c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bddc34014d27442284cf1f60e8d11ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c00e7f3eb1414eaba4e7942c336800f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b34d2102a5e439fa8132a90f9741dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8780615a0da340e1b0714b1f5ef1cd9e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_448f5f30d1c040babbb43a4d864b75d8",
              "IPY_MODEL_6dc500d800bd4c56b1fd901ba85baa48"
            ]
          }
        },
        "8780615a0da340e1b0714b1f5ef1cd9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "448f5f30d1c040babbb43a4d864b75d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c7a055c1d7646cd86851162c52bb568",
            "_dom_classes": [],
            "description": "split=train:  98%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 59,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 58,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10ee71a7b44a4104a15ef35c34b3b4ce"
          }
        },
        "6dc500d800bd4c56b1fd901ba85baa48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1631e034781f42f0bcc1ad3e2dae750e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 58/59 [05:42&lt;00:00,  1.50it/s, acc=25.7, epoch=99, loss=2.45]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e913f39af8cf480fa91713e4581a4fec"
          }
        },
        "8c7a055c1d7646cd86851162c52bb568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10ee71a7b44a4104a15ef35c34b3b4ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1631e034781f42f0bcc1ad3e2dae750e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e913f39af8cf480fa91713e4581a4fec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e9f1a85372b462483270ce45b22ed3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bcba07351247448eb881042ac2ece38d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_34c78331659f476c8fc90cd1fea88597",
              "IPY_MODEL_537137b8f06f4ca3924c95a5caeae0b5"
            ]
          }
        },
        "bcba07351247448eb881042ac2ece38d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34c78331659f476c8fc90cd1fea88597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_58e70214b3944f398ececc0cfb62b63f",
            "_dom_classes": [],
            "description": "split=val:  89%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 9,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9b62a7bf909439fb64669afe845b40d"
          }
        },
        "537137b8f06f4ca3924c95a5caeae0b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_413f0aad9c2842aa8c7873c0d6e03227",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8/9 [05:43&lt;00:01,  1.83s/it, acc=26.4, epoch=99, loss=2.45]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_143848ccf6e04f239abe26fe1bd21802"
          }
        },
        "58e70214b3944f398ececc0cfb62b63f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9b62a7bf909439fb64669afe845b40d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "413f0aad9c2842aa8c7873c0d6e03227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "143848ccf6e04f239abe26fe1bd21802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mplatt27/Language-Model-Linguistic-Doubling-Task/blob/main/LanguageModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bymBLatcwZz_"
      },
      "source": [
        "# Character-level English Language Model\n",
        "\n",
        "*Langauge and Mind Lab*\n",
        "\n",
        "\n",
        "All code is adapted from the book: Natural Language Processing with PyTorch: Build Intelligent Language Applications Using Deep Learning, by Delip Rao and Brian McMahan. The original code is available here: https://github.com/joosthub/PyTorchNLPBook. \n",
        "\n",
        "The model uses a Gated Recurrent Unit (GRU) neural network and is trained on a set of ### English words from \"\". We then evaluate the model with a test set of novel words that both have and do not have linguistic doubling, to determine if the model has learned preferences that are observed in English speakers. We can also generate novel words and look for features like linguistic doubling. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWHsiuY6nUsY"
      },
      "source": [
        "Notes on dataset:\n",
        "\n",
        "*   Retrieved from https://www.kaggle.com/rtatman/english-word-frequency and contains 333,333 unique words.\n",
        "*   I first shuffled the words in the spreadsheet, then took the first ~10,000 words to use (the original code uses a smaller dataset around this size, so as a first attempt on this project, I used a shortened version of the word dataset). We can increase this size later if we want\n",
        "*   I then labeled approximatley 70% as the training set, 15% as the validation set, and 15% as the test set. The test set will be used as a proof of concept to see how the model does with words that are true English words that the model has never seen before. \n",
        "*   I then added to the data set, ~30 \"slaflaf\" words that I found (they may not be the more recent versions) both with doubling and the control matched pair without doubling (i.e., \"slafmat\").\n",
        "*   Looking over the English words in the dataset in detail, I'm not sure this is what we want to use for the final version, as many words are strange and something I have never seen before. We can keep searching, but this at least shows us that the code works and we can replace the dataset as long as it is in the same format.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpfKJcY39nvZ"
      },
      "source": [
        "# Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuIZa6uj9oAC"
      },
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6n06uyV9vDy"
      },
      "source": [
        "# Data Vectorization classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woqkA8VU9tc0"
      },
      "source": [
        "class Vocabulary(object):\n",
        "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
        "\n",
        "    def __init__(self, token_to_idx=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
        "        \"\"\"\n",
        "\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self._token_to_idx = token_to_idx\n",
        "\n",
        "        self._idx_to_token = {idx: token \n",
        "                              for token, idx in self._token_to_idx.items()}\n",
        "        \n",
        "    def to_serializable(self):\n",
        "        \"\"\" returns a dictionary that can be serialized \"\"\"\n",
        "        return {'token_to_idx': self._token_to_idx}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        \"\"\"Update mapping dicts based on the token.\n",
        "\n",
        "        Args:\n",
        "            token (str): the item to add into the Vocabulary\n",
        "        Returns:\n",
        "            index (int): the integer corresponding to the token\n",
        "        \"\"\"\n",
        "        if token in self._token_to_idx:\n",
        "            index = self._token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self._token_to_idx)\n",
        "            self._token_to_idx[token] = index\n",
        "            self._idx_to_token[index] = token\n",
        "        return index\n",
        "            \n",
        "    def add_many(self, tokens):\n",
        "        \"\"\"Add a list of tokens into the Vocabulary\n",
        "        \n",
        "        Args:\n",
        "            tokens (list): a list of string tokens\n",
        "        Returns:\n",
        "            indices (list): a list of indices corresponding to the tokens\n",
        "        \"\"\"\n",
        "        return [self.add_token(token) for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"Retrieve the index associated with the token \n",
        "        \n",
        "        Args:\n",
        "            token (str): the token to look up \n",
        "        Returns:\n",
        "            index (int): the index corresponding to the token\n",
        "        \"\"\"\n",
        "        return self._token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        \"\"\"Return the token associated with the index\n",
        "        \n",
        "        Args: \n",
        "            index (int): the index to look up\n",
        "        Returns:\n",
        "            token (str): the token corresponding to the index\n",
        "        Raises:\n",
        "            KeyError: if the index is not in the Vocabulary\n",
        "        \"\"\"\n",
        "        if index not in self._idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self._idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._token_to_idx)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbYTG8LH9z5m"
      },
      "source": [
        "class SequenceVocabulary(Vocabulary):\n",
        "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
        "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
        "                 end_seq_token=\"<END>\"):\n",
        "\n",
        "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
        "\n",
        "        self._mask_token = mask_token\n",
        "        self._unk_token = unk_token\n",
        "        self._begin_seq_token = begin_seq_token\n",
        "        self._end_seq_token = end_seq_token\n",
        "\n",
        "        self.mask_index = self.add_token(self._mask_token)\n",
        "        self.unk_index = self.add_token(self._unk_token)\n",
        "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
        "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        contents = super(SequenceVocabulary, self).to_serializable()\n",
        "        contents.update({'unk_token': self._unk_token,\n",
        "                         'mask_token': self._mask_token,\n",
        "                         'begin_seq_token': self._begin_seq_token,\n",
        "                         'end_seq_token': self._end_seq_token})\n",
        "        return contents\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"Retrieve the index associated with the token \n",
        "          or the UNK index if token isn't present.\n",
        "        \n",
        "        Args:\n",
        "            token (str): the token to look up \n",
        "        Returns:\n",
        "            index (int): the index corresponding to the token\n",
        "        Notes:\n",
        "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
        "              for the UNK functionality \n",
        "        \"\"\"\n",
        "        if self.unk_index >= 0:\n",
        "            return self._token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            return self._token_to_idx[token]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRDY-lT992oJ"
      },
      "source": [
        "# Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liiGfSkL94h9"
      },
      "source": [
        "class WordVectorizer(object):\n",
        "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"    \n",
        "    def __init__(self, char_vocab, classification_vocab):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            char_vocab (Vocabulary): maps words to integers\n",
        "            classification_vocab (Vocabulary): maps classes to integers\n",
        "        \"\"\"\n",
        "        self.char_vocab = char_vocab\n",
        "        self.classification_vocab = classification_vocab\n",
        "\n",
        "    def vectorize(self, word, vector_length=-1):\n",
        "        \"\"\"Vectorize a word into a vector of observations and targets\n",
        "        \n",
        "        The outputs are the vectorized word split into two vectors:\n",
        "            word[:-1] and word[1:]\n",
        "        At each timestep, the first vector is the observation and the second vector is the target. \n",
        "        \n",
        "        Args:\n",
        "            word (str): the word to be vectorized\n",
        "            vector_length (int): an argument for forcing the length of index vector\n",
        "        Returns:\n",
        "            a tuple: (from_vector, to_vector)\n",
        "            from_vector (numpy.ndarray): the observation vector \n",
        "            to_vector (numpy.ndarray): the target prediction vector\n",
        "        \"\"\"\n",
        "        indices = [self.char_vocab.begin_seq_index] \n",
        "        indices.extend(self.char_vocab.lookup_token(token) for token in word)\n",
        "        indices.append(self.char_vocab.end_seq_index)\n",
        "\n",
        "        if vector_length < 0:\n",
        "            vector_length = len(indices) - 1\n",
        "\n",
        "        from_vector = np.empty(vector_length, dtype=np.int64)         \n",
        "        from_indices = indices[:-1]\n",
        "        from_vector[:len(from_indices)] = from_indices\n",
        "        from_vector[len(from_indices):] = self.char_vocab.mask_index\n",
        "\n",
        "        to_vector = np.empty(vector_length, dtype=np.int64)\n",
        "        to_indices = indices[1:]\n",
        "        to_vector[:len(to_indices)] = to_indices\n",
        "        to_vector[len(to_indices):] = self.char_vocab.mask_index\n",
        "        \n",
        "        return from_vector, to_vector\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, word_df):\n",
        "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
        "        \n",
        "        Args:\n",
        "            word_df (pandas.DataFrame): the word dataset\n",
        "        Returns:\n",
        "            an instance of the WordVectorizer\n",
        "        \"\"\"\n",
        "        char_vocab = SequenceVocabulary()\n",
        "        classification_vocab = Vocabulary()\n",
        "\n",
        "        for index, row in word_df.iterrows():\n",
        "            for char in row.word:\n",
        "                char_vocab.add_token(char)\n",
        "            classification_vocab.add_token(row.classification)\n",
        "\n",
        "        return cls(char_vocab, classification_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\"Instantiate the vectorizer from saved contents\n",
        "        \n",
        "        Args:\n",
        "            contents (dict): a dict holding two vocabularies for this vectorizer\n",
        "                This dictionary is created using `vectorizer.to_serializable()`\n",
        "        Returns:\n",
        "            an instance of WordVectorizer\n",
        "        \"\"\"\n",
        "        char_vocab = SequenceVocabulary.from_serializable(contents['char_vocab'])\n",
        "        class_vocab =  Vocabulary.from_serializable(contents['classification_vocab'])\n",
        "\n",
        "        return cls(char_vocab=char_vocab, classification_vocab=nat_vocab)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        \"\"\" Returns the serializable contents \"\"\"\n",
        "        return {'char_vocab': self.char_vocab.to_serializable(), \n",
        "                'classification_vocab': self.classification_vocab.to_serializable()}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlu4nKW696x8"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo824x6m98cd"
      },
      "source": [
        "class WordDataset(Dataset):\n",
        "    def __init__(self, word_df, vectorizer):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            word_df (pandas.DataFrame): the dataset\n",
        "            vectorizer (WordVectorizer): vectorizer instatiated from dataset\n",
        "        \"\"\"\n",
        "        self.word_df = word_df \n",
        "        self._vectorizer = vectorizer\n",
        "\n",
        "        self._max_seq_length = max(map(len, self.word_df.word)) + 2\n",
        "\n",
        "        self.train_df = self.word_df[self.word_df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.word_df[self.word_df.split=='val']\n",
        "        self.validation_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.word_df[self.word_df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "\n",
        "        # ADDED:\n",
        "        # -----------------------------------------------------------------\n",
        "        self.doubling_df = self.word_df[self.word_df.split=='doubling']\n",
        "        self.doubling_size = len(self.doubling_df)\n",
        "\n",
        "        self.nodoubling_df = self.word_df[self.word_df.split=='no_doubling']\n",
        "        self.nodoubling_size = len(self.nodoubling_df)\n",
        "\n",
        "\n",
        "        # -----------------------------------------------------------------\n",
        "\n",
        "        self._lookup_dict = {'train': (self.train_df, self.train_size), \n",
        "                             'val': (self.val_df, self.validation_size), \n",
        "                             'test': (self.test_df, self.test_size),\n",
        "                             'doubling': (self.doubling_df, self.doubling_size), # ADDED\n",
        "                             'no_doubling': (self.nodoubling_df, self.nodoubling_size)} # ADDED\n",
        "\n",
        "        self.set_split('train')\n",
        "        \n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, word_csv):\n",
        "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
        "        \n",
        "        Args:\n",
        "            word_csv (str): location of the dataset\n",
        "        Returns:\n",
        "            an instance of WordDataset\n",
        "        \"\"\"\n",
        "        \n",
        "        word_df = pd.read_csv(word_csv, encoding='latin-1')\n",
        "        return cls(word_df, WordVectorizer.from_dataframe(word_df))\n",
        "        \n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, word_csv, vectorizer_filepath):\n",
        "        \"\"\"Load dataset and the corresponding vectorizer. \n",
        "        Used in the case in the vectorizer has been cached for re-use\n",
        "        \n",
        "        Args:\n",
        "            word_csv (str): location of the dataset\n",
        "            vectorizer_filepath (str): location of the saved vectorizer\n",
        "        Returns:\n",
        "            an instance of WordDataset\n",
        "        \"\"\"\n",
        "        word_df = pd.read_csv(word_csv, encoding='latin-1') # changed coding here\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(word_df, vectorizer)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        \"\"\"a static method for loading the vectorizer from file\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location of the serialized vectorizer\n",
        "        Returns:\n",
        "            an instance of WordVectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return WordVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        \"\"\"saves the vectorizer to disk using json\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location to save the vectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self._vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def get_vectorizer(self):\n",
        "        \"\"\" returns the vectorizer \"\"\"\n",
        "        return self._vectorizer\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        self._target_split = split\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"the primary entry point method for PyTorch datasets\n",
        "        \n",
        "        Args:\n",
        "            index (int): the index to the data point \n",
        "        Returns:\n",
        "            a dictionary holding the data point: (x_data, y_target, class_index)\n",
        "        \"\"\"\n",
        "        row = self._target_df.iloc[index]\n",
        "        \n",
        "        from_vector, to_vector = \\\n",
        "            self._vectorizer.vectorize(row.word, self._max_seq_length)\n",
        "        \n",
        "        classification_index = \\\n",
        "            self._vectorizer.classification_vocab.lookup_token(row.classification)\n",
        "\n",
        "        return {'x_data': from_vector, \n",
        "                'y_target': to_vector, \n",
        "                'class_index': classification_index}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
        "        \n",
        "        Args:\n",
        "            batch_size (int)\n",
        "        Returns:\n",
        "            number of batches in the dataset\n",
        "        \"\"\"\n",
        "        return len(self) // batch_size\n",
        "    \n",
        "def generate_batches(dataset, batch_size, shuffle=True,\n",
        "                     drop_last=True, device=\"cpu\"): \n",
        "    \"\"\"\n",
        "    A generator function which wraps the PyTorch DataLoader. It will \n",
        "      ensure each tensor is on the write device location.\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last)\n",
        "\n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        for name, tensor in data_dict.items():\n",
        "            out_data_dict[name] = data_dict[name].to(device)\n",
        "        yield out_data_dict"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcCvBM1j9_xY"
      },
      "source": [
        "# Word Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w33KikSE-BXG"
      },
      "source": [
        "class WordGenerationModel(nn.Module):\n",
        "    def __init__(self, char_embedding_size, char_vocab_size, rnn_hidden_size, \n",
        "                 batch_first=True, padding_idx=0, dropout_p=0.5):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            char_embedding_size (int): The size of the character embeddings\n",
        "            char_vocab_size (int): The number of characters to embed\n",
        "            rnn_hidden_size (int): The size of the RNN's hidden state\n",
        "            batch_first (bool): Informs whether the input tensors will \n",
        "                have batch or the sequence on the 0th dimension\n",
        "            padding_idx (int): The index for the tensor padding; \n",
        "                see torch.nn.Embedding\n",
        "            dropout_p (float): the probability of zeroing activations using\n",
        "                the dropout method.  higher means more likely to zero.\n",
        "        \"\"\"\n",
        "        super(WordGenerationModel, self).__init__()\n",
        "        \n",
        "        self.char_emb = nn.Embedding(num_embeddings=char_vocab_size,\n",
        "                                     embedding_dim=char_embedding_size,\n",
        "                                     padding_idx=padding_idx)\n",
        "\n",
        "        self.rnn = nn.GRU(input_size=char_embedding_size, \n",
        "                          hidden_size=rnn_hidden_size,\n",
        "                          batch_first=batch_first)\n",
        "        \n",
        "        self.fc = nn.Linear(in_features=rnn_hidden_size, \n",
        "                            out_features=char_vocab_size)\n",
        "        \n",
        "        self._dropout_p = dropout_p\n",
        "\n",
        "    def forward(self, x_in, apply_softmax=False):\n",
        "        \"\"\"The forward pass of the model\n",
        "        \n",
        "        Args:\n",
        "            x_in (torch.Tensor): an input data tensor. \n",
        "                x_in.shape should be (batch, input_dim)\n",
        "            apply_softmax (bool): a flag for the softmax activation\n",
        "                should be false if used with the Cross Entropy losses\n",
        "        Returns:\n",
        "            the resulting tensor. tensor.shape should be (batch, char_vocab_size)\n",
        "        \"\"\"\n",
        "        x_embedded = self.char_emb(x_in)\n",
        "\n",
        "        y_out, _ = self.rnn(x_embedded)\n",
        "\n",
        "        batch_size, seq_size, feat_size = y_out.shape\n",
        "        y_out = y_out.contiguous().view(batch_size * seq_size, feat_size)\n",
        "\n",
        "        y_out = self.fc(F.dropout(y_out, p=self._dropout_p))\n",
        "                         \n",
        "        if apply_softmax:\n",
        "            y_out = F.softmax(y_out, dim=1)\n",
        "            \n",
        "        new_feat_size = y_out.shape[-1]\n",
        "        y_out = y_out.view(batch_size, seq_size, new_feat_size)\n",
        "            \n",
        "        return y_out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGCoOA1M-JMg"
      },
      "source": [
        "def sample_from_model(model, vectorizer, num_samples=1, sample_size=20, \n",
        "                      temperature=1.0):\n",
        "    \"\"\"Sample a sequence of indices from the model\n",
        "    \n",
        "    Args:\n",
        "        model (WordGenerationModel): the trained model\n",
        "        vectorizer (WordVectorizer): the corresponding vectorizer\n",
        "        num_samples (int): the number of samples\n",
        "        sample_size (int): the max length of the samples\n",
        "        temperature (float): accentuates or flattens \n",
        "            the distribution. \n",
        "            0.0 < temperature < 1.0 will make it peakier. \n",
        "            temperature > 1.0 will make it more uniform\n",
        "    Returns:\n",
        "        indices (torch.Tensor): the matrix of indices; \n",
        "        shape = (num_samples, sample_size)\n",
        "    \"\"\"\n",
        "    begin_seq_index = [vectorizer.char_vocab.begin_seq_index \n",
        "                       for _ in range(num_samples)]\n",
        "    begin_seq_index = torch.tensor(begin_seq_index, \n",
        "                                   dtype=torch.int64).unsqueeze(dim=1)\n",
        "    indices = [begin_seq_index]\n",
        "    h_t = None\n",
        "    \n",
        "    for time_step in range(sample_size):\n",
        "        x_t = indices[time_step]\n",
        "        x_emb_t = model.char_emb(x_t)\n",
        "        rnn_out_t, h_t = model.rnn(x_emb_t, h_t)\n",
        "        prediction_vector = model.fc(rnn_out_t.squeeze(dim=1))\n",
        "        probability_vector = F.softmax(prediction_vector / temperature, dim=1)\n",
        "        indices.append(torch.multinomial(probability_vector, num_samples=1))\n",
        "    indices = torch.stack(indices).squeeze().permute(1, 0)\n",
        "    return indices\n",
        "\n",
        "def decode_samples(sampled_indices, vectorizer):\n",
        "    \"\"\"Transform indices into the string form of a word\n",
        "    \n",
        "    Args:\n",
        "        sampled_indices (torch.Tensor): the inidces from `sample_from_model`\n",
        "        vectorizer (WordVectorizer): the corresponding vectorizer\n",
        "    \"\"\"\n",
        "    decoded_words = []\n",
        "    vocab = vectorizer.char_vocab\n",
        "    \n",
        "    for sample_index in range(sampled_indices.shape[0]):\n",
        "        word = \"\"\n",
        "        for time_step in range(sampled_indices.shape[1]):\n",
        "            sample_item = sampled_indices[sample_index, time_step].item()\n",
        "            if sample_item == vocab.begin_seq_index:\n",
        "                continue\n",
        "            elif sample_item == vocab.end_seq_index:\n",
        "                break\n",
        "            else:\n",
        "                word += vocab.lookup_index(sample_item)\n",
        "        decoded_words.append(word)\n",
        "    return decoded_words"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQUIJdm7-M8y"
      },
      "source": [
        "# Training routine\n",
        "\n",
        "Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVhEaA5z-MBc"
      },
      "source": [
        "def make_train_state(args):\n",
        "    return {'stop_early': False,\n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'learning_rate': args.learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': args.model_state_file}\n",
        "\n",
        "def update_train_state(args, model, train_state):\n",
        "    \"\"\"Handle the training state updates.\n",
        "    Components:\n",
        "     - Early Stopping: Prevent overfitting.\n",
        "     - Model Checkpoint: Model is saved if the model is better\n",
        "    \n",
        "    :param args: main arguments\n",
        "    :param model: model to train\n",
        "    :param train_state: a dictionary representing the training state values\n",
        "    :returns:\n",
        "        a new train_state\n",
        "    \"\"\"\n",
        "\n",
        "    # Save one model at least\n",
        "    if train_state['epoch_index'] == 0:\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\n",
        "        train_state['stop_early'] = False\n",
        "\n",
        "    # Save model if performance improved\n",
        "    elif train_state['epoch_index'] >= 1:\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
        "         \n",
        "        # If loss worsened\n",
        "        if loss_t >= loss_tm1:\n",
        "            # Update step\n",
        "            train_state['early_stopping_step'] += 1\n",
        "        # Loss decreased\n",
        "        else:\n",
        "            # Save the best model\n",
        "            if loss_t < train_state['early_stopping_best_val']:\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\n",
        "                train_state['early_stopping_best_val'] = loss_t\n",
        "\n",
        "            # Reset early stopping step\n",
        "            train_state['early_stopping_step'] = 0\n",
        "\n",
        "        # Stop early ?\n",
        "        train_state['stop_early'] = \\\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
        "\n",
        "    return train_state\n",
        "\n",
        "def normalize_sizes(y_pred, y_true):\n",
        "    \"\"\"Normalize tensor sizes\n",
        "    \n",
        "    Args:\n",
        "        y_pred (torch.Tensor): the output of the model\n",
        "            If a 3-dimensional tensor, reshapes to a matrix\n",
        "        y_true (torch.Tensor): the target predictions\n",
        "            If a matrix, reshapes to be a vector\n",
        "    \"\"\"\n",
        "    if len(y_pred.size()) == 3:\n",
        "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
        "    if len(y_true.size()) == 2:\n",
        "        y_true = y_true.contiguous().view(-1)\n",
        "    return y_pred, y_true\n",
        "\n",
        "def compute_accuracy(y_pred, y_true, mask_index):\n",
        "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
        "\n",
        "    _, y_pred_indices = y_pred.max(dim=1)\n",
        "    \n",
        "    correct_indices = torch.eq(y_pred_indices, y_true).float()\n",
        "    valid_indices = torch.ne(y_true, mask_index).float()\n",
        "    \n",
        "    n_correct = (correct_indices * valid_indices).sum().item()\n",
        "    n_valid = valid_indices.sum().item()\n",
        "\n",
        "    return n_correct / n_valid * 100\n",
        "\n",
        "def sequence_loss(y_pred, y_true, mask_index):\n",
        "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
        "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ8oC67-XFq"
      },
      "source": [
        "Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPae1Ke1-UQj"
      },
      "source": [
        "def set_seed_everywhere(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gux7fTG7-Yau"
      },
      "source": [
        "Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZSQZzGocS2i",
        "outputId": "c80b24ae-7ca1-484b-b75e-aa8a5d7d8d08"
      },
      "source": [
        "# to access and save files on google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RnmkCGW-a9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "127cf385-5050-459c-b7c2-d24754710422"
      },
      "source": [
        "args = Namespace(\n",
        "    # Data and Path information\n",
        "    word_csv=\"/content/drive/MyDrive/Lang-and-Mind-Lab/words_doubling_unshuffled.csv\", # CHANGE THIS TO YOUR PATH\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir=\"/content/drive/MyDrive/Lang-and-Mind-Lab\", # CHANGE THIS TO YOUR PATH\n",
        "    # Model hyper parameters\n",
        "    char_embedding_size=32,\n",
        "    rnn_hidden_size=32,\n",
        "    # Training hyper parameters\n",
        "    seed=1337,\n",
        "    learning_rate=0.001,\n",
        "    batch_size=128,\n",
        "    num_epochs=100,\n",
        "    early_stopping_criteria=5,\n",
        "    # Runtime options\n",
        "    catch_keyboard_interrupt=True,\n",
        "    cuda=True,\n",
        "    expand_filepaths_to_save_dir=True,\n",
        "    reload_from_files=False, # change to true after first time running\n",
        ")\n",
        "\n",
        "if args.expand_filepaths_to_save_dir:\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\n",
        "                                        args.vectorizer_file)\n",
        "\n",
        "    args.model_state_file = os.path.join(args.save_dir,\n",
        "                                         args.model_state_file)\n",
        "    \n",
        "    print(\"Expanded filepaths: \")\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\n",
        "    print(\"\\t{}\".format(args.model_state_file))\n",
        "    \n",
        "    \n",
        "# Check CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "    \n",
        "print(\"Using CUDA: {}\".format(args.cuda))\n",
        "\n",
        "# Set seed for reproducibility\n",
        "set_seed_everywhere(args.seed, args.cuda)\n",
        "\n",
        "# handle dirs\n",
        "handle_dirs(args.save_dir)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expanded filepaths: \n",
            "\t/content/drive/MyDrive/Lang-and-Mind-Lab/vectorizer.json\n",
            "\t/content/drive/MyDrive/Lang-and-Mind-Lab/model.pth\n",
            "Using CUDA: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jntkz8JI-dh9"
      },
      "source": [
        "Initializations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEdeHSwz-gaD"
      },
      "source": [
        "if args.reload_from_files:\n",
        "    # training from a checkpoint\n",
        "    dataset = WordDataset.load_dataset_and_load_vectorizer(args.word_csv, args.vectorizer_file)\n",
        "else:\n",
        "    # create dataset and vectorizer\n",
        "    dataset = WordDataset.load_dataset_and_make_vectorizer(args.word_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "\n",
        "vectorizer = dataset.get_vectorizer()\n",
        "\n",
        "model = WordGenerationModel(char_embedding_size=args.char_embedding_size,\n",
        "                               char_vocab_size=len(vectorizer.char_vocab),\n",
        "                               rnn_hidden_size=args.rnn_hidden_size,\n",
        "                               padding_idx=vectorizer.char_vocab.mask_index)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHOKSXvE5A20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97e0ab2-12de-4d36-ac65-446cdfa40917"
      },
      "source": [
        "# this is useful later if we want to get the probability of a certain char\n",
        "vectorizer.char_vocab._idx_to_token"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '<MASK>',\n",
              " 1: '<UNK>',\n",
              " 2: '<BEGIN>',\n",
              " 3: '<END>',\n",
              " 4: 's',\n",
              " 5: 't',\n",
              " 6: 'a',\n",
              " 7: 'u',\n",
              " 8: 'e',\n",
              " 9: 'o',\n",
              " 10: 'h',\n",
              " 11: 'i',\n",
              " 12: 'b',\n",
              " 13: 'j',\n",
              " 14: 'd',\n",
              " 15: 'r',\n",
              " 16: 'p',\n",
              " 17: 'y',\n",
              " 18: 'c',\n",
              " 19: 'q',\n",
              " 20: 'n',\n",
              " 21: 'l',\n",
              " 22: 'g',\n",
              " 23: 'f',\n",
              " 24: 'k',\n",
              " 25: 'm',\n",
              " 26: 'w',\n",
              " 27: 'x',\n",
              " 28: 'v',\n",
              " 29: 'z',\n",
              " 30: 'T',\n",
              " 31: 'R',\n",
              " 32: 'U',\n",
              " 33: 'E',\n",
              " 34: 'F',\n",
              " 35: 'A',\n",
              " 36: 'L',\n",
              " 37: 'S'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhy4G1pV-kfI"
      },
      "source": [
        "Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO2IKw0K-iK7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230,
          "referenced_widgets": [
            "0fcc4a2f6b754de396bdb9eee340f93a",
            "0cc4c5098fc743198a8d8ebad10f138e",
            "39aabd6237814d709ebbfea93a926389",
            "f71d8360b27c43afa18c6604770d9a6b",
            "13eeab08f272488aa6be4a327eb00268",
            "94c7ddecf68b4dd3a68c005e8df1595c",
            "bddc34014d27442284cf1f60e8d11ec6",
            "c00e7f3eb1414eaba4e7942c336800f7",
            "4b34d2102a5e439fa8132a90f9741dea",
            "8780615a0da340e1b0714b1f5ef1cd9e",
            "448f5f30d1c040babbb43a4d864b75d8",
            "6dc500d800bd4c56b1fd901ba85baa48",
            "8c7a055c1d7646cd86851162c52bb568",
            "10ee71a7b44a4104a15ef35c34b3b4ce",
            "1631e034781f42f0bcc1ad3e2dae750e",
            "e913f39af8cf480fa91713e4581a4fec",
            "9e9f1a85372b462483270ce45b22ed3d",
            "bcba07351247448eb881042ac2ece38d",
            "34c78331659f476c8fc90cd1fea88597",
            "537137b8f06f4ca3924c95a5caeae0b5",
            "58e70214b3944f398ececc0cfb62b63f",
            "d9b62a7bf909439fb64669afe845b40d",
            "413f0aad9c2842aa8c7873c0d6e03227",
            "143848ccf6e04f239abe26fe1bd21802"
          ]
        },
        "outputId": "e1a17332-903a-4ea6-b37b-4329be891ea6"
      },
      "source": [
        "mask_index = vectorizer.char_vocab.mask_index\n",
        "\n",
        "model = model.to(args.device)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                           mode='min', factor=0.5,\n",
        "                                           patience=1)\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm_notebook(desc='training routine', \n",
        "                          total=args.num_epochs,\n",
        "                          position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm_notebook(desc='split=train',\n",
        "                          total=dataset.get_num_batches(args.batch_size), \n",
        "                          position=1, \n",
        "                          leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm_notebook(desc='split=val',\n",
        "                        total=dataset.get_num_batches(args.batch_size), \n",
        "                        position=1, \n",
        "                        leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # Iterate over training dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        model.train()\n",
        "        \n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # the training routine is these 5 steps:\n",
        "\n",
        "            # --------------------------------------    \n",
        "            # step 1. zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # step 2. compute the output\n",
        "            y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "\n",
        "            # step 4. use loss to produce gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # step 5. use optimizer to take gradient step\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            # compute the  running loss and running accuracy\n",
        "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # update bar\n",
        "            train_bar.set_postfix(loss=running_loss,\n",
        "                                  acc=running_acc,\n",
        "                                  epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # Iterate over val dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        model.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # compute the output\n",
        "            y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "            # compute the  running loss and running accuracy\n",
        "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            \n",
        "            # Update bar\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "\n",
        "        train_state = update_train_state(args=args, model=model, \n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "        \n",
        "        # move model to cpu for sampling\n",
        "        model = model.cpu()\n",
        "        sampled_words = decode_samples(\n",
        "            sample_from_model(model, vectorizer, num_samples=2), \n",
        "            vectorizer)\n",
        "        epoch_bar.set_postfix(sample1=sampled_words[0], \n",
        "                              sample2=sampled_words[1])\n",
        "        # move model back to whichever device it should be on\n",
        "        model = model.to(args.device)\n",
        "        \n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "        \n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fcc4a2f6b754de396bdb9eee340f93a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b34d2102a5e439fa8132a90f9741dea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='split=train', max=59.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e9f1a85372b462483270ce45b22ed3d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='split=val', max=9.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-VArXzT-qjk"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVQ3DBn--sey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "403a729f-ea16-43e0-9b7b-e0b08b3f8213"
      },
      "source": [
        "np.random.choice(np.arange(len(vectorizer.classification_vocab)), replace=True, size=2) # I think this just shows us how many classes are, if we have different classes"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogzoDm3N5hw7"
      },
      "source": [
        "\"\"\"\n",
        "For reference, the index of each character token in the distribution: CHANGE IF USING NEW DATASET\n",
        "\n",
        "{0: '<MASK>', 1: '<UNK>', 2: '<BEGIN>', 3: '<END>', 4: 'f', 5: 'i', 6: 'o', 7: 'n',\n",
        " 8: 'a', 9: 's', 10: 'h', 11: 't', 12: 'l', 13: 'w', 14: 'e', 15: 'b', 16: 'r', 17: 'u',\n",
        " 18: 'm', 19: 'c', 20: 'k', 21: 'p', 22: 'j', 23: 'd', 24: 'y', 25: 'v', 26: 'g', 27: 'q', \n",
        " 28: 'x', 29: 'z'}\n",
        "\n",
        "\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGzcIknG-I03"
      },
      "source": [
        "Evaluate using actual English words. This will give us an idea of how well the model does with predicting words that are actual in English. That is, for each \n",
        "test sequence, we will compare the probability of the sequence that actually exists in English, with the probability of the sequence that the model generated. We will evaluate using perplexity (2^-log prob of sequence). Lower perplexity means a better prediction was made."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acinRVe2-tMh"
      },
      "source": [
        "\"\"\"\n",
        "Compute the loss & accuracy on the English test set using the best available model.\n",
        "That is, here we are comparing the probability distribution of possible characters that could occur\n",
        "at each position, with what actually occured.\n",
        "\n",
        "y_pred: 128 words in batch, 20 character positions in each word, 38 characters in the distribution <-- NOTE THIS CHANGES WITH DIFFERENT DATASETS, BECAUSE OF HOW MANY CHARS THERE ARE\n",
        "\"\"\"\n",
        "\n",
        "model.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "model = model.to(args.device)\n",
        "\n",
        "dataset.set_split('test')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=args.batch_size, \n",
        "                                   device=args.device)\n",
        "running_acc = 0.\n",
        "model.eval()\n",
        "\n",
        "word_perplexities = {} # maps words --> perplexity values\n",
        "position_perplexities = {} # maps char positions --> perplexity values\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "    # compute the output\n",
        "    y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "    # initialize dictionary\n",
        "    word_perplexities[batch_index] = {}\n",
        "    position_perplexities[batch_index] = {}\n",
        "\n",
        "    # iterate over each word in the batch, and calculate the loss for that word\n",
        "    # save perplexity to dict\n",
        "    start = 0\n",
        "    end = 1\n",
        "    for i in range(128):\n",
        "        \n",
        "        word_loss = sequence_loss(y_pred[start:end,:],batch_dict['y_target'][start:end,:], mask_index)\n",
        "\n",
        "        # reconstruct the word\n",
        "        word = \"\"\n",
        "        start_pos = 0\n",
        "        end_pos = 1\n",
        "        for j in range(20):\n",
        "            curr_char_index = batch_dict['y_target'][i][j].item()\n",
        "            if curr_char_index >= 4:\n",
        "                curr_char = vectorizer.char_vocab._idx_to_token[curr_char_index]\n",
        "                word += curr_char\n",
        "\n",
        "            position_loss = sequence_loss(y_pred[:, start_pos:end_pos],batch_dict['y_target'][:, start_pos:end_pos], mask_index)\n",
        "            position_pp = math.pow(2,position_loss)\n",
        "            position_perplexities[batch_index][j] = position_pp\n",
        "            start_pos += 1\n",
        "            end_pos += 1\n",
        "\n",
        "        pp = math.pow(2,word_loss)\n",
        "        word_perplexities[batch_index][word] = pp\n",
        "\n",
        "        start += 1\n",
        "        end += 1\n",
        "\n",
        "    # compute the loss\n",
        "    loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "    # compute the accuracy\n",
        "    running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss \n",
        "train_state['test_acc'] = running_acc"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCAugUqRLR-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2561ed-30e4-489a-d7b0-142e300a6ca7"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 20, 38])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NoiBWYC-wJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b68ce1-ed50-4c45-c118-dcfae4bf011f"
      },
      "source": [
        "# print the loss, perplexity, and accuracy for the test set overall\n",
        "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
        "print(\"Test perplexity: {};\".format(math.pow(2,train_state['test_loss'])))\n",
        "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 2.4695907036463423;\n",
            "Test perplexity: 5.538866258685075;\n",
            "Test Accuracy: 25.599759204746327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I0XeU2wt-_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b47a840-b78f-4bbb-c10e-062e558939bd"
      },
      "source": [
        "# print the perplexity values for each word in the first batch (128 words)\n",
        "# low perplexity values are good\n",
        "\n",
        "flag = 0\n",
        "for b, w_dict in word_perplexities.items():\n",
        "    if flag > 0:\n",
        "            break\n",
        "    for w, p in w_dict.items():\n",
        "        print(\"word: \", w, \" perplexity: \", round(p,2))\n",
        "    flag += 1"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word:  usher  perplexity:  5.8\n",
            "word:  ef  perplexity:  13.53\n",
            "word:  billion  perplexity:  4.25\n",
            "word:  handmade  perplexity:  6.55\n",
            "word:  byte  perplexity:  6.83\n",
            "word:  wiley  perplexity:  6.67\n",
            "word:  signing  perplexity:  4.38\n",
            "word:  lid  perplexity:  8.62\n",
            "word:  complementary  perplexity:  4.16\n",
            "word:  uh  perplexity:  21.81\n",
            "word:  oz  perplexity:  19.0\n",
            "word:  hybrid  perplexity:  9.06\n",
            "word:  ups  perplexity:  7.43\n",
            "word:  twiki  perplexity:  13.7\n",
            "word:  managed  perplexity:  5.99\n",
            "word:  inches  perplexity:  4.19\n",
            "word:  deposit  perplexity:  6.84\n",
            "word:  brazil  perplexity:  7.19\n",
            "word:  bulk  perplexity:  6.09\n",
            "word:  welsh  perplexity:  6.69\n",
            "word:  expenditures  perplexity:  3.97\n",
            "word:  chrome  perplexity:  5.24\n",
            "word:  moses  perplexity:  4.43\n",
            "word:  missed  perplexity:  3.87\n",
            "word:  ten  perplexity:  6.88\n",
            "word:  pure  perplexity:  6.2\n",
            "word:  mst  perplexity:  8.64\n",
            "word:  extra  perplexity:  5.35\n",
            "word:  mitsubishi  perplexity:  9.1\n",
            "word:  race  perplexity:  4.26\n",
            "word:  present  perplexity:  3.43\n",
            "word:  specs  perplexity:  5.74\n",
            "word:  might  perplexity:  6.07\n",
            "word:  payments  perplexity:  6.22\n",
            "word:  nylon  perplexity:  7.67\n",
            "word:  reason  perplexity:  4.77\n",
            "word:  king  perplexity:  3.89\n",
            "word:  examines  perplexity:  4.2\n",
            "word:  donor  perplexity:  5.56\n",
            "word:  valentines  perplexity:  3.99\n",
            "word:  transmission  perplexity:  4.39\n",
            "word:  narrow  perplexity:  6.83\n",
            "word:  headlines  perplexity:  5.7\n",
            "word:  rep  perplexity:  8.53\n",
            "word:  terrain  perplexity:  5.33\n",
            "word:  moldova  perplexity:  8.03\n",
            "word:  infrastructure  perplexity:  5.52\n",
            "word:  lenders  perplexity:  4.67\n",
            "word:  teams  perplexity:  5.91\n",
            "word:  ict  perplexity:  7.03\n",
            "word:  response  perplexity:  5.41\n",
            "word:  allow  perplexity:  5.25\n",
            "word:  cleanup  perplexity:  7.95\n",
            "word:  housewares  perplexity:  6.55\n",
            "word:  communicate  perplexity:  4.95\n",
            "word:  congo  perplexity:  5.32\n",
            "word:  lucky  perplexity:  7.53\n",
            "word:  vol  perplexity:  6.63\n",
            "word:  lan  perplexity:  6.41\n",
            "word:  interpretation  perplexity:  3.79\n",
            "word:  arbor  perplexity:  5.08\n",
            "word:  twelve  perplexity:  6.53\n",
            "word:  planes  perplexity:  4.25\n",
            "word:  panties  perplexity:  3.9\n",
            "word:  surgeon  perplexity:  4.73\n",
            "word:  inns  perplexity:  4.88\n",
            "word:  instant  perplexity:  3.81\n",
            "word:  pissing  perplexity:  3.86\n",
            "word:  est  perplexity:  6.36\n",
            "word:  lawyers  perplexity:  7.29\n",
            "word:  adopted  perplexity:  4.94\n",
            "word:  divisions  perplexity:  3.42\n",
            "word:  determined  perplexity:  4.1\n",
            "word:  stories  perplexity:  3.43\n",
            "word:  viii  perplexity:  14.6\n",
            "word:  retreat  perplexity:  4.8\n",
            "word:  devon  perplexity:  4.71\n",
            "word:  disturbed  perplexity:  5.19\n",
            "word:  coupons  perplexity:  4.97\n",
            "word:  patio  perplexity:  6.63\n",
            "word:  beaches  perplexity:  4.26\n",
            "word:  beside  perplexity:  5.78\n",
            "word:  submit  perplexity:  8.16\n",
            "word:  tba  perplexity:  9.58\n",
            "word:  identify  perplexity:  6.51\n",
            "word:  azerbaijan  perplexity:  9.52\n",
            "word:  drill  perplexity:  8.21\n",
            "word:  blame  perplexity:  6.12\n",
            "word:  dont  perplexity:  5.62\n",
            "word:  reduction  perplexity:  4.0\n",
            "word:  named  perplexity:  4.18\n",
            "word:  year  perplexity:  9.97\n",
            "word:  magnificent  perplexity:  6.64\n",
            "word:  ata  perplexity:  6.54\n",
            "word:  securing  perplexity:  4.72\n",
            "word:  trader  perplexity:  3.86\n",
            "word:  panic  perplexity:  4.76\n",
            "word:  awesome  perplexity:  8.14\n",
            "word:  suites  perplexity:  4.93\n",
            "word:  futures  perplexity:  4.89\n",
            "word:  pay  perplexity:  7.58\n",
            "word:  that  perplexity:  5.39\n",
            "word:  st  perplexity:  6.48\n",
            "word:  recreational  perplexity:  4.61\n",
            "word:  crucial  perplexity:  6.45\n",
            "word:  soccer  perplexity:  4.96\n",
            "word:  questions  perplexity:  3.71\n",
            "word:  addressed  perplexity:  4.73\n",
            "word:  bash  perplexity:  5.38\n",
            "word:  please  perplexity:  4.89\n",
            "word:  dorothy  perplexity:  6.12\n",
            "word:  console  perplexity:  3.88\n",
            "word:  upset  perplexity:  6.69\n",
            "word:  dx  perplexity:  22.21\n",
            "word:  indoor  perplexity:  5.58\n",
            "word:  fp  perplexity:  14.02\n",
            "word:  min  perplexity:  5.75\n",
            "word:  participate  perplexity:  4.57\n",
            "word:  tribe  perplexity:  4.76\n",
            "word:  nails  perplexity:  5.19\n",
            "word:  vonage  perplexity:  5.94\n",
            "word:  hill  perplexity:  8.86\n",
            "word:  mustang  perplexity:  5.49\n",
            "word:  em  perplexity:  6.87\n",
            "word:  wealth  perplexity:  5.63\n",
            "word:  magical  perplexity:  5.42\n",
            "word:  prophet  perplexity:  5.26\n",
            "word:  slightly  perplexity:  6.06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIeXrJHzHQKs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "c4bb287a-bb69-448f-c93d-347cc4c76882"
      },
      "source": [
        "# get the perpelxity at each character position (averaged over each English word)\n",
        "avgs = {}\n",
        "for batch, char_dict in position_perplexities.items():\n",
        "    for ch, p in char_dict.items():\n",
        "        if avgs.get(ch):\n",
        "            avgs[ch] += p\n",
        "        else:\n",
        "            avgs[ch] = p\n",
        "avgs = {k: v / 20 for k, v in avgs.items()} # change this for num of chars\n",
        "\n",
        "# plot\n",
        "df = pd.DataFrame(list(avgs.items()), columns=['Character Positions', 'English']) \n",
        "plt.bar(df['Character Positions'], df['English'], color='purple', width=0.5)\n",
        "plt.title('English words')\n",
        "plt.xlabel('Character positions')\n",
        "plt.ylabel('Avg. perplexities')\n",
        "plt.xlim(0,29)\n",
        "plt.xticks(np.arange(0, 20, 1))\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 4)\n",
        "plt.show()\n",
        "print('\\n')\n",
        "\n",
        "# note that many of the character positions at the end are not real. Since\n",
        "# the model needs each word to be the same length, a \"mask\" character is created\n",
        "# for shorter words, and that probability is not counted overall when looking \n",
        "# at the probabilty of that word. So the end of the graph doesn't tell us a ton.\n",
        "\n",
        "# Each word should have high perplexity in the beginning, because the more \n",
        "# observations that a model sees, the less \"perlexed\" it will be, and it has\n",
        "# observed little in the beginning of the word. As we get farther into the word\n",
        "# perplexity should decrease. This isn't happening right now, but a lot of \n",
        "# the words aren't very representative of English. \n",
        "\n",
        "# However, I would guess that for doubling words, the model would get more \n",
        "# perplexed towards the end of the word as well, when the doubling occurs, \n",
        "# as doubling is not expected. I'm not sure how the non-words without doubling\n",
        "# will perform. They may have higher perpelxity than the actual English words,\n",
        "# but lower than the non-words with doubling. "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hTJdNIV-vGv"
      },
      "source": [
        "Evaluate the model using non-words that have doubling. We would predict that the perplexity of these words would be higher than those that do not have doubling. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lK0eb2ztB0W"
      },
      "source": [
        "# test doubling words\n",
        "\n",
        "model.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "model = model.to(args.device)\n",
        "\n",
        "dataset.set_split('doubling')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=1, # we change the batch size to 1, since we don't have many words we are working with\n",
        "                                   device=args.device)\n",
        "\n",
        "\n",
        "running_acc = 0.\n",
        "model.eval()\n",
        "\n",
        "word_perplexities_doubling = {} # maps words --> perplexity values\n",
        "position_perplexities_doubling = {} # maps char positions --> perplexity values\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "    # compute the output\n",
        "    y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "    # initialize dictionary\n",
        "    word_perplexities_doubling[batch_index] = {}\n",
        "    position_perplexities_doubling[batch_index] = {}\n",
        "\n",
        "    # iterate over each word in the batch, and calculate the loss for that word\n",
        "    # save perplexity to dict\n",
        "    start = 0\n",
        "    end = 1\n",
        "    for i in range(1):\n",
        "        word_loss = sequence_loss(y_pred[start:end,:],batch_dict['y_target'][start:end,:], mask_index)\n",
        "\n",
        "        # reconstruct the word and get perplexity at each char position\n",
        "        word = \"\"\n",
        "        start_pos = 0\n",
        "        end_pos = 1\n",
        "        for j in range(20):\n",
        "            curr_char_index = batch_dict['y_target'][i][j].item()\n",
        "            if curr_char_index >= 4:\n",
        "                curr_char = vectorizer.char_vocab._idx_to_token[curr_char_index]\n",
        "                word += curr_char\n",
        "\n",
        "            position_loss = sequence_loss(y_pred[:, start_pos:end_pos],batch_dict['y_target'][:, start_pos:end_pos], mask_index)\n",
        "            position_pp = math.pow(2,position_loss)\n",
        "            position_perplexities_doubling[batch_index][j] = position_pp\n",
        "            start_pos += 1\n",
        "            end_pos += 1\n",
        "\n",
        "        pp = math.pow(2,word_loss)\n",
        "        word_perplexities_doubling[batch_index][word] = pp\n",
        "\n",
        "        start += 1\n",
        "        end += 1\n",
        "\n",
        "    # compute the loss\n",
        "    loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "    # compute the accuracy\n",
        "    running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss \n",
        "train_state['test_acc'] = running_acc"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czkYOh0RMJqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf6077e-cdd6-4e16-b7b3-ba5131879792"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20, 38])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnXu7uyH9a60",
        "outputId": "27cf60a9-44b6-489a-c2ba-f5dca33578d2"
      },
      "source": [
        "# print the loss, perplexity, and accuracy for the doubling set overall\n",
        "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
        "print(\"Test perplexity: {};\".format(math.pow(2,train_state['test_loss'])))\n",
        "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 2.8011513914380757;\n",
            "Test perplexity: 6.969964902823694;\n",
            "Test Accuracy: 14.285714285714286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS8YDxwL9ASu",
        "outputId": "4bce42c1-7092-4648-de80-f5adda3806a2"
      },
      "source": [
        "# Print the perplexities for each word\n",
        "for b, w_dict in word_perplexities_doubling.items():\n",
        "    for w, p in w_dict.items():\n",
        "        print(\"word: \", w, \" perplexity: \", round(p,2))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word:  kravrav  perplexity:  10.52\n",
            "word:  blatlat  perplexity:  5.34\n",
            "word:  smolmol  perplexity:  7.27\n",
            "word:  kragrag  perplexity:  7.83\n",
            "word:  stimtim  perplexity:  7.85\n",
            "word:  kloplop  perplexity:  7.25\n",
            "word:  fliblib  perplexity:  7.47\n",
            "word:  flonlon  perplexity:  6.34\n",
            "word:  flaklak  perplexity:  6.59\n",
            "word:  slodlod  perplexity:  6.75\n",
            "word:  plonlon  perplexity:  6.78\n",
            "word:  blaflaf  perplexity:  7.44\n",
            "word:  frebreb  perplexity:  6.4\n",
            "word:  snadnad  perplexity:  7.14\n",
            "word:  prafraf  perplexity:  8.08\n",
            "word:  dranran  perplexity:  5.92\n",
            "word:  snognog  perplexity:  9.05\n",
            "word:  frosros  perplexity:  6.13\n",
            "word:  smatmat  perplexity:  6.68\n",
            "word:  grefref  perplexity:  7.33\n",
            "word:  grofrof  perplexity:  8.57\n",
            "word:  drofrof  perplexity:  9.05\n",
            "word:  drakrak  perplexity:  8.31\n",
            "word:  blaslas  perplexity:  5.4\n",
            "word:  plaflaf  perplexity:  8.06\n",
            "word:  klenlen  perplexity:  6.47\n",
            "word:  flamlam  perplexity:  7.08\n",
            "word:  trosros  perplexity:  5.27\n",
            "word:  trafraf  perplexity:  8.09\n",
            "word:  slanlan  perplexity:  6.27\n",
            "word:  tramram  perplexity:  5.39\n",
            "word:  trelrel  perplexity:  5.55\n",
            "word:  franran  perplexity:  6.07\n",
            "word:  granran  perplexity:  7.59\n",
            "word:  premrem  perplexity:  5.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7kkYuuQE04h",
        "outputId": "30b67222-924e-47af-ebb0-c750c34242ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# perplexity vaues at each character (chars after 7 are just \"masking chars\")\n",
        "# these appear in the same order as the words above\n",
        "for key, value in position_perplexities_doubling.items():\n",
        "    print(key, value)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 {0: 23.606268411244947, 1: 10.863526167005553, 2: 2.4827214916248432, 3: 17.56040794788158, 4: 37.19333863178482, 5: 4.315340564157689, 6: 15.613335797907386, 7: 5.361752763891722, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "1 {0: 10.006861771765793, 1: 11.946116185985156, 2: 3.150047998585803, 3: 5.013737582613103, 4: 9.399372521516806, 5: 4.281635360384417, 6: 2.062483832870156, 7: 4.243211760518619, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "2 {0: 7.056391596589868, 1: 18.587709819343516, 2: 4.874776304972514, 3: 5.259423292628387, 4: 16.292460403913864, 5: 6.345294322827111, 6: 6.995380076932304, 7: 3.2164659636770434, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "3 {0: 13.790841355685647, 1: 10.224991566341217, 2: 3.476178486411586, 3: 11.625981823438316, 4: 6.170045359595207, 5: 5.54001956518806, 6: 17.824719826891286, 7: 4.052122282249577, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "4 {0: 5.626986488623434, 1: 7.594609952556747, 2: 3.4390454228521086, 3: 8.948343368061776, 4: 17.749099653500686, 5: 4.2404056665480665, 6: 18.059224296899497, 7: 8.100494051353193, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "5 {0: 17.9413487670305, 1: 9.77450173135768, 2: 2.7769867218452102, 3: 10.038129552867806, 4: 10.001728270874274, 5: 4.279219658158791, 6: 13.155693218944231, 7: 2.7646967472316932, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "6 {0: 12.326049885302371, 1: 7.235720259392637, 2: 2.941330628723525, 3: 15.295794319299896, 4: 7.894611871318761, 5: 3.03692153574093, 6: 15.50935901795037, 7: 6.51939307825933, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "7 {0: 8.125012879944533, 1: 12.125643559762683, 2: 2.4733466156365993, 3: 6.272116017426229, 4: 21.977804789574023, 5: 5.348368441498079, 6: 7.030262729849945, 7: 2.0640115515407413, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "8 {0: 8.71099227561175, 1: 5.3205813903443895, 2: 3.768562241090279, 3: 17.46132343681651, 4: 6.717761583852363, 5: 4.119752637975092, 6: 18.10081569376993, 7: 2.3146823746974627, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "9 {0: 5.294072445957223, 1: 9.973044127478452, 2: 3.62514011203471, 3: 9.966896823856185, 4: 20.91487460516189, 5: 4.953120393640613, 6: 8.128479212635773, 7: 2.686087818172243, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "10 {0: 5.754151190505272, 1: 9.978340997647061, 2: 3.8587787230664987, 3: 8.52873425536132, 4: 29.100889233471378, 5: 7.127918468658105, 6: 3.5115530534597874, 7: 3.239122461285179, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "11 {0: 6.720910768640063, 1: 13.872364145785252, 2: 3.2138334746696997, 3: 22.624814533551202, 4: 4.907528003315483, 5: 4.581376823080489, 6: 18.075496889131028, 7: 3.411407893616205, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "12 {0: 9.301678977050196, 1: 6.634386511109617, 2: 2.481106695490421, 3: 12.86600737413887, 4: 10.841462855109567, 5: 2.571031214834181, 6: 16.21149479841046, 7: 3.1456948434616363, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "13 {0: 4.469040250024539, 1: 22.300127666784032, 2: 3.577672489893815, 3: 9.859557983477233, 4: 17.25973920449267, 5: 5.167152656428507, 6: 11.608422886261108, 7: 1.8600749671146004, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "14 {0: 7.6739813654819065, 1: 2.878244996637803, 2: 2.658103738957996, 3: 30.909151361284426, 4: 9.681225199489743, 5: 4.159592675840281, 6: 20.076919355973235, 7: 12.423680538664902, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "15 {0: 6.79957472678397, 1: 8.978080975354585, 2: 3.147335933469517, 3: 6.7356235270090865, 4: 13.461715411565619, 5: 3.9072101134417485, 6: 8.286333035229998, 7: 2.6803456732876567, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "16 {0: 5.60514631518555, 1: 24.023862494303557, 2: 3.20495277031579, 3: 10.732373524748693, 4: 36.59506719727362, 5: 6.506032075391789, 6: 14.597424313856521, 7: 2.7868798559389347, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "17 {0: 8.861433452872369, 1: 5.151818568953545, 2: 3.312139994873738, 3: 7.531712517406191, 4: 16.961947824688142, 5: 5.140794724723088, 6: 8.385150984680449, 7: 2.3959664712235753, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "18 {0: 6.552299594734508, 1: 25.148600558733634, 2: 2.508241686834517, 3: 3.6233079661103, 4: 57.74917531988389, 5: 4.086647715424671, 6: 2.73830191544449, 7: 4.117252039212182, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "19 {0: 13.226565566787347, 1: 6.281944781675174, 2: 2.5751674090930137, 3: 19.506498820328098, 4: 17.51240464655687, 5: 2.2940484870652393, 6: 21.716591860405927, 7: 2.278084512214862, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "20 {0: 11.717761498313829, 1: 5.401105462555119, 2: 2.236965508246896, 3: 13.963857008938822, 4: 16.66101566344767, 5: 7.29962167262109, 6: 18.15697203329431, 7: 6.664310774355274, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "21 {0: 6.930986841902141, 1: 13.329518068350419, 2: 3.448772545845551, 3: 13.12727804053527, 4: 11.211167093379443, 5: 3.981069220181401, 6: 26.14096526446564, 7: 9.23952386598813, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "22 {0: 8.450588023594085, 1: 20.18310638858575, 2: 3.827127623670265, 3: 23.81116720076695, 4: 9.83020932318292, 5: 3.4168630262446875, 6: 17.632933643001042, 7: 2.4725556196859397, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "23 {0: 9.79869366597988, 1: 8.651814762066532, 2: 2.6536696555487933, 3: 5.080440308352203, 4: 12.519270439726872, 5: 4.265943890628355, 6: 8.455756791051558, 7: 1.3973481622804176, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "24 {0: 7.610191403131202, 1: 8.628503444273006, 2: 3.090273786539861, 3: 19.902733402890874, 4: 7.4967349591810395, 5: 4.894440310954799, 6: 30.37301835317769, 7: 3.947484351532454, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "25 {0: 19.538949029501822, 1: 11.9841524222929, 2: 2.6663229747058073, 3: 3.438031380755536, 4: 14.325531941931327, 5: 2.914879108470837, 6: 9.280600383488132, 7: 3.6709757949535033, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "26 {0: 8.470671710625718, 1: 11.734518102420653, 2: 3.9913520951133954, 3: 7.613173884763177, 4: 17.491082440059337, 5: 3.4807252306184666, 6: 7.907509797514302, 7: 4.340677982240195, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "27 {0: 5.932360935607738, 1: 4.382248902463454, 2: 3.826707371813517, 3: 5.016964228231378, 4: 15.677332868570058, 5: 4.4615119123852685, 6: 5.7652163333135675, 7: 2.9454623070897576, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "28 {0: 6.476433203473208, 1: 2.827184285066383, 2: 2.8833873872288627, 3: 14.477097612034653, 4: 17.13391034399551, 5: 4.379105524453553, 6: 17.23030546502259, 7: 18.56052594936102, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "29 {0: 5.880251757245616, 1: 10.40455757681462, 2: 3.081697333960006, 3: 5.136830491806894, 4: 14.647953977207164, 5: 9.04063149590117, 6: 5.986897485782062, 7: 3.12172669603071, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "30 {0: 8.496555320268358, 1: 2.1969569955744483, 2: 3.771065751696657, 3: 6.656323151975567, 4: 19.087088970454662, 5: 3.4644884702019083, 6: 8.900858497755918, 7: 2.5943562175642807, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "31 {0: 8.916744190592192, 1: 5.596221100355895, 2: 2.551694210573265, 3: 8.688693114950231, 4: 11.26366310059786, 5: 2.3110642476496017, 6: 11.728953812825164, 7: 2.6569875534056107, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "32 {0: 8.740004657085935, 1: 4.218615468756991, 2: 3.025907993215959, 3: 4.656913036479664, 4: 47.615912892273435, 5: 3.4078363310677275, 6: 8.086516908494822, 7: 2.7136051616946912, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "33 {0: 22.903635203662294, 1: 5.873597959194923, 2: 4.255928645002983, 3: 5.7766044115791795, 4: 24.17288631823138, 5: 5.273549694223565, 6: 7.586427483936214, 7: 3.4539001259296582, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "34 {0: 5.878598044945119, 1: 2.191745908778503, 2: 2.9532000850664466, 3: 8.622696122792513, 4: 29.738253337195683, 5: 2.2450527734904884, 6: 15.688347733822336, 7: 4.835552327542828, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-57V3aYEd_o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "171b07e6-b68c-45c0-bf1f-be15575a2270"
      },
      "source": [
        "# get the perpelxity at each character position (averaged over each doubling word)\n",
        "avgs_doubling = {}\n",
        "for batch, char_dict in position_perplexities_doubling.items():\n",
        "    for ch, p in char_dict.items():\n",
        "        if avgs_doubling.get(ch):\n",
        "            avgs_doubling[ch] += p\n",
        "        else:\n",
        "            avgs_doubling[ch] = p\n",
        "avgs_doubling = {k: v / 20 for k, v in avgs_doubling.items()}\n",
        "\n",
        "# plot\n",
        "df_doubling = pd.DataFrame(list(avgs_doubling.items()), columns=['Character Positions', 'doubling']) \n",
        "plt.bar(df_doubling['Character Positions'], df_doubling['doubling'], color='orange', width=0.5)\n",
        "plt.title('Doubling words')\n",
        "plt.xlabel('Character positions')\n",
        "plt.ylabel('Avg. perplexities')\n",
        "plt.xlim(0,6)\n",
        "plt.xticks(np.arange(0, 6, 1))\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
        "plt.show()\n",
        "print('\\n')\n",
        "\n",
        "# Each word should have high perplexity in the begining, because the more \n",
        "# observations that a model sees, the less \"perlexed\" it will be, and it has\n",
        "# observed little in the beginning of the word. However, I would guess that\n",
        "# for doubling words, the model would get more perplexed towards the end\n",
        "# of the word as well, when the doubling occurs, as that is not expected.\n",
        "# On the other hand, I would expect perplexity to go down later in the word\n",
        "# for words without doubling. "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOaS7UAY_DZT"
      },
      "source": [
        "Evaluate the model using non-words that do not have doubling. The perplexity of these words should be similar to that of actual English words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkEfde5M9ng1"
      },
      "source": [
        "# test control words (non-words, no doubling)\n",
        "\n",
        "model.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "model = model.to(args.device)\n",
        "\n",
        "dataset.set_split('no_doubling')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=1, # we change the batch size to 1, since we don't have many words we are working with\n",
        "                                   device=args.device)\n",
        "\n",
        "\n",
        "running_acc = 0.\n",
        "model.eval()\n",
        "\n",
        "word_perplexities_control = {} # maps words --> perplexity values\n",
        "position_perplexities_control = {}\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "    # compute the output\n",
        "    y_pred = model(x_in=batch_dict['x_data'])\n",
        "\n",
        "    # initialize dictionary\n",
        "    word_perplexities_control[batch_index] = {}\n",
        "    position_perplexities_control[batch_index] = {}\n",
        "\n",
        "    # iterate over each word in the batch, and calculate the loss for that word\n",
        "    # save perplexity to dict\n",
        "    start = 0\n",
        "    end = 1\n",
        "    for i in range(1):\n",
        "        word_loss = sequence_loss(y_pred[start:end,:],batch_dict['y_target'][start:end,:], mask_index)\n",
        "\n",
        "        # reconstruct the word and pp at each char posiiton\n",
        "        word = \"\"\n",
        "        start_pos = 0\n",
        "        end_pos = 1\n",
        "        for j in range(20):\n",
        "            curr_char_index = batch_dict['y_target'][i][j].item()\n",
        "            if curr_char_index >= 4:\n",
        "                curr_char = vectorizer.char_vocab._idx_to_token[curr_char_index]\n",
        "                word += curr_char\n",
        "\n",
        "            position_loss = sequence_loss(y_pred[:, start_pos:end_pos],batch_dict['y_target'][:, start_pos:end_pos], mask_index)\n",
        "            position_pp = math.pow(2,position_loss)\n",
        "            position_perplexities_control[batch_index][j] = position_pp\n",
        "            start_pos += 1\n",
        "            end_pos += 1\n",
        "\n",
        "        pp = math.pow(2,word_loss)\n",
        "        word_perplexities_control[batch_index][word] = pp\n",
        "\n",
        "        start += 1\n",
        "        end += 1\n",
        "\n",
        "    # compute the loss\n",
        "    loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "    # compute the accuracy\n",
        "    running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss \n",
        "train_state['test_acc'] = running_acc"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n6ON6wp9uCd",
        "outputId": "2d91016f-a2ad-460d-943e-4a2ad9a6f3ec"
      },
      "source": [
        "# print the loss, perplexity, and accuracy for the doubling set overall\n",
        "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
        "print(\"Test perplexity: {};\".format(math.pow(2,train_state['test_loss'])))\n",
        "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 2.814232867104667;\n",
            "Test perplexity: 7.03345167338926;\n",
            "Test Accuracy: 17.142857142857146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McjjRGs09uO2",
        "outputId": "9a6e1c7b-52d8-416a-d548-811dbe875584"
      },
      "source": [
        "# print the perplexities for each word\n",
        "for b, w_dict in word_perplexities_control.items():\n",
        "    for w, p in w_dict.items():\n",
        "        print(\"word: \", w, \" perplexity: \", round(p,2))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word:  plonmuk  perplexity:  8.68\n",
            "word:  smatnod  perplexity:  6.79\n",
            "word:  flamrad  perplexity:  6.13\n",
            "word:  franmet  perplexity:  5.91\n",
            "word:  dranlat  perplexity:  5.5\n",
            "word:  tramlut  perplexity:  5.1\n",
            "word:  kragnel  perplexity:  8.48\n",
            "word:  froslak  perplexity:  6.38\n",
            "word:  plafnut  perplexity:  7.85\n",
            "word:  greflek  perplexity:  5.69\n",
            "word:  flibnep  perplexity:  7.62\n",
            "word:  granlat  perplexity:  5.63\n",
            "word:  freblek  perplexity:  5.62\n",
            "word:  blatnog  perplexity:  6.31\n",
            "word:  smolrog  perplexity:  6.77\n",
            "word:  slanmot  perplexity:  7.42\n",
            "word:  flakmal  perplexity:  6.36\n",
            "word:  klenmof  perplexity:  10.22\n",
            "word:  snadmak  perplexity:  8.95\n",
            "word:  premlek  perplexity:  6.91\n",
            "word:  trelnat  perplexity:  4.7\n",
            "word:  blafron  perplexity:  6.65\n",
            "word:  blasnol  perplexity:  7.21\n",
            "word:  trosnot  perplexity:  5.89\n",
            "word:  snogmot  perplexity:  9.74\n",
            "word:  flonmog  perplexity:  7.49\n",
            "word:  klopnog  perplexity:  11.22\n",
            "word:  grofnom  perplexity:  6.93\n",
            "word:  traflam  perplexity:  6.95\n",
            "word:  draknad  perplexity:  7.02\n",
            "word:  kravmal  perplexity:  8.44\n",
            "word:  slodmog  perplexity:  9.53\n",
            "word:  stimkam  perplexity:  7.22\n",
            "word:  drofmok  perplexity:  8.51\n",
            "word:  praflak  perplexity:  5.52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBMnMVHOFaty",
        "outputId": "e9c99747-4fe7-4fae-956e-1c15732bbedb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# perplexity vaues at each character (chars after 7 are just \"masking chars\")\n",
        "# these appear in the same order as the words above\n",
        "for key, value in position_perplexities_control.items():\n",
        "    print(key, value)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 {0: 7.757460931824101, 1: 7.246996769393511, 2: 2.596043433622049, 3: 3.411084870750131, 4: 18.913574936225235, 5: 23.58489197919264, 6: 84.33902916081446, 7: 1.719587644786188, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "1 {0: 5.353904311336256, 1: 24.387224743422568, 2: 3.226961238355178, 3: 4.143251420819037, 4: 24.49015534629528, 5: 3.409366542637322, 6: 9.709053977712633, 7: 3.186386194193425, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "2 {0: 12.39075717857046, 1: 8.362386796775171, 2: 2.9935645037224123, 3: 7.125631249302657, 4: 12.344498461808932, 5: 3.6827642362284747, 6: 8.759924908163152, 7: 2.264716320630102, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "3 {0: 8.650706744462612, 1: 9.158929501883936, 2: 3.5653421258992744, 3: 3.677448211950629, 4: 18.27480244195398, 5: 2.2874160416007747, 6: 15.866354976141709, 7: 2.160596177395276, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "4 {0: 8.727323666885738, 1: 19.168612394872614, 2: 2.7248535156696327, 3: 3.1534906142619024, 4: 10.733310038601829, 5: 5.798164925801661, 6: 5.004950890572797, 7: 1.87669202962247, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "5 {0: 6.426704640205855, 1: 2.437212134921832, 2: 4.304880659885979, 3: 6.992914655392376, 4: 10.684949062855212, 5: 8.26308466784304, 6: 4.856605274259537, 7: 2.269589435411153, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "6 {0: 32.84125692518134, 1: 15.1373133895105, 2: 3.736926968986278, 3: 19.71097399543902, 4: 15.320259930533851, 5: 2.3094488896832375, 6: 10.279030882741662, 7: 2.008307929621153, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "7 {0: 10.642288312007729, 1: 5.86348651000103, 2: 3.138851130994389, 3: 5.822222395709609, 4: 15.4208051970168, 5: 3.6542981220177837, 6: 12.86174712343463, 7: 3.340693972044993, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "8 {0: 7.493898405411703, 1: 7.627471032867888, 2: 3.541926848049341, 3: 21.218564808368715, 4: 20.69745221571511, 5: 9.858370235307563, 6: 6.979828853863535, 7: 2.3489124802404606, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "9 {0: 15.350727646737786, 1: 3.950125000894148, 2: 2.0278929601909774, 3: 15.665738044040888, 4: 8.135951424659803, 5: 2.2084272663378375, 6: 19.034666956563516, 7: 1.6770076225781223, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "10 {0: 12.02122104995426, 1: 7.893677792189948, 2: 6.8500203067624295, 3: 16.331855836252128, 4: 7.500078267905593, 5: 2.6506217775654313, 6: 17.51345233680425, 7: 3.0802161981799765, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "11 {0: 15.00801674984578, 1: 8.546372021377762, 2: 3.140893232977254, 3: 6.331620417453744, 4: 16.557267563197975, 5: 4.877906265467922, 6: 2.6146991525703362, 7: 1.8837976644154468, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "12 {0: 7.253327824099868, 1: 8.268837002224954, 2: 2.575457238583937, 3: 14.118916054706215, 4: 6.873784224495134, 5: 2.6238012204765, 6: 20.659622517807833, 7: 1.2238844101238497, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "13 {0: 6.112069538404355, 1: 11.35046268562358, 2: 3.919123042265956, 3: 6.154159203815212, 4: 9.667664259276933, 5: 2.804274595543076, 6: 10.058047708603533, 7: 5.506427241278871, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "14 {0: 6.7655437579757205, 1: 20.62909490467476, 2: 3.5972368135985016, 3: 7.270251306334156, 4: 7.992340931670391, 5: 4.207647313548399, 6: 8.082031955100934, 7: 4.424119977737675, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "15 {0: 5.637325427737228, 1: 15.123093588411555, 2: 3.3659694915742464, 3: 3.451807963238596, 4: 29.45488448366286, 5: 8.28528962385432, 6: 9.39522138076886, 7: 4.039264011063471, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "16 {0: 7.855758565110442, 1: 7.248567035883066, 2: 3.5346311365567584, 3: 12.872300414357401, 4: 24.197170858722927, 5: 4.370065158910401, 6: 4.620510182427034, 7: 2.123532506401394, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "17 {0: 22.217802974432757, 1: 14.019017095998798, 2: 2.2678340347337937, 3: 7.273272443700103, 4: 46.15180178614281, 5: 5.632286686751474, 6: 40.70054704023066, 7: 2.195868608019967, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "18 {0: 5.936579036063292, 1: 29.516573944780742, 2: 4.5233706122542845, 3: 12.057162909246369, 4: 32.66384122422708, 5: 3.7488677205246943, 6: 20.056902527172227, 7: 1.7503678393273465, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "19 {0: 5.745041878801989, 1: 5.341096513385285, 2: 2.8017935515022185, 3: 6.942372386425059, 4: 21.827446794394646, 5: 4.002223022762988, 6: 64.19532972792169, 7: 1.5490416216613467, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "20 {0: 5.589182973525238, 1: 5.49694606277893, 2: 2.6705535526888227, 3: 8.73727234402068, 4: 13.64339811469837, 5: 4.4932354114455615, 6: 1.9192536344677364, 7: 2.842547829819892, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "21 {0: 8.329156029109301, 1: 13.495062208549946, 2: 3.245251488416117, 3: 33.00124107517599, 4: 5.550831631323306, 5: 5.886015205772067, 6: 3.2010577256040227, 7: 3.0535149126850785, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "22 {0: 6.297744481424373, 1: 10.756191294670327, 2: 3.6111664353784194, 3: 7.199972850699058, 4: 48.48012002134886, 5: 4.2741931465350635, 6: 5.629874603494544, 7: 3.5527603893884, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "23 {0: 5.090501821767246, 1: 3.130943048373265, 2: 4.947264687270511, 3: 7.295321169318235, 4: 28.094193287534363, 5: 4.633653281460187, 6: 4.487201805576464, 7: 4.337237564321646, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "24 {0: 6.694123308678788, 1: 107.35285683732738, 2: 5.237495696519125, 3: 7.4126964590134286, 4: 35.34351176321789, 5: 4.603658198265953, 6: 9.36363322021002, 7: 1.8976999653770656, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "25 {0: 8.796205756948844, 1: 6.046092518642345, 2: 4.4481351607708275, 3: 4.202858368294684, 4: 15.488717036101361, 5: 8.258545459728733, 6: 21.49723600946235, 7: 3.6391074200848594, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "26 {0: 26.56112897026016, 1: 11.885795140383097, 2: 3.5451901345821675, 3: 16.38060741830558, 4: 22.01531935821069, 5: 4.5491640860669635, 6: 32.000232685751556, 7: 4.279989846776622, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "27 {0: 14.55781175362543, 1: 4.844843012540568, 2: 3.393466579240139, 3: 14.397471002130708, 4: 11.023708699823263, 5: 6.870424888248405, 6: 7.19054818215927, 7: 2.825156118225997, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "28 {0: 6.18195112521909, 1: 2.778103963918107, 2: 4.5029539835787435, 3: 21.701337362939896, 4: 10.470084907051204, 5: 3.8701231243742313, 6: 11.794644451941219, 7: 6.804862629263025, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "29 {0: 5.961218688371814, 1: 17.212318875049213, 2: 3.203094774882578, 3: 16.579051408026647, 4: 11.281477967550885, 5: 4.603911550542779, 6: 6.972392867177581, 7: 2.9768341945067207, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "30 {0: 39.958427234473525, 1: 9.023889782847, 2: 2.9431749151314675, 3: 18.879199150522307, 4: 26.223894301931725, 5: 4.773499543395524, 6: 4.306160696510654, 7: 2.3879349404136674, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "31 {0: 4.40215171267858, 1: 18.678166094637888, 2: 2.770109120358052, 3: 8.129809194067406, 4: 27.95576148966444, 5: 8.901676382669466, 6: 39.19270846103255, 7: 3.7826701633708457, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "32 {0: 4.415155227664956, 1: 4.749322326059915, 2: 3.805704454735353, 3: 7.533239900173301, 4: 34.69230443929795, 5: 5.8578070763232475, 6: 17.43664555256331, 7: 3.4830257270606713, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "33 {0: 6.515116168206741, 1: 17.225989247403906, 2: 3.0420666370215823, 3: 9.436146410528384, 4: 18.870964250771564, 5: 10.517666321460341, 6: 23.521593982668296, 7: 1.821585456651907, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
            "34 {0: 6.431615411541974, 1: 2.6674657843129395, 2: 3.859638117551198, 3: 29.857501779861888, 4: 5.868410101069028, 5: 4.216281309578496, 6: 6.713777249565961, 7: 2.6312790056603617, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUnMeF-gGFOG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "f2afe77d-7d17-42ba-b734-198236768f35"
      },
      "source": [
        "# get the perpelxity at each character position (averaged over each non-doubling word)\n",
        "avgs_control = {}\n",
        "for batch, char_dict in position_perplexities_control.items():\n",
        "    for ch, p in char_dict.items():\n",
        "        if avgs_control.get(ch):\n",
        "            avgs_control[ch] += p\n",
        "        else:\n",
        "            avgs_control[ch] = p\n",
        "avgs_control = {k: v / 20 for k, v in avgs_control.items()}\n",
        "\n",
        "# plot\n",
        "df_control = pd.DataFrame(list(avgs_control.items()), columns=['Character Positions', 'control']) \n",
        "plt.bar(df_control['Character Positions'], df_control['control'], color='green', width=0.5)\n",
        "plt.title('Control non-words')\n",
        "plt.xlabel('Character positions')\n",
        "plt.ylabel('Avg. perplexities')\n",
        "plt.xlim(0,6)\n",
        "plt.xticks(np.arange(0, 6, 1))\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
        "plt.show()\n",
        "print('\\n')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLuqxq9iKGSg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "25f60f2e-f6f2-403a-bb82-66cab451d0a7"
      },
      "source": [
        "# plot English test words, doubling non-words, and control non-words together\n",
        "# combined plot\n",
        "df_doubling_pp = df_doubling[\"doubling\"]\n",
        "df_control_pp = df_control[\"control\"]\n",
        "all_data = df.join(df_doubling_pp)\n",
        "all_data = all_data.join(df_control_pp)\n",
        "plt.plot(all_data[\"English\"], label='English', color=\"purple\")\n",
        "plt.plot(all_data[\"doubling\"], label='Doubling non-words', color=\"orange\")\n",
        "plt.plot(all_data[\"control\"], label='Control non-words', color=\"green\")\n",
        "plt.title('Perplexity by character position')\n",
        "plt.xlabel('Character positions')\n",
        "plt.ylabel('Avg. perplexities')\n",
        "plt.legend()\n",
        "plt.xlim(0,6)\n",
        "plt.xticks(np.arange(0, 6, 1))\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE7UzCKe-0jT"
      },
      "source": [
        "# Generate new words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF2dX7qQ_LpN"
      },
      "source": [
        "We can have the model generate words, and count the words that have doubling in them (a model that has learned English well, would not have many words with doubling?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPgUqGDF-yZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1b74f8-b93b-401c-d37a-e231986b8003"
      },
      "source": [
        "# number of names to generate\n",
        "num_words = 20\n",
        "model = model.cpu()\n",
        "# Generate nationality hidden state\n",
        "sampled_words = decode_samples(\n",
        "    sample_from_model(model, vectorizer, num_samples=num_words), \n",
        "    vectorizer)\n",
        "# Show results\n",
        "print (\"-\"*15)\n",
        "for i in range(num_words):\n",
        "    print (sampled_words[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------\n",
            "lecaderLrmecs\n",
            "accoccuytal\n",
            "dilire\n",
            "rofamict\n",
            "obmcnecrieds\n",
            "bummere\n",
            "des\n",
            "mipt\n",
            "abhl\n",
            "palfes\n",
            "pxlure\n",
            "icolic\n",
            "pbor\n",
            "wanyac\n",
            "atibakiud\n",
            "hnakul\n",
            "benlexs\n",
            "detons\n",
            "arfhion\n",
            "cenpimalemer\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}